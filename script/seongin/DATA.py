# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from datetime import datetime
# import warnings
# warnings.filterwarnings('ignore')

# # í•œê¸€ í°íŠ¸ ì„¤ì •
# plt.rcParams['font.family'] = 'DejaVu Sans'
# plt.rcParams['axes.unicode_minus'] = False

# def analyze_train_data():
#     """train.csv ë°ì´í„° ì¢…í•© ë¶„ì„"""
    
#     print("=" * 60)
#     print("ğŸ” ë¦¬ì¡°íŠ¸ ì‹ìŒì—…ì¥ ë§¤ì¶œ ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸")
#     print("=" * 60)
    
#     # ë°ì´í„° ë¡œë“œ
#     print("\nğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
#     df = pd.read_csv('./data/train/train.csv')
    
#     # ë‚ ì§œ ë³€í™˜
#     df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
#     df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
#     df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:]
#     df['ë©”ë‰´ëª…'] = df['ë©”ë‰´ëª…'].apply(lambda x: '_'.join(x) if x else '')
    
#     # 1. ê¸°ë³¸ ì •ë³´
#     print("\n" + "="*50)
#     print("ğŸ“ˆ 1. ë°ì´í„° ê¸°ë³¸ ì •ë³´")
#     print("="*50)
#     print(f"â€¢ ì´ ë ˆì½”ë“œ ìˆ˜: {len(df):,}ê±´")
#     print(f"â€¢ ë¶„ì„ ê¸°ê°„: {df['ì˜ì—…ì¼ì'].min().strftime('%Y-%m-%d')} ~ {df['ì˜ì—…ì¼ì'].max().strftime('%Y-%m-%d')}")
#     print(f"â€¢ ì´ ë¶„ì„ ì¼ìˆ˜: {(df['ì˜ì—…ì¼ì'].max() - df['ì˜ì—…ì¼ì'].min()).days + 1}ì¼")
#     print(f"â€¢ ì˜ì—…ì¥ ìˆ˜: {df['ì˜ì—…ì¥ëª…'].nunique()}ê°œ")
#     print(f"â€¢ ë©”ë‰´ ìˆ˜: {df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].nunique()}ê°œ")
#     print(f"â€¢ ì´ ë§¤ì¶œìˆ˜ëŸ‰: {df['ë§¤ì¶œìˆ˜ëŸ‰'].sum():,}ê°œ")
#     print(f"â€¢ í‰ê·  ë§¤ì¶œìˆ˜ëŸ‰: {df['ë§¤ì¶œìˆ˜ëŸ‰'].mean():.2f}ê°œ")
    
#     # 2. ë§¤ì¶œìˆ˜ëŸ‰ ë¶„í¬ ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸ“Š 2. ë§¤ì¶œìˆ˜ëŸ‰ ë¶„í¬ ë¶„ì„")
#     print("="*50)
#     print(f"â€¢ ìµœì†Œê°’: {df['ë§¤ì¶œìˆ˜ëŸ‰'].min()}ê°œ")
#     print(f"â€¢ ìµœëŒ€ê°’: {df['ë§¤ì¶œìˆ˜ëŸ‰'].max()}ê°œ")
#     print(f"â€¢ ì¤‘ì•™ê°’: {df['ë§¤ì¶œìˆ˜ëŸ‰'].median()}ê°œ")
#     print(f"â€¢ í‘œì¤€í¸ì°¨: {df['ë§¤ì¶œìˆ˜ëŸ‰'].std():.2f}ê°œ")
#     print(f"â€¢ ë§¤ì¶œ 0ì¸ ë¹„ìœ¨: {(df['ë§¤ì¶œìˆ˜ëŸ‰'] == 0).mean()*100:.1f}%")
#     print(f"â€¢ ë§¤ì¶œ > 0ì¸ í‰ê· : {df[df['ë§¤ì¶œìˆ˜ëŸ‰'] > 0]['ë§¤ì¶œìˆ˜ëŸ‰'].mean():.2f}ê°œ")
    
#     # 3. ì˜ì—…ì¥ë³„ ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸª 3. ì˜ì—…ì¥ë³„ ë§¤ì¶œ í˜„í™©")
#     print("="*50)
#     store_analysis = df.groupby('ì˜ì—…ì¥ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'count']).round(2)
#     store_analysis['ë¹„ìœ¨(%)'] = (store_analysis['sum'] / store_analysis['sum'].sum() * 100).round(1)
#     store_analysis = store_analysis.sort_values('sum', ascending=False)
    
#     print("TOP ì˜ì—…ì¥ (ì´ ë§¤ì¶œìˆ˜ëŸ‰ ê¸°ì¤€):")
#     for i, (store, data) in enumerate(store_analysis.head(10).iterrows(), 1):
#         print(f"{i:2d}. {store:15s}: {data['sum']:8,.0f}ê°œ ({data['ë¹„ìœ¨(%)']:5.1f}%) | í‰ê· : {data['mean']:6.2f}ê°œ")
    
#     # 4. ì¸ê¸° ë©”ë‰´ ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸ½ï¸ 4. ì¸ê¸° ë©”ë‰´ ë¶„ì„")
#     print("="*50)
#     menu_analysis = df.groupby('ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'count']).round(2)
#     menu_analysis = menu_analysis.sort_values('sum', ascending=False)
    
#     print("TOP 10 ì¸ê¸° ë©”ë‰´ (ì´ ë§¤ì¶œìˆ˜ëŸ‰ ê¸°ì¤€):")
#     for i, (menu, data) in enumerate(menu_analysis.head(10).iterrows(), 1):
#         print(f"{i:2d}. {menu:25s}: {data['sum']:8,.0f}ê°œ | í‰ê· : {data['mean']:6.2f}ê°œ")
    
#     # 5. ì›”ë³„ ë§¤ì¶œ ì¶”ì´
#     print("\n" + "="*50)
#     print("ğŸ“… 5. ì›”ë³„ ë§¤ì¶œ ì¶”ì´")
#     print("="*50)
#     df['ì—°ì›”'] = df['ì˜ì—…ì¼ì'].dt.to_period('M')
#     monthly_sales = df.groupby('ì—°ì›”')['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
    
#     print("ì›”ë³„ ë§¤ì¶œìˆ˜ëŸ‰:")
#     for period, sales in monthly_sales.items():
#         print(f"â€¢ {period}: {sales:8,}ê°œ")
    
#     # 6. ìš”ì¼ë³„ ë§¤ì¶œ ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸ“† 6. ìš”ì¼ë³„ ë§¤ì¶œ ë¶„ì„")
#     print("="*50)
#     df['ìš”ì¼'] = df['ì˜ì—…ì¼ì'].dt.dayofweek
#     weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
#     df['ìš”ì¼ëª…'] = df['ìš”ì¼'].map(dict(enumerate(weekday_names)))
    
#     weekday_sales = df.groupby('ìš”ì¼ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean']).round(2)
#     weekday_sales = weekday_sales.reindex(weekday_names)
    
#     print("ìš”ì¼ë³„ ë§¤ì¶œ í˜„í™©:")
#     for day, data in weekday_sales.iterrows():
#         print(f"â€¢ {day}ìš”ì¼: ì´ {data['sum']:8,.0f}ê°œ | í‰ê·  {data['mean']:6.2f}ê°œ")
    
#     # 7. ì˜ì—…ì¥ë³„ ì£¼ë ¥ ë©”ë‰´
#     print("\n" + "="*50)
#     print("ğŸ¯ 7. ì˜ì—…ì¥ë³„ ì£¼ë ¥ ë©”ë‰´")
#     print("="*50)
#     for store in df['ì˜ì—…ì¥ëª…'].unique():
#         store_data = df[df['ì˜ì—…ì¥ëª…'] == store]
#         top_menu = store_data.groupby('ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].sum().sort_values(ascending=False).head(3)
#         print(f"\nâ€¢ {store}:")
#         for i, (menu, sales) in enumerate(top_menu.items(), 1):
#             print(f"  {i}. {menu}: {sales:,}ê°œ")
    
#     # 8. ê³„ì ˆì„± ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸŒ¸ 8. ê³„ì ˆì„± ë¶„ì„")
#     print("="*50)
#     df['ì›”'] = df['ì˜ì—…ì¼ì'].dt.month
#     df['ê³„ì ˆ'] = df['ì›”'].map({12: 'ê²¨ìš¸', 1: 'ê²¨ìš¸', 2: 'ê²¨ìš¸',
#                           3: 'ë´„', 4: 'ë´„', 5: 'ë´„',
#                           6: 'ì—¬ë¦„', 7: 'ì—¬ë¦„', 8: 'ì—¬ë¦„',
#                           9: 'ê°€ì„', 10: 'ê°€ì„', 11: 'ê°€ì„'})
    
#     seasonal_sales = df.groupby('ê³„ì ˆ')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean']).round(2)
#     seasonal_order = ['ë´„', 'ì—¬ë¦„', 'ê°€ì„', 'ê²¨ìš¸']
#     seasonal_sales = seasonal_sales.reindex(seasonal_order)
    
#     print("ê³„ì ˆë³„ ë§¤ì¶œ í˜„í™©:")
#     for season, data in seasonal_sales.iterrows():
#         print(f"â€¢ {season}: ì´ {data['sum']:8,.0f}ê°œ | í‰ê·  {data['mean']:6.2f}ê°œ")
    
#     # 9. íŠ¹ì´ì‚¬í•­ ë¶„ì„
#     print("\n" + "="*50)
#     print("âš ï¸ 9. íŠ¹ì´ì‚¬í•­ ë¶„ì„")
#     print("="*50)
    
#     # 3ì›” ë§¤ì¶œ ê¸‰ê° í˜„ìƒ
#     march_2023 = df[(df['ì˜ì—…ì¼ì'].dt.year == 2023) & (df['ì˜ì—…ì¼ì'].dt.month == 3)]['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
#     march_2024 = df[(df['ì˜ì—…ì¼ì'].dt.year == 2024) & (df['ì˜ì—…ì¼ì'].dt.month == 3)]['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
#     feb_2023 = df[(df['ì˜ì—…ì¼ì'].dt.year == 2023) & (df['ì˜ì—…ì¼ì'].dt.month == 2)]['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
#     feb_2024 = df[(df['ì˜ì—…ì¼ì'].dt.year == 2024) & (df['ì˜ì—…ì¼ì'].dt.month == 2)]['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
    
#     print(f"â€¢ 3ì›” ë§¤ì¶œ ê¸‰ê° í˜„ìƒ:")
#     print(f"  - 2023ë…„ 2ì›” â†’ 3ì›”: {feb_2023:,} â†’ {march_2023:,} ({(march_2023/feb_2023-1)*100:+.1f}%)")
#     print(f"  - 2024ë…„ 2ì›” â†’ 3ì›”: {feb_2024:,} â†’ {march_2024:,} ({(march_2024/feb_2024-1)*100:+.1f}%)")
    
#     # 1ì›” ë§¤ì¶œ ìµœê³  í˜„ìƒ
#     jan_2023 = df[(df['ì˜ì—…ì¼ì'].dt.year == 2023) & (df['ì˜ì—…ì¼ì'].dt.month == 1)]['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
#     jan_2024 = df[(df['ì˜ì—…ì¼ì'].dt.year == 2024) & (df['ì˜ì—…ì¼ì'].dt.month == 1)]['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
    
#     print(f"â€¢ 1ì›” ë§¤ì¶œ ìµœê³  í˜„ìƒ:")
#     print(f"  - 2023ë…„ 1ì›”: {jan_2023:,}ê°œ")
#     print(f"  - 2024ë…„ 1ì›”: {jan_2024:,}ê°œ (ì „ì²´ ìµœê³ )")
    
#     # 10. ë°ì´í„° í’ˆì§ˆ ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸ” 10. ë°ì´í„° í’ˆì§ˆ ë¶„ì„")
#     print("="*50)
#     print(f"â€¢ ê²°ì¸¡ê°’:")
#     print(f"  - ì˜ì—…ì¼ì: {df['ì˜ì—…ì¼ì'].isnull().sum()}ê°œ")
#     print(f"  - ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…: {df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].isnull().sum()}ê°œ")
#     print(f"  - ë§¤ì¶œìˆ˜ëŸ‰: {df['ë§¤ì¶œìˆ˜ëŸ‰'].isnull().sum()}ê°œ")
    
#     print(f"â€¢ ìŒìˆ˜ ë§¤ì¶œìˆ˜ëŸ‰: {(df['ë§¤ì¶œìˆ˜ëŸ‰'] < 0).sum()}ê°œ")
#     print(f"â€¢ ì´ìƒì¹˜ (Q3 + 1.5*IQR ì´ˆê³¼): {detect_outliers(df['ë§¤ì¶œìˆ˜ëŸ‰'])}ê°œ")
    
#     # 11. ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ì„
#     print("\n" + "="*50)
#     print("ğŸ·ï¸ 11. ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ì„")
#     print("="*50)
    
#     # ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
#     df['ì¹´í…Œê³ ë¦¬'] = 'ê¸°íƒ€'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ë¶„ì‹ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ìŒë£Œë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|Beer|ìƒë§¥ì£¼', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ì£¼ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'í•œì‹ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ì–‘ì‹ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ë¸ŒëŸ°ì¹˜', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ë‹¨ì²´ë©”ë‰´'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ëŒ€ì—¬ë£Œ|ì´ìš©ë£Œ|Conference|Convention', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ëŒ€ì—¬ë£Œ'
    
#     category_sales = df.groupby('ì¹´í…Œê³ ë¦¬')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'count']).round(2)
#     category_sales['ë¹„ìœ¨(%)'] = (category_sales['sum'] / category_sales['sum'].sum() * 100).round(1)
#     category_sales = category_sales.sort_values('sum', ascending=False)
    
#     print("ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ í˜„í™©:")
#     for category, data in category_sales.iterrows():
#         print(f"â€¢ {category:8s}: {data['sum']:8,.0f}ê°œ ({data['ë¹„ìœ¨(%)']:5.1f}%) | í‰ê· : {data['mean']:6.2f}ê°œ")
    
#     return df

# def detect_outliers(series):
#     """ì´ìƒì¹˜ ê°œìˆ˜ ê³„ì‚° (IQR ë°©ë²•)"""
#     Q1 = series.quantile(0.25)
#     Q3 = series.quantile(0.75)
#     IQR = Q3 - Q1
#     lower_bound = Q1 - 1.5 * IQR
#     upper_bound = Q3 + 1.5 * IQR
#     return ((series < lower_bound) | (series > upper_bound)).sum()

# def create_visualizations(df):
#     """ì‹œê°í™” ìƒì„±"""
#     print("\n" + "="*50)
#     print("ğŸ“Š 12. ì‹œê°í™” ìƒì„± ì¤‘...")
#     print("="*50)
    
#     # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •
#     plt.style.use('default')
#     fig, axes = plt.subplots(2, 3, figsize=(20, 12))
#     fig.suptitle('Resort Restaurant Sales Analysis', fontsize=16, fontweight='bold')
    
#     # 1. ì›”ë³„ ë§¤ì¶œ ì¶”ì´
#     monthly_sales = df.groupby(df['ì˜ì—…ì¼ì'].dt.to_period('M'))['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
#     axes[0, 0].plot(range(len(monthly_sales)), monthly_sales.values, marker='o', linewidth=2, markersize=6)
#     axes[0, 0].set_title('Monthly Sales Trend', fontweight='bold')
#     axes[0, 0].set_xlabel('Month')
#     axes[0, 0].set_ylabel('Sales Quantity')
#     axes[0, 0].grid(True, alpha=0.3)
#     axes[0, 0].tick_params(axis='x', rotation=45)
    
#     # 2. ì˜ì—…ì¥ë³„ ë§¤ì¶œ
#     store_sales = df.groupby('ì˜ì—…ì¥ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].sum().sort_values(ascending=True)
#     axes[0, 1].barh(range(len(store_sales)), store_sales.values, color='skyblue')
#     axes[0, 1].set_title('Sales by Store', fontweight='bold')
#     axes[0, 1].set_xlabel('Sales Quantity')
#     axes[0, 1].set_yticks(range(len(store_sales)))
#     axes[0, 1].set_yticklabels(store_sales.index, fontsize=8)
    
#     # 3. ìš”ì¼ë³„ ë§¤ì¶œ
#     weekday_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
#     weekday_sales = df.groupby(df['ì˜ì—…ì¼ì'].dt.dayofweek)['ë§¤ì¶œìˆ˜ëŸ‰'].sum()
#     axes[0, 2].bar(weekday_names, weekday_sales.values, color='lightgreen')
#     axes[0, 2].set_title('Sales by Day of Week', fontweight='bold')
#     axes[0, 2].set_xlabel('Day of Week')
#     axes[0, 2].set_ylabel('Sales Quantity')
    
#     # 4. ë§¤ì¶œìˆ˜ëŸ‰ ë¶„í¬
#     axes[1, 0].hist(df[df['ë§¤ì¶œìˆ˜ëŸ‰'] > 0]['ë§¤ì¶œìˆ˜ëŸ‰'], bins=50, color='orange', alpha=0.7, edgecolor='black')
#     axes[1, 0].set_title('Sales Quantity Distribution (>0)', fontweight='bold')
#     axes[1, 0].set_xlabel('Sales Quantity')
#     axes[1, 0].set_ylabel('Frequency')
#     axes[1, 0].set_yscale('log')
    
#     # 5. ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ
#     df['ì¹´í…Œê³ ë¦¬'] = 'ê¸°íƒ€'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ë¶„ì‹ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ìŒë£Œë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ì£¼ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'í•œì‹ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ì–‘ì‹ë¥˜'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ë¸ŒëŸ°ì¹˜', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ë‹¨ì²´ë©”ë‰´'
#     df.loc[df['ë©”ë‰´ëª…'].str.contains('ëŒ€ì—¬ë£Œ|ì´ìš©ë£Œ', na=False), 'ì¹´í…Œê³ ë¦¬'] = 'ëŒ€ì—¬ë£Œ'
    
#     category_sales = df.groupby('ì¹´í…Œê³ ë¦¬')['ë§¤ì¶œìˆ˜ëŸ‰'].sum().sort_values(ascending=True)
#     colors = plt.cm.Set3(np.linspace(0, 1, len(category_sales)))
#     axes[1, 1].barh(range(len(category_sales)), category_sales.values, color=colors)
#     axes[1, 1].set_title('Sales by Category', fontweight='bold')
#     axes[1, 1].set_xlabel('Sales Quantity')
#     axes[1, 1].set_yticks(range(len(category_sales)))
#     axes[1, 1].set_yticklabels(category_sales.index, fontsize=9)
    
#     # 6. ìƒìœ„ ë©”ë‰´ ë§¤ì¶œ
#     top_menus = df.groupby('ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].sum().sort_values(ascending=False).head(10)
#     axes[1, 2].barh(range(len(top_menus)), top_menus.values, color='coral')
#     axes[1, 2].set_title('Top 10 Menu Sales', fontweight='bold')
#     axes[1, 2].set_xlabel('Sales Quantity')
#     axes[1, 2].set_yticks(range(len(top_menus)))
#     axes[1, 2].set_yticklabels([menu[:20] + '...' if len(menu) > 20 else menu for menu in top_menus.index], fontsize=8)
    
#     plt.tight_layout()
#     plt.savefig('train_data_analysis.png', dpi=300, bbox_inches='tight')
#     print("âœ… ì‹œê°í™” ì €ì¥ ì™„ë£Œ: train_data_analysis.png")
    
#     return fig

# if __name__ == "__main__":
#     # ë°ì´í„° ë¶„ì„ ì‹¤í–‰
#     df = analyze_train_data()
    
#     # ì‹œê°í™” ìƒì„±
#     fig = create_visualizations(df)
    
#     print("\n" + "="*60)
#     print("âœ… ë¶„ì„ ì™„ë£Œ!")
#     print("ğŸ“ˆ ìƒì„¸í•œ ì‹œê°í™”ëŠ” 'train_data_analysis.png' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
#     print("="*60)


import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

def create_enhanced_features(df):
    """
    ë§¤ì¶œ ë°ì´í„°ì—ì„œ ì˜ë¯¸ìˆëŠ” ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    # ì›ë³¸ ë°ì´í„° ë³µì‚¬
    enhanced_df = df.copy()
    
    # 1. ê¸°ë³¸ ì „ì²˜ë¦¬: ì˜ì—…ì¥ëª…ê³¼ ë©”ë‰´ëª… ë¶„ë¦¬
    enhanced_df[['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…']] = enhanced_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_', expand=True)
    enhanced_df['ì˜ì—…ì¼ì'] = pd.to_datetime(enhanced_df['ì˜ì—…ì¼ì'])
    
    # 2. ì‹œê°„ ê´€ë ¨ íŠ¹ì„± ìƒì„±
    enhanced_df['ì—°ë„'] = enhanced_df['ì˜ì—…ì¼ì'].dt.year
    enhanced_df['ì›”'] = enhanced_df['ì˜ì—…ì¼ì'].dt.month
    enhanced_df['ì¼'] = enhanced_df['ì˜ì—…ì¼ì'].dt.day
    enhanced_df['ìš”ì¼'] = enhanced_df['ì˜ì—…ì¼ì'].dt.dayofweek
    enhanced_df['ìš”ì¼ëª…'] = enhanced_df['ì˜ì—…ì¼ì'].dt.day_name()
    
    # ê³„ì ˆ ì •ì˜
    def get_season(month):
        if month in [3, 4, 5]:
            return 'ë´„'
        elif month in [6, 7, 8]:
            return 'ì—¬ë¦„'
        elif month in [9, 10, 11]:
            return 'ê°€ì„'
        else:
            return 'ê²¨ìš¸'
    
    enhanced_df['ê³„ì ˆ'] = enhanced_df['ì›”'].apply(get_season)
    enhanced_df['ì£¼ë§ì—¬ë¶€'] = (enhanced_df['ìš”ì¼'].isin([5, 6])).astype(int)
    enhanced_df['ì›”ë§ì—¬ë¶€'] = (enhanced_df['ì¼'] >= 25).astype(int)
    enhanced_df['ì›”ì´ˆì—¬ë¶€'] = (enhanced_df['ì¼'] <= 7).astype(int)
    enhanced_df['ë¶„ê¸°'] = enhanced_df['ì˜ì—…ì¼ì'].dt.quarter
    
    # 3. ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
    def categorize_menu(menu_name):
        menu_lower = menu_name.lower()
        if any(keyword in menu_lower for keyword in ['ìˆ˜ì €', 'ì “ê°€ë½', 'í¬í¬', 'ë‚˜ì´í”„']):
            return 'ì‹ê¸°ë¥˜'
        elif any(keyword in menu_lower for keyword in ['ë°¥', 'ìŒ€', 'ë©´', 'êµ­ìˆ˜']):
            return 'ì£¼ì‹'
        elif any(keyword in menu_lower for keyword in ['ê³ ê¸°', 'ì‚¼ê²¹', 'ê°ˆë¹„', 'ì¹˜í‚¨', 'ë¼ì§€', 'ì†Œê³ ê¸°']):
            return 'ìœ¡ë¥˜'
        elif any(keyword in menu_lower for keyword in ['ì•¼ì±„', 'ìƒëŸ¬ë“œ', 'ì±„ì†Œ', 'ê¹€ì¹˜']):
            return 'ì±„ì†Œë¥˜'
        elif any(keyword in menu_lower for keyword in ['ìŒë£Œ', 'ì»¤í”¼', 'ì°¨', 'ì£¼ìŠ¤', 'ë¬¼']):
            return 'ìŒë£Œ'
        elif any(keyword in menu_lower for keyword in ['ë””ì €íŠ¸', 'ì¼€ì´í¬', 'ì•„ì´ìŠ¤í¬ë¦¼', 'ê³¼ì']):
            return 'ë””ì €íŠ¸'
        elif any(keyword in menu_lower for keyword in ['êµ­', 'ì°Œê°œ', 'íƒ•', 'ìŠ¤í”„']):
            return 'êµ­ë¬¼ë¥˜'
        else:
            return 'ê¸°íƒ€'
    
    enhanced_df['ë©”ë‰´ì¹´í…Œê³ ë¦¬'] = enhanced_df['ë©”ë‰´ëª…'].apply(categorize_menu)
    
    # 4. ìƒí˜¸ì‘ìš© íŠ¹ì„± ìƒì„±
    enhanced_df['ì˜ì—…ì¥_ì¹´í…Œê³ ë¦¬'] = enhanced_df['ì˜ì—…ì¥ëª…'] + '_' + enhanced_df['ë©”ë‰´ì¹´í…Œê³ ë¦¬']
    enhanced_df['ê³„ì ˆ_ì¹´í…Œê³ ë¦¬'] = enhanced_df['ê³„ì ˆ'] + '_' + enhanced_df['ë©”ë‰´ì¹´í…Œê³ ë¦¬']
    enhanced_df['ì£¼ë§_ì¹´í…Œê³ ë¦¬'] = enhanced_df['ì£¼ë§ì—¬ë¶€'].map({0: 'í‰ì¼', 1: 'ì£¼ë§'}) + '_' + enhanced_df['ë©”ë‰´ì¹´í…Œê³ ë¦¬']
    
    # 5. ì§‘ê³„ í†µê³„ íŠ¹ì„± ìƒì„±
    # ì˜ì—…ì¥ë³„ í†µê³„
    store_stats = enhanced_df.groupby('ì˜ì—…ì¥ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'std', 'count']).reset_index()
    store_stats.columns = ['ì˜ì—…ì¥ëª…', 'ì˜ì—…ì¥_ì´ë§¤ì¶œ', 'ì˜ì—…ì¥_í‰ê· ë§¤ì¶œ', 'ì˜ì—…ì¥_ë§¤ì¶œí‘œì¤€í¸ì°¨', 'ì˜ì—…ì¥_ë°ì´í„°ìˆ˜']
    enhanced_df = enhanced_df.merge(store_stats, on='ì˜ì—…ì¥ëª…', how='left')
    
    # ë©”ë‰´ë³„ í†µê³„
    menu_stats = enhanced_df.groupby('ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'std', 'count']).reset_index()
    menu_stats.columns = ['ë©”ë‰´ëª…', 'ë©”ë‰´_ì´ë§¤ì¶œ', 'ë©”ë‰´_í‰ê· ë§¤ì¶œ', 'ë©”ë‰´_ë§¤ì¶œí‘œì¤€í¸ì°¨', 'ë©”ë‰´_ë°ì´í„°ìˆ˜']
    enhanced_df = enhanced_df.merge(menu_stats, on='ë©”ë‰´ëª…', how='left')
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    category_stats = enhanced_df.groupby('ë©”ë‰´ì¹´í…Œê³ ë¦¬')['ë§¤ì¶œìˆ˜ëŸ‰'].agg(['sum', 'mean', 'std']).reset_index()
    category_stats.columns = ['ë©”ë‰´ì¹´í…Œê³ ë¦¬', 'ì¹´í…Œê³ ë¦¬_ì´ë§¤ì¶œ', 'ì¹´í…Œê³ ë¦¬_í‰ê· ë§¤ì¶œ', 'ì¹´í…Œê³ ë¦¬_ë§¤ì¶œí‘œì¤€í¸ì°¨']
    enhanced_df = enhanced_df.merge(category_stats, on='ë©”ë‰´ì¹´í…Œê³ ë¦¬', how='left')
    
    # 6. ë§¤ì¶œ ë¹„ì¤‘ ê³„ì‚°
    enhanced_df['ë§¤ì¶œë¹„ì¤‘_ì˜ì—…ì¥ë‚´'] = (enhanced_df['ë§¤ì¶œìˆ˜ëŸ‰'] / enhanced_df['ì˜ì—…ì¥_ì´ë§¤ì¶œ'] * 100).fillna(0)
    enhanced_df['ë§¤ì¶œë¹„ì¤‘_ë©”ë‰´ë‚´'] = (enhanced_df['ë§¤ì¶œìˆ˜ëŸ‰'] / enhanced_df['ë©”ë‰´_ì´ë§¤ì¶œ'] * 100).fillna(0)
    enhanced_df['ë§¤ì¶œë¹„ì¤‘_ì¹´í…Œê³ ë¦¬ë‚´'] = (enhanced_df['ë§¤ì¶œìˆ˜ëŸ‰'] / enhanced_df['ì¹´í…Œê³ ë¦¬_ì´ë§¤ì¶œ'] * 100).fillna(0)
    
    # 7. ì‹œê³„ì—´ ì§€ì—°(Lag) íŠ¹ì„± ìƒì„±
    enhanced_df = enhanced_df.sort_values(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'])
    
    # ì˜ì—…ì¥-ë©”ë‰´ ì¡°í•©ë³„ë¡œ lag íŠ¹ì„± ìƒì„±
    lag_features = []
    for (store, menu), group in enhanced_df.groupby(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…']):
        group = group.sort_values('ì˜ì—…ì¼ì').copy()
        
        # lag íŠ¹ì„±ë“¤
        group['ì „ì¼ë§¤ì¶œ'] = group['ë§¤ì¶œìˆ˜ëŸ‰'].shift(1).fillna(0)
        group['ë‹¤ìŒì¼ë§¤ì¶œ'] = group['ë§¤ì¶œìˆ˜ëŸ‰'].shift(-1).fillna(0)
        group['ì „ì£¼ë™ìš”ì¼ë§¤ì¶œ'] = group['ë§¤ì¶œìˆ˜ëŸ‰'].shift(7).fillna(0)
        
        # ì´ë™ í‰ê· 
        group['ìµœê·¼3ì¼í‰ê· '] = group['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window=3, min_periods=1).mean()
        group['ìµœê·¼7ì¼í‰ê· '] = group['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window=7, min_periods=1).mean()
        group['ìµœê·¼30ì¼í‰ê· '] = group['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window=30, min_periods=1).mean()
        
        # ë³€í™”ìœ¨
        group['ì „ì¼ëŒ€ë¹„ì¦ê°ë¥ '] = ((group['ë§¤ì¶œìˆ˜ëŸ‰'] - group['ì „ì¼ë§¤ì¶œ']) / (group['ì „ì¼ë§¤ì¶œ'] + 1e-8) * 100).fillna(0)
        group['ì „ì£¼ë™ìš”ì¼ëŒ€ë¹„ì¦ê°ë¥ '] = ((group['ë§¤ì¶œìˆ˜ëŸ‰'] - group['ì „ì£¼ë™ìš”ì¼ë§¤ì¶œ']) / (group['ì „ì£¼ë™ìš”ì¼ë§¤ì¶œ'] + 1e-8) * 100).fillna(0)
        
        lag_features.append(group)
    
    enhanced_df = pd.concat(lag_features, ignore_index=True)
    
    # 8. ì¶”ê°€ íŒŒìƒ íŠ¹ì„±
    # ë§¤ì¶œ ë“±ê¸‰ (0: ë¬´ë§¤ì¶œ, 1: ì €ë§¤ì¶œ, 2: ë³´í†µ, 3: ê³ ë§¤ì¶œ)
    def sales_grade(sales):
        if sales == 0:
            return 0
        elif sales <= 5:
            return 1
        elif sales <= 20:
            return 2
        else:
            return 3
    
    enhanced_df['ë§¤ì¶œë“±ê¸‰'] = enhanced_df['ë§¤ì¶œìˆ˜ëŸ‰'].apply(sales_grade)
    
    # íŠ¸ë Œë“œ ë°©í–¥ (ìµœê·¼ 7ì¼ ê¸°ì¤€)
    enhanced_df['íŠ¸ë Œë“œë°©í–¥'] = np.where(
        enhanced_df['ìµœê·¼7ì¼í‰ê· '] > enhanced_df['ìµœê·¼7ì¼í‰ê· '].shift(7),
        'ìƒìŠ¹',
        np.where(enhanced_df['ìµœê·¼7ì¼í‰ê· '] < enhanced_df['ìµœê·¼7ì¼í‰ê· '].shift(7), 'í•˜ë½', 'ìœ ì§€')
    )
    
    # ê³„ì ˆì„± ì§€ìˆ˜ (í•´ë‹¹ ì›”ì˜ ì „ì²´ í‰ê·  ëŒ€ë¹„)
    monthly_avg = enhanced_df.groupby(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì›”'])['ë§¤ì¶œìˆ˜ëŸ‰'].mean().reset_index()
    monthly_avg.columns = ['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì›”', 'ì›”ë³„í‰ê· ë§¤ì¶œ']
    enhanced_df = enhanced_df.merge(monthly_avg, on=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì›”'], how='left')
    
    overall_avg = enhanced_df.groupby(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])['ë§¤ì¶œìˆ˜ëŸ‰'].mean().reset_index()
    overall_avg.columns = ['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì „ì²´í‰ê· ë§¤ì¶œ']
    enhanced_df = enhanced_df.merge(overall_avg, on=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'], how='left')
    
    enhanced_df['ê³„ì ˆì„±ì§€ìˆ˜'] = (enhanced_df['ì›”ë³„í‰ê· ë§¤ì¶œ'] / (enhanced_df['ì „ì²´í‰ê· ë§¤ì¶œ'] + 1e-8)).fillna(1.0)
    
    # 9. ì´ìƒì¹˜ íƒì§€ (Z-score ê¸°ì¤€)
    enhanced_df['ë§¤ì¶œ_zscore'] = enhanced_df.groupby(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])['ë§¤ì¶œìˆ˜ëŸ‰'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-8)
    )
    enhanced_df['ì´ìƒì¹˜ì—¬ë¶€'] = (np.abs(enhanced_df['ë§¤ì¶œ_zscore']) > 2).astype(int)
    
    # 10. ìš”ì¼ë³„ ë§¤ì¶œ íŒ¨í„´
    dow_pattern = enhanced_df.groupby(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ìš”ì¼'])['ë§¤ì¶œìˆ˜ëŸ‰'].mean().reset_index()
    dow_pattern.columns = ['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ìš”ì¼', 'ìš”ì¼ë³„í‰ê· ë§¤ì¶œ']
    enhanced_df = enhanced_df.merge(dow_pattern, on=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ìš”ì¼'], how='left')
    
    # 11. ì—°ì† ë¬´ë§¤ì¶œ ì¼ìˆ˜
    def count_consecutive_zeros(group):
        group = group.sort_values('ì˜ì—…ì¼ì')
        consecutive_zeros = []
        current_count = 0
        
        for sales in group['ë§¤ì¶œìˆ˜ëŸ‰']:
            if sales == 0:
                current_count += 1
            else:
                current_count = 0
            consecutive_zeros.append(current_count)
        
        group['ì—°ì†ë¬´ë§¤ì¶œì¼ìˆ˜'] = consecutive_zeros
        return group
    
    enhanced_df = enhanced_df.groupby(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…']).apply(count_consecutive_zeros).reset_index(drop=True)
    
    # 12. ìœ ë‹ˆí¬ ì‹ë³„ì
    enhanced_df['ìœ ë‹ˆí¬í‚¤'] = enhanced_df['ì˜ì—…ì¥ëª…'] + '_' + enhanced_df['ë©”ë‰´ëª…'] + '_' + enhanced_df['ì˜ì—…ì¼ì'].dt.strftime('%Y%m%d')
    
    # ì •ë ¬
    enhanced_df = enhanced_df.sort_values(['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì']).reset_index(drop=True)
    
    return enhanced_df

# ì‚¬ìš© ì˜ˆì‹œ
def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    # ë°ì´í„° ë¡œë“œ (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½)
    df = pd.read_csv('./data/train/train.csv')
    
    print("=== ì›ë³¸ ë°ì´í„° ì •ë³´ ===")
    print(f"ë°ì´í„° í¬ê¸°: {df.shape}")
    print(f"ì»¬ëŸ¼: {list(df.columns)}")
    print("\n=== íŠ¹ì„± ìƒì„± ì‹œì‘ ===")
    
    # ìƒˆë¡œìš´ íŠ¹ì„±ë“¤ ìƒì„±
    enhanced_df = create_enhanced_features(df)
    
    print(f"\n=== ê²°ê³¼ ===")
    print(f"í™•ì¥ëœ ë°ì´í„° í¬ê¸°: {enhanced_df.shape}")
    print(f"ì¶”ê°€ëœ ì»¬ëŸ¼ ìˆ˜: {enhanced_df.shape[1] - df.shape[1]}")
    
    print(f"\n=== ìƒˆë¡œ ìƒì„±ëœ ì£¼ìš” íŠ¹ì„±ë“¤ ===")
    new_features = [
        'ìš”ì¼ëª…', 'ê³„ì ˆ', 'ì£¼ë§ì—¬ë¶€', 'ë©”ë‰´ì¹´í…Œê³ ë¦¬', 'ì˜ì—…ì¥_ì¹´í…Œê³ ë¦¬',
        'ì˜ì—…ì¥_í‰ê· ë§¤ì¶œ', 'ë©”ë‰´_í‰ê· ë§¤ì¶œ', 'ë§¤ì¶œë¹„ì¤‘_ì˜ì—…ì¥ë‚´',
        'ì „ì¼ë§¤ì¶œ', 'ìµœê·¼7ì¼í‰ê· ', 'ì „ì¼ëŒ€ë¹„ì¦ê°ë¥ ', 'ë§¤ì¶œë“±ê¸‰',
        'íŠ¸ë Œë“œë°©í–¥', 'ê³„ì ˆì„±ì§€ìˆ˜', 'ì´ìƒì¹˜ì—¬ë¶€', 'ì—°ì†ë¬´ë§¤ì¶œì¼ìˆ˜'
    ]
    
    for feature in new_features:
        if feature in enhanced_df.columns:
            print(f"âœ… {feature}")
    
    # ê²°ê³¼ ì €ì¥
    enhanced_df.to_csv('enhanced_train.csv', index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ í™•ì¥ëœ ë°ì´í„°ê°€ 'enhanced_train.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ìƒ˜í”Œ í™•ì¸
    print(f"\n=== ìƒ˜í”Œ ë°ì´í„° ===")
    sample_cols = ['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…', 'ë©”ë‰´ì¹´í…Œê³ ë¦¬', 'ë§¤ì¶œìˆ˜ëŸ‰', 'ê³„ì ˆ', 'ì£¼ë§ì—¬ë¶€', 'ìµœê·¼7ì¼í‰ê· ', 'ë§¤ì¶œë“±ê¸‰']
    print(enhanced_df[sample_cols].head(3).to_string())
    
    return enhanced_df

if __name__ == "__main__":
    enhanced_data = main()