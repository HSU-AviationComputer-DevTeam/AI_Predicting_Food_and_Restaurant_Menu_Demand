import os
import glob
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.tabular import TabularPredictor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)


# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)


# í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± ì¶”ê°€)
def create_features(df):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['day'] = df['ì˜ì—…ì¼ì'].dt.day
    df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    # ì˜ì—…ì¥ëª…ê³¼ ë©”ë‰´ëª… ë¶„ë¦¬
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].apply(lambda x: '_'.join(x) if x else '')

        # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ AutoGluonì´ ì²˜ë¦¬í•˜ë„ë¡ ë¬¸ìì—´ë¡œ ìœ ì§€
        # df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…_encoded'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].astype('category').cat.codes
        # df['ì˜ì—…ì¥ëª…_encoded'] = df['ì˜ì—…ì¥ëª…'].astype('category').cat.codes

    # === ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± í”¼ì²˜ ì¶”ê°€ ===
    if 'ë©”ë‰´ëª…' in df.columns:
        # 1. ê³„ì ˆ íŠ¹í™” ë©”ë‰´ ë¶„ë¥˜
        df['ë´„_íŠ¹í™”ë©”ë‰´'] = 0
        df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] = 0
        df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] = 0
        df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] = 0
        
        spring_keywords = ['ë¸ŒëŸ°ì¹˜', 'ìƒëŸ¬ë“œ', 'ë¦¬ì¡°ë˜', 'ê·¸ë¦´ë“œ', 'ì‹œì €']
        df['ë´„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(spring_keywords), na=False).astype(int)
        
        summer_keywords = ['ice', 'ì•„ì´ìŠ¤', 'ì—ì´ë“œ', 'ì‹í˜œ', 'ìƒìˆ˜', 'ëƒ‰ë©´', 'í•´ë¬¼', 'ëìŠ¤íƒ€', 'ì‰¬ë¦¼í”„', 'í•´ì‚°ë¬¼']
        df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(summer_keywords), na=False, case=False).astype(int)
        
        fall_keywords = ['ë§‰ê±¸ë¦¬', 'ì†Œì£¼', 'ë§¥ì£¼', 'ì°¸ì´ìŠ¬', 'ì¹´ìŠ¤', 'beer']
        df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(fall_keywords), na=False, case=False).astype(int)
        
        winter_keywords = ['êµ­', 'íƒ•', 'ì°Œê°œ', 'í•´ì¥', 'hot', 'í•«ë„ê·¸', 'ë–¡ë³¶ì´', 'ê¼¬ì¹˜ì–´ë¬µ', 'íŒŒì „', 'ë¶ˆê³ ê¸°', 'ê°ˆë¹„', 'ëˆê¹ŒìŠ¤', 'bbq', 'í•œìš°', 'ì‚¼ê²¹']
        df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(winter_keywords), na=False, case=False).astype(int)
        
        # 2. ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
        df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False).astype(int)
        df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
        df['í•œì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False).astype(int)
        df['ì–‘ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False).astype(int)
        df['ë‹¨ì²´ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ë¸ŒëŸ°ì¹˜', na=False).astype(int)
        df['ëŒ€ì—¬ë£Œ'] = df['ë©”ë‰´ëª…'].str.contains('ëŒ€ì—¬ë£Œ|ì´ìš©ë£Œ|conference|convention', na=False, case=False).astype(int)
        
        # 3. ì˜ì—…ì¥ë³„ íŠ¹ì„±
        df['í¬ë ˆìŠ¤íŠ¸ë¦¿'] = (df['ì˜ì—…ì¥ëª…'] == 'í¬ë ˆìŠ¤íŠ¸ë¦¿').astype(int)
        df['ì¹´í˜í…Œë¦¬ì•„'] = (df['ì˜ì—…ì¥ëª…'] == 'ì¹´í˜í…Œë¦¬ì•„').astype(int)
        df['í™”ë‹´ìˆ²ì£¼ë§‰'] = (df['ì˜ì—…ì¥ëª…'] == 'í™”ë‹´ìˆ²ì£¼ë§‰').astype(int)
        df['ë‹´í•˜'] = (df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜').astype(int)
        df['ë¯¸ë¼ì‹œì•„'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„').astype(int)
        df['ëŠí‹°ë‚˜ë¬´'] = (df['ì˜ì—…ì¥ëª…'] == 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ').astype(int)
        df['ë¼ê·¸ë¡œíƒ€'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¼ê·¸ë¡œíƒ€').astype(int)
        df['ì—°íšŒì¥'] = (df['ì˜ì—…ì¥ëª…'] == 'ì—°íšŒì¥').astype(int)
        df['í™”ë‹´ìˆ²ì¹´í˜'] = (df['ì˜ì—…ì¥ëª…'] == 'í™”ë‹´ìˆ²ì¹´í˜').astype(int)
        
        # 4. ì¸ê¸° ë©”ë‰´ TOP 10 íŠ¹ë³„ ì²˜ë¦¬
        df['ì¸ê¸°ë©”ë‰´_ê¼¬ì¹˜ì–´ë¬µ'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_í•´ë¬¼íŒŒì „'] = df['ë©”ë‰´ëª…'].str.contains('í•´ë¬¼íŒŒì „', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ë–¡ë³¶ì´'] = df['ë©”ë‰´ëª…'].str.contains('ë–¡ë³¶ì´', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ìƒìˆ˜'] = df['ë©”ë‰´ëª…'].str.contains('ìƒìˆ˜', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ì•„ë©”ë¦¬ì¹´ë…¸'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ì¹˜ì¦ˆí•«ë„ê·¸'] = df['ë©”ë‰´ëª…'].str.contains('ì¹˜ì¦ˆ í•«ë„ê·¸', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ëˆê¹ŒìŠ¤'] = df['ë©”ë‰´ëª…'].str.contains('ëˆê¹ŒìŠ¤', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ë‹¨ì²´ì‹'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´ì‹', na=False).astype(int)
        df['ì¸ê¸°ë©”ë‰´_ì½œë¼'] = df['ë©”ë‰´ëª…'].str.contains('ì½œë¼', na=False).astype(int)
        
        # 5. ê³„ì ˆ-ë©”ë‰´ ìƒí˜¸ì‘ìš© í”¼ì²˜
        df['ë´„_ë¸ŒëŸ°ì¹˜_ë§¤ì¹˜'] = df['ë´„_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 2).astype(int)
        df['ì—¬ë¦„_ì‹œì›í•¨_ë§¤ì¹˜'] = df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 3).astype(int)
        df['ê°€ì„_ì£¼ë¥˜_ë§¤ì¹˜'] = df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 4).astype(int)
        df['ê²¨ìš¸_ë”°ëœ»í•¨_ë§¤ì¹˜'] = df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 1).astype(int)
        
        # 6. íŠ¹ì´ íŒ¨í„´ í”¼ì²˜
        df['3ì›”_ê¸‰ê°íŒ¨í„´'] = (df['month'] == 3).astype(int)
        df['1ì›”_ìµœê³ íŒ¨í„´'] = (df['month'] == 1).astype(int)
        df['12ì›”_ì—°ë§íŒ¨í„´'] = (df['month'] == 12).astype(int)
        
        # 7. ê³ ê°€ì¤‘ì¹˜ ì˜ì—…ì¥ íŠ¹ë³„ ì²˜ë¦¬
        df['ê³ ê°€ì¤‘ì¹˜_ì˜ì—…ì¥'] = ((df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜') | (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„')).astype(int)
        df['ë‹´í•˜_íŠ¹ë³„ì²˜ë¦¬'] = (df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜').astype(int)
        df['ë¯¸ë¼ì‹œì•„_íŠ¹ë³„ì²˜ë¦¬'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„').astype(int)
        
        # ê³ ê°€ì¤‘ì¹˜ ì˜ì—…ì¥ Ã— ê³„ì ˆ ìƒí˜¸ì‘ìš©
        df['ë‹´í•˜_ê³„ì ˆìƒí˜¸ì‘ìš©'] = df['ë‹´í•˜_íŠ¹ë³„ì²˜ë¦¬'] * df['season']
        df['ë¯¸ë¼ì‹œì•„_ê³„ì ˆìƒí˜¸ì‘ìš©'] = df['ë¯¸ë¼ì‹œì•„_íŠ¹ë³„ì²˜ë¦¬'] * df['season']

    # ì‹œê°„ í”¼ì²˜
    sort_keys = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'] if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else ['ì˜ì—…ì¼ì']
    df = df.sort_values(sort_keys)
    
    if 'ë§¤ì¶œìˆ˜ëŸ‰' in df.columns:
        gb_key = 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else 'ì˜ì—…ì¼ì'
        gb = df.groupby(gb_key)['ë§¤ì¶œìˆ˜ëŸ‰']
        for lag in [1, 2, 3, 7, 14]:
            df[f'lag_{lag}'] = gb.shift(lag)
        for window in [7, 14, 28]:
            df[f'rolling_mean_{window}'] = gb.shift(1).rolling(window).mean()
            df[f'rolling_std_{window}'] = gb.shift(1).rolling(window).std()
    
    # AutoGluonì´ ë‚ ì§œ ê´€ë ¨ í”¼ì²˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ íƒ€ì… ë³€ê²½
    df['month'] = df['month'].astype(str)
    df['day'] = df['day'].astype(str)
    df['week_of_year'] = df['week_of_year'].astype(str)
    df['day_of_week'] = df['day_of_week'].astype(str)
    df['year'] = df['year'].astype(str)
    df['season'] = df['season'].astype(str)

    # ë¶ˆí•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼ ì œê±°
    if 'ë©”ë‰´ëª…' in df.columns:
        df = df.drop(columns=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])

    df = df.fillna(0)
    
    return df

# ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv('./data/train/train.csv')
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)
submission_df = pd.read_csv('./data/sample_submission.csv')

# í”¼ì²˜ ìƒì„±
train_full_featured = create_features(train_df)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
all_predictions = []

# test í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
test_paths = sorted(glob.glob('./data/test/*.csv'))
if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ê° ë©”ë‰´ë³„ë¡œ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
    unique_menus = train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
    
    for menu_name in tqdm(unique_menus, desc="ë©”ë‰´ë³„ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"):
        
        # 1. ë©”ë‰´ë³„ ë°ì´í„° ì¤€ë¹„
        menu_train_data = train_full_featured[train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()
        
        if len(menu_train_data) < 30: # í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„° ìˆ˜
            continue
            
        # AutoGluon í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        train_data_ag = menu_train_data.drop(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'])

        predictor_path = f'autogluon_models/{menu_name.replace("/", "_").replace(" ", "")}'
        # "ìŠ¤ë§ˆíŠ¸í•œ ì´ì–´í•˜ê¸°" ê¸°ëŠ¥: ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµ
        if os.path.exists(predictor_path):
            print(f"âœ… ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ ë°œê²¬: {menu_name}. ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            predictor = TabularPredictor.load(predictor_path)
        else:
            print(f"ğŸš€ ìƒˆë¡œìš´ ëª¨ë¸ í•™ìŠµ ì‹œì‘: {menu_name}")
            predictor = TabularPredictor(
                label='ë§¤ì¶œìˆ˜ëŸ‰',
                path=predictor_path,
                problem_type='regression',
                eval_metric='root_mean_squared_error'
            ).fit(
                train_data_ag,
                presets='best_quality',
                time_limit=180, # ë©”ë‰´ë³„ ìµœëŒ€ í•™ìŠµ ì‹œê°„(ì´ˆ)
                ag_args_fit={'num_gpus': 0}
            )

        # 3. ë©”ë‰´ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ (ìˆœí™˜ ì˜ˆì¸¡)
        for path in test_paths:
            test_file_df = pd.read_csv(path)
            
            if menu_name not in test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique():
                continue

            basename = os.path.basename(path).replace('.csv', '')
            
            # ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° (train + test íŒŒì¼ì˜ ê³¼ê±° ë°ì´í„°)
            historical_data = pd.concat([
                train_full_featured[train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name],
                test_file_df[test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name]
            ]).copy()
            historical_data['ì˜ì—…ì¼ì'] = pd.to_datetime(historical_data['ì˜ì—…ì¼ì'])
            historical_data = historical_data.sort_values(by='ì˜ì—…ì¼ì').tail(28) # ëŒ€íšŒ ê·œì¹™: ìµœê·¼ 28ì¼ ë°ì´í„° ì‚¬ìš©

            # 7ì¼ ì˜ˆì¸¡
            for i in range(7):
                last_date = historical_data['ì˜ì—…ì¼ì'].max()
                next_date = last_date + pd.Timedelta(days=1)
                
                # ì˜ˆì¸¡ì„ ìœ„í•œ ìƒˆë¡œìš´ í–‰ ìƒì„±
                new_row = pd.DataFrame([{'ì˜ì—…ì¼ì': next_date, 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name, 'ë§¤ì¶œìˆ˜ëŸ‰': np.nan}])
                
                # í”¼ì²˜ ìƒì„±ì„ ìœ„í•´ ê³¼ê±° ë°ì´í„°ì™€ í•©ì¹¨
                combined_for_feature = pd.concat([historical_data, new_row], ignore_index=True)
                featured_data = create_features(combined_for_feature)
                
                # ì˜ˆì¸¡í•  ë§ˆì§€ë§‰ í–‰ ì„ íƒ
                X_test = featured_data.tail(1).drop(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰'])
                
                # ì˜ˆì¸¡
                pred = predictor.predict(X_test).iloc[0]
                pred = max(0, pred)
                
                # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                all_predictions.append({
                    'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': pred
                })

                # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì˜ˆì¸¡ê°’ì„ í¬í•¨í•˜ì—¬ historical_data ì—…ë°ì´íŠ¸
                update_row = featured_data.tail(1).copy()
                update_row['ë§¤ì¶œìˆ˜ëŸ‰'] = pred
                historical_data = pd.concat([historical_data, update_row], ignore_index=True)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
if all_predictions:
    pred_df = pd.DataFrame(all_predictions)
    
    print("ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
    
    final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
    final_submission = final_submission.fillna(0)
    
    # ì»¬ëŸ¼ ìˆœì„œë¥¼ ìƒ˜í”Œê³¼ ë™ì¼í•˜ê²Œ ë§ì¶¤
    final_submission = final_submission[submission_df.columns]
    
    final_submission.to_csv('submission_autogluon_per_item.csv', index=False)
    print("submission_autogluon_per_item.csv íŒŒì¼ ìƒì„± ì™„ë£Œ")
else:
    print("ìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

print("\n=== ğŸ† AutoGluon (ë©”ë‰´ë³„ ëª¨ë¸)ì„ ì´ìš©í•œ ìë™í™” ëª¨ë¸ ===")
print("âœ… ê° ë©”ë‰´ë³„ë¡œ ë…ë¦½ì ì¸ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ ì‹œë„")
print("âœ… AutoGluonì´ ìë™ìœ¼ë¡œ ìµœì ì˜ ëª¨ë¸ íƒìƒ‰ ë° ì•™ìƒë¸” ìˆ˜í–‰")
print("\nğŸ¯ ìˆ˜ë£Œ ê¸°ì¤€ ëª©í‘œ:")
print("  â€¢ Public Score â‰¤ 0.711046")
print("  â€¢ Private Score â‰¤ 0.693935")
