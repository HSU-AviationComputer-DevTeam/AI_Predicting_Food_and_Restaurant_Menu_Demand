import os
import glob
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor


# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)


# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)


# í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (TimeSeriesPredictorì— ë§ê²Œ ìˆ˜ì •)
def create_features(df, is_train=True):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    
    # ì‹œê°„ ê´€ë ¨ í”¼ì²˜ (known covariates)
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['day'] = df['ì˜ì—…ì¼ì'].dt.day
    df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    # ì •ì  í”¼ì²˜ (static features) - is_trainì¼ ë•Œë§Œ ìƒì„±
    if is_train and 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].apply(lambda x: '_'.join(x) if x else '')

        # ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
        df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False).astype(int)
        df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
        df['í•œì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False).astype(int)
        df['ì–‘ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False).astype(int)
        df['ë‹¨ì²´ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ë¸ŒëŸ°ì¹˜', na=False).astype(int)
        df['ëŒ€ì—¬ë£Œ'] = df['ë©”ë‰´ëª…'].str.contains('ëŒ€ì—¬ë£Œ|ì´ìš©ë£Œ|conference|convention', na=False, case=False).astype(int)
        
        # ì˜ì—…ì¥ë³„ íŠ¹ì„±
        df['ì˜ì—…ì¥_ì¹´í…Œê³ ë¦¬'] = df['ì˜ì—…ì¥ëª…'].astype('category').cat.codes

        df = df.drop(columns=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])

    # TimeSeriesPredictorëŠ” ë‚´ë¶€ì ìœ¼ë¡œ lag, rolling í”¼ì²˜ë¥¼ ìƒì„±í•˜ë¯€ë¡œ ìˆ˜ë™ ìƒì„± ë¶€ë¶„ ì œê±°
    
    # AutoGluonì´ ë‚ ì§œ ê´€ë ¨ í”¼ì²˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ íƒ€ì… ë³€ê²½
    df['month'] = df['month'].astype(str)
    df['day'] = df['day'].astype(str)
    df['week_of_year'] = df['week_of_year'].astype(str)
    df['day_of_week'] = df['day_of_week'].astype(str)
    df['year'] = df['year'].astype(str)
    df['season'] = df['season'].astype(str)
    
    return df

# ë°ì´í„° ë¡œë“œ
print("ë°ì´í„° ë¡œë”© ì¤‘...")
train_df = pd.read_csv('./data/train/train.csv')
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)
submission_df = pd.read_csv('./data/sample_submission.csv')

# í”¼ì²˜ ìƒì„±
print("í”¼ì²˜ ìƒì„± ì¤‘...")
train_featured = create_features(train_df, is_train=True)

# TimeSeriesDataFrameìœ¼ë¡œ ë³€í™˜
ts_df = TimeSeriesDataFrame.from_data_frame(
    train_featured,
    id_column='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…',
    timestamp_column='ì˜ì—…ì¼ì'
)

# TimeSeriesPredictor í•™ìŠµ
predictor_path = 'autogluon_timeseries_model'
predictor = TimeSeriesPredictor(
    label='ë§¤ì¶œìˆ˜ëŸ‰',
    path=predictor_path,
    prediction_length=7, # 7ì¼ ì˜ˆì¸¡
    eval_metric='RMSE',
    known_covariates_names=[
        'day_of_week', 'is_weekend', 'month', 'day', 
        'week_of_year', 'season', 'is_holiday', 'year'
    ]
)

print("ğŸš€ ìƒˆë¡œìš´ í†µí•© ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
predictor.fit(
    ts_df,
    presets='best_quality',
    time_limit=600, # í•™ìŠµ ì‹œê°„ 600ì´ˆë¡œ ì¦ê°€
    num_gpus=0
)

# ì˜ˆì¸¡
print("ì˜ˆì¸¡ ìƒì„± ì¤‘...")
predictions = predictor.predict(ts_df)

# ì˜ˆì¸¡ ê²°ê³¼ í›„ì²˜ë¦¬
predictions['mean'] = predictions['mean'].clip(lower=0) # ì˜ˆì¸¡ê°’ì´ ìŒìˆ˜ì¼ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬

# ì œì¶œ íŒŒì¼ ìƒì„±
print("ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
pred_df = predictions.reset_index()

# 'TEST_XX+Nì¼' í˜•ì‹ì— ë§ê²Œ ë°ì´í„° ë³€í™˜
test_paths = sorted(glob.glob('./data/test/*.csv'))
if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    all_submission_dfs = []
    
    for path in tqdm(test_paths, desc="Test íŒŒì¼ë³„ ì˜ˆì¸¡ ë³€í™˜"):
        test_file_df = pd.read_csv(path)
        basename = os.path.basename(path).replace('.csv', '')
        
        # í•´ë‹¹ test íŒŒì¼ì— í¬í•¨ëœ ë©”ë‰´ë§Œ í•„í„°ë§
        menus_in_test = test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
        test_preds = pred_df[pred_df['item_id'].isin(menus_in_test)].copy()

        # timestampì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œí•˜ì—¬ ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œ ìƒì„±
        # test íŒŒì¼ì˜ ë§ˆì§€ë§‰ ë‚ ì§œ + 1ì¼ì´ ì˜ˆì¸¡ ì‹œì‘ ë‚ ì§œê°€ ë¨
        test_last_date = pd.to_datetime(test_file_df['ì˜ì—…ì¼ì']).max()
        
        # ì˜ˆì¸¡ ë°ì´í„°ì˜ ë‚ ì§œ ìƒì„±
        test_preds['day_offset'] = test_preds.groupby('item_id').cumcount()
        test_preds['ì˜ì—…ì¼ì_pred'] = test_preds.apply(
            lambda row: test_last_date + pd.Timedelta(days=row['day_offset'] + 1), axis=1
        )
        
        # ì œì¶œ í˜•ì‹ì— ë§ëŠ” 'ì˜ì—…ì¼ì' ì»¬ëŸ¼ ìƒì„±
        test_preds['ì˜ì—…ì¼ì'] = test_preds.apply(lambda row: f"{basename}+{row['day_offset']+1}ì¼", axis=1)
        
        # ì»¬ëŸ¼ëª… ë³€ê²½
        test_preds = test_preds.rename(columns={'item_id': 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'mean': 'ë§¤ì¶œìˆ˜ëŸ‰'})
        
        all_submission_dfs.append(test_preds[['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰']])

    # ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ê²°í•©
    final_pred_df = pd.concat(all_submission_dfs, ignore_index=True)

    # Pivot í…Œì´ë¸” ìƒì„±
    submission_pivot = final_pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()

    # ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„±
    final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
    final_submission = final_submission.fillna(0)
    
    # ì»¬ëŸ¼ ìˆœì„œë¥¼ ìƒ˜í”Œê³¼ ë™ì¼í•˜ê²Œ ë§ì¶¤
    final_submission = final_submission[submission_df.columns]
    
    output_filename = 'submission_autogluon_timeseries.csv'
    final_submission.to_csv(output_filename, index=False)
    print(f"{output_filename} íŒŒì¼ ìƒì„± ì™„ë£Œ")

print("\n=== ğŸ† AutoGluon-TimeSeries (í†µí•© ëª¨ë¸)ì„ ì´ìš©í•œ ìë™í™” ëª¨ë¸ ===")
print("âœ… ëª¨ë“  ë©”ë‰´ë¥¼ í•˜ë‚˜ì˜ ì‹œê³„ì—´ ëª¨ë¸ë¡œ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ ì‹œë„")
print("âœ… AutoGluonì´ ìë™ìœ¼ë¡œ ìµœì ì˜ ì‹œê³„ì—´ ëª¨ë¸ íƒìƒ‰ ë° ì•™ìƒë¸” ìˆ˜í–‰")
print("âœ… í•™ìŠµ ì‹œê°„ 600ì´ˆë¡œ ì¦ê°€, TimeSeriesPredictor í™œìš©")
print("\nğŸ¯ ìˆ˜ë£Œ ê¸°ì¤€ ëª©í‘œ:")
print("  â€¢ Public Score â‰¤ 0.711046")
print("  â€¢ Private Score â‰¤ 0.693935")
