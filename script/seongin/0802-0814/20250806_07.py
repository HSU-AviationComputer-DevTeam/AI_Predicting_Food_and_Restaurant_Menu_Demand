import os
import glob
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)


# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)


# í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± ì¶”ê°€)
def create_features(df):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['day'] = df['ì˜ì—…ì¼ì'].dt.day
    df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    # ì˜ì—…ì¥ëª…ê³¼ ë©”ë‰´ëª… ë¶„ë¦¬
    df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
    df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:]
    df['ë©”ë‰´ëª…'] = df['ë©”ë‰´ëª…'].apply(lambda x: '_'.join(x) if x else '')
    
    # ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ìˆ«ìë¡œ ì¸ì½”ë”©
    df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…_encoded'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].astype('category').cat.codes
    df['ì˜ì—…ì¥ëª…_encoded'] = df['ì˜ì—…ì¥ëª…'].astype('category').cat.codes
    
    # === ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± í”¼ì²˜ ì¶”ê°€ ===
    
    # 1. ê³„ì ˆ íŠ¹í™” ë©”ë‰´ ë¶„ë¥˜
    df['ë´„_íŠ¹í™”ë©”ë‰´'] = 0
    df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] = 0
    df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] = 0
    df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] = 0
    
    # ë´„ íŠ¹í™” (ë¸ŒëŸ°ì¹˜, ìƒëŸ¬ë“œ, ì‹ ì„ í•œ ìš”ë¦¬)
    spring_keywords = ['ë¸ŒëŸ°ì¹˜', 'ìƒëŸ¬ë“œ', 'ë¦¬ì¡°ë˜', 'ê·¸ë¦´ë“œ', 'ì‹œì €']
    df['ë´„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(spring_keywords), na=False).astype(int)
    
    # ì—¬ë¦„ íŠ¹í™” (ì°¨ê°€ìš´ ìŒë£Œ, í•´ì‚°ë¬¼, ì‹œì›í•œ ìš”ë¦¬)
    summer_keywords = ['ice', 'ì•„ì´ìŠ¤', 'ì—ì´ë“œ', 'ì‹í˜œ', 'ìƒìˆ˜', 'ëƒ‰ë©´', 'í•´ë¬¼', 'ëìŠ¤íƒ€', 'ì‰¬ë¦¼í”„', 'í•´ì‚°ë¬¼']
    df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(summer_keywords), na=False, case=False).astype(int)
    
    # ê°€ì„ íŠ¹í™” (ë”°ëœ»í•œ ì£¼ë¥˜)
    fall_keywords = ['ë§‰ê±¸ë¦¬', 'ì†Œì£¼', 'ë§¥ì£¼', 'ì°¸ì´ìŠ¬', 'ì¹´ìŠ¤', 'beer']
    df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(fall_keywords), na=False, case=False).astype(int)
    
    # ê²¨ìš¸ íŠ¹í™” (ëœ¨ê±°ìš´ êµ­ë¬¼, ë³´ì–‘ì‹)
    winter_keywords = ['êµ­', 'íƒ•', 'ì°Œê°œ', 'í•´ì¥', 'hot', 'í•«ë„ê·¸', 'ë–¡ë³¶ì´', 'ê¼¬ì¹˜ì–´ë¬µ', 'íŒŒì „', 'ë¶ˆê³ ê¸°', 'ê°ˆë¹„', 'ëˆê¹ŒìŠ¤', 'bbq', 'í•œìš°', 'ì‚¼ê²¹']
    df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(winter_keywords), na=False, case=False).astype(int)
    
    # 2. ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
    df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False).astype(int)
    df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
    df['í•œì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False).astype(int)
    df['ì–‘ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False).astype(int)
    df['ë‹¨ì²´ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ë¸ŒëŸ°ì¹˜', na=False).astype(int)
    df['ëŒ€ì—¬ë£Œ'] = df['ë©”ë‰´ëª…'].str.contains('ëŒ€ì—¬ë£Œ|ì´ìš©ë£Œ|conference|convention', na=False, case=False).astype(int)
    
    # 3. ì˜ì—…ì¥ë³„ íŠ¹ì„±
    df['í¬ë ˆìŠ¤íŠ¸ë¦¿'] = (df['ì˜ì—…ì¥ëª…'] == 'í¬ë ˆìŠ¤íŠ¸ë¦¿').astype(int)
    df['ì¹´í˜í…Œë¦¬ì•„'] = (df['ì˜ì—…ì¥ëª…'] == 'ì¹´í˜í…Œë¦¬ì•„').astype(int)
    df['í™”ë‹´ìˆ²ì£¼ë§‰'] = (df['ì˜ì—…ì¥ëª…'] == 'í™”ë‹´ìˆ²ì£¼ë§‰').astype(int)
    df['ë‹´í•˜'] = (df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜').astype(int)
    df['ë¯¸ë¼ì‹œì•„'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„').astype(int)
    df['ëŠí‹°ë‚˜ë¬´'] = (df['ì˜ì—…ì¥ëª…'] == 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ').astype(int)
    df['ë¼ê·¸ë¡œíƒ€'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¼ê·¸ë¡œíƒ€').astype(int)
    df['ì—°íšŒì¥'] = (df['ì˜ì—…ì¥ëª…'] == 'ì—°íšŒì¥').astype(int)
    df['í™”ë‹´ìˆ²ì¹´í˜'] = (df['ì˜ì—…ì¥ëª…'] == 'í™”ë‹´ìˆ²ì¹´í˜').astype(int)
    
    # 4. ì¸ê¸° ë©”ë‰´ TOP 10 íŠ¹ë³„ ì²˜ë¦¬
    df['ì¸ê¸°ë©”ë‰´_ê¼¬ì¹˜ì–´ë¬µ'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_í•´ë¬¼íŒŒì „'] = df['ë©”ë‰´ëª…'].str.contains('í•´ë¬¼íŒŒì „', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ë–¡ë³¶ì´'] = df['ë©”ë‰´ëª…'].str.contains('ë–¡ë³¶ì´', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ìƒìˆ˜'] = df['ë©”ë‰´ëª…'].str.contains('ìƒìˆ˜', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ì•„ë©”ë¦¬ì¹´ë…¸'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ì¹˜ì¦ˆí•«ë„ê·¸'] = df['ë©”ë‰´ëª…'].str.contains('ì¹˜ì¦ˆ í•«ë„ê·¸', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ëˆê¹ŒìŠ¤'] = df['ë©”ë‰´ëª…'].str.contains('ëˆê¹ŒìŠ¤', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ë‹¨ì²´ì‹'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´ì‹', na=False).astype(int)
    df['ì¸ê¸°ë©”ë‰´_ì½œë¼'] = df['ë©”ë‰´ëª…'].str.contains('ì½œë¼', na=False).astype(int)
    
    # 5. ê³„ì ˆ-ë©”ë‰´ ìƒí˜¸ì‘ìš© í”¼ì²˜
    df['ë´„_ë¸ŒëŸ°ì¹˜_ë§¤ì¹˜'] = df['ë´„_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 2).astype(int)  # ë´„(3-5ì›”)ì´ season 2
    df['ì—¬ë¦„_ì‹œì›í•¨_ë§¤ì¹˜'] = df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 3).astype(int)  # ì—¬ë¦„(6-8ì›”)ì´ season 3
    df['ê°€ì„_ì£¼ë¥˜_ë§¤ì¹˜'] = df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 4).astype(int)  # ê°€ì„(9-11ì›”)ì´ season 4
    df['ê²¨ìš¸_ë”°ëœ»í•¨_ë§¤ì¹˜'] = df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] * (df['season'] == 1).astype(int)  # ê²¨ìš¸(12-2ì›”)ì´ season 1
    
    # 6. íŠ¹ì´ íŒ¨í„´ í”¼ì²˜ (3ì›” ê¸‰ê°, 1ì›” ìµœê³ )
    df['3ì›”_ê¸‰ê°íŒ¨í„´'] = (df['month'] == 3).astype(int)
    df['1ì›”_ìµœê³ íŒ¨í„´'] = (df['month'] == 1).astype(int)
    df['12ì›”_ì—°ë§íŒ¨í„´'] = (df['month'] == 12).astype(int)
    
    # 7. ê³ ê°€ì¤‘ì¹˜ ì˜ì—…ì¥ íŠ¹ë³„ ì²˜ë¦¬ (ë‹´í•˜, ë¯¸ë¼ì‹œì•„)
    df['ê³ ê°€ì¤‘ì¹˜_ì˜ì—…ì¥'] = ((df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜') | (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„')).astype(int)
    df['ë‹´í•˜_íŠ¹ë³„ì²˜ë¦¬'] = (df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜').astype(int)
    df['ë¯¸ë¼ì‹œì•„_íŠ¹ë³„ì²˜ë¦¬'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„').astype(int)
    
    # ê³ ê°€ì¤‘ì¹˜ ì˜ì—…ì¥ Ã— ê³„ì ˆ ìƒí˜¸ì‘ìš©
    df['ë‹´í•˜_ê³„ì ˆìƒí˜¸ì‘ìš©'] = df['ë‹´í•˜_íŠ¹ë³„ì²˜ë¦¬'] * df['season']
    df['ë¯¸ë¼ì‹œì•„_ê³„ì ˆìƒí˜¸ì‘ìš©'] = df['ë¯¸ë¼ì‹œì•„_íŠ¹ë³„ì²˜ë¦¬'] * df['season']
    
    # 7. ì‹œê°„ í”¼ì²˜
    df = df.sort_values(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'])
    for lag in [1, 2, 3, 7, 14]:
        df[f'lag_{lag}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].shift(lag)
    for window in [7, 14, 28]:
        df[f'rolling_mean_{window}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].shift(1).rolling(window).mean()
        df[f'rolling_std_{window}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].shift(1).rolling(window).std()
    
    # NaN ê°’ ì²˜ë¦¬
    df = df.fillna(0)
    
    return df


# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
train = pd.read_csv('./data/train/train.csv')
train['ë§¤ì¶œìˆ˜ëŸ‰'] = train['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)

# í”¼ì²˜ ìƒì„±
train_xgb = create_features(train)

# í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
features = [
    # ê¸°ë³¸ ì‹œê°„ í”¼ì²˜
    'day_of_week', 'is_weekend', 'month', 'day', 'week_of_year', 
    'season', 'is_holiday', 'year', 
    
    # ì¸ì½”ë”©ëœ ë²”ì£¼í˜• í”¼ì²˜
    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…_encoded', 'ì˜ì—…ì¥ëª…_encoded',
    
    # ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± í”¼ì²˜
    'ë´„_íŠ¹í™”ë©”ë‰´', 'ì—¬ë¦„_íŠ¹í™”ë©”ë‰´', 'ê°€ì„_íŠ¹í™”ë©”ë‰´', 'ê²¨ìš¸_íŠ¹í™”ë©”ë‰´',
    
    # ë©”ë‰´ ì¹´í…Œê³ ë¦¬ í”¼ì²˜
    'ë¶„ì‹ë¥˜', 'ìŒë£Œë¥˜', 'ì£¼ë¥˜', 'í•œì‹ë¥˜', 'ì–‘ì‹ë¥˜', 'ë‹¨ì²´ë©”ë‰´', 'ëŒ€ì—¬ë£Œ',
    
    # ì˜ì—…ì¥ë³„ íŠ¹ì„± í”¼ì²˜
    'í¬ë ˆìŠ¤íŠ¸ë¦¿', 'ì¹´í˜í…Œë¦¬ì•„', 'í™”ë‹´ìˆ²ì£¼ë§‰', 'ë‹´í•˜', 'ë¯¸ë¼ì‹œì•„', 'ëŠí‹°ë‚˜ë¬´', 'ë¼ê·¸ë¡œíƒ€', 'ì—°íšŒì¥', 'í™”ë‹´ìˆ²ì¹´í˜',
    
    # ì¸ê¸° ë©”ë‰´ TOP 10 í”¼ì²˜
    'ì¸ê¸°ë©”ë‰´_ê¼¬ì¹˜ì–´ë¬µ', 'ì¸ê¸°ë©”ë‰´_í•´ë¬¼íŒŒì „', 'ì¸ê¸°ë©”ë‰´_ë–¡ë³¶ì´', 'ì¸ê¸°ë©”ë‰´_ìƒìˆ˜', 'ì¸ê¸°ë©”ë‰´_ì•„ë©”ë¦¬ì¹´ë…¸',
    'ì¸ê¸°ë©”ë‰´_ì¹˜ì¦ˆí•«ë„ê·¸', 'ì¸ê¸°ë©”ë‰´_ëˆê¹ŒìŠ¤', 'ì¸ê¸°ë©”ë‰´_ë‹¨ì²´ì‹', 'ì¸ê¸°ë©”ë‰´_ì½œë¼',
    
    # ê³„ì ˆ-ë©”ë‰´ ìƒí˜¸ì‘ìš© í”¼ì²˜
    'ë´„_ë¸ŒëŸ°ì¹˜_ë§¤ì¹˜', 'ì—¬ë¦„_ì‹œì›í•¨_ë§¤ì¹˜', 'ê°€ì„_ì£¼ë¥˜_ë§¤ì¹˜', 'ê²¨ìš¸_ë”°ëœ»í•¨_ë§¤ì¹˜',
    
    # íŠ¹ì´ íŒ¨í„´ í”¼ì²˜
    '3ì›”_ê¸‰ê°íŒ¨í„´', '1ì›”_ìµœê³ íŒ¨í„´', '12ì›”_ì—°ë§íŒ¨í„´',
    
    # ê³ ê°€ì¤‘ì¹˜ ì˜ì—…ì¥ íŠ¹ë³„ ì²˜ë¦¬ í”¼ì²˜
    'ê³ ê°€ì¤‘ì¹˜_ì˜ì—…ì¥', 'ë‹´í•˜_íŠ¹ë³„ì²˜ë¦¬', 'ë¯¸ë¼ì‹œì•„_íŠ¹ë³„ì²˜ë¦¬', 'ë‹´í•˜_ê³„ì ˆìƒí˜¸ì‘ìš©', 'ë¯¸ë¼ì‹œì•„_ê³„ì ˆìƒí˜¸ì‘ìš©'
    
] + [f'lag_{lag}' for lag in [1, 2, 3, 7, 14]] + \
    [f'rolling_mean_{window}' for window in [7, 14, 28]] + \
    [f'rolling_std_{window}' for window in [7, 14, 28]]

X = train_xgb[features]
y = train_xgb['ë§¤ì¶œìˆ˜ëŸ‰']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)


# XGBoost ëª¨ë¸ í•™ìŠµ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
xgb_params_list = [
    {'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.1},
    {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.05},
    {'n_estimators': 400, 'max_depth': 5, 'learning_rate': 0.07},
]

best_mse = float('inf')
best_xgb_params = None
best_xgb_model = None

for params in tqdm(xgb_params_list, desc="XGBoost H-param Tuning"):
    model = xgb.XGBRegressor(
        **params,
        objective='reg:squarederror',
        eval_metric='rmse',
        random_state=42,
        n_jobs=-1
    )
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_val, y_val)],
        verbose=False
    )
    
    preds_val = model.predict(X_val)
    mse = mean_squared_error(y_val, preds_val)
    print(f"\n[XGBoost Params {params}] Validation MSE: {mse:.4f}")
    
    if mse < best_mse:
        best_mse = mse
        best_xgb_params = params
        best_xgb_model = model

print(f"\nBest XGBoost Params: {best_xgb_params}")

# ìµœì  XGBoost ëª¨ë¸ ì €ì¥
os.makedirs("models", exist_ok=True)
best_xgb_model.save_model("models/best_xgboost_model.json")
print("XGBoost ìµœì  ëª¨ë¸ ì €ì¥ ì™„ë£Œ")


# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ (28ì¼ ì œí•œ ê·œì¹™ ì¤€ìˆ˜)
submission_df = pd.read_csv('./data/sample_submission.csv')

# test í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
test_paths = sorted(glob.glob('./data/test/*.csv'))
if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    all_predictions = []
    
    for path in test_paths:
        test_df = pd.read_csv(path)
        test_df = create_features(test_df)
        
        basename = os.path.basename(path).replace('.csv', '')
        
        # ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì—ì„œ í•„ìš”í•œ ëª¨ë“  ë©”ë‰´ ê°€ì ¸ì˜¤ê¸°
        required_menus = list(submission_df.columns[1:])  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ì˜ì—…ì¼ì
        
        print(f"ì²˜ë¦¬ ì¤‘: {basename}, í•„ìš”í•œ ë©”ë‰´ ìˆ˜: {len(required_menus)}")
        
        # ê° ë©”ë‰´ì— ëŒ€í•´ ì˜ˆì¸¡
        processed_menus = 0
        for menu_name in required_menus:
            menu_data = test_df[test_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()
            
            if len(menu_data) == 0:
                # í•´ë‹¹ ë©”ë‰´ì˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                for i in range(7):
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': 0.0
                    })
                continue
            
            # ë©”ë‰´ë³„ë¡œ ìµœê·¼ 28ì¼ ë°ì´í„°ë§Œ ì‚¬ìš© (ëŒ€íšŒ ê·œì¹™ ì¤€ìˆ˜)
            menu_data = menu_data.tail(28).copy()
            
            # 7ì¼ ì˜ˆì¸¡
            prediction_data = menu_data.copy()
            
            for i in range(7):
                if len(prediction_data) > 0:
                    # ìµœê·¼ ë°ì´í„°ë¡œ í”¼ì²˜ ìƒì„±
                    try:
                        X_test = prediction_data[features].tail(1)
                        
                        # ì˜ˆì¸¡
                        pred = best_xgb_model.predict(X_test)[0]
                        pred = max(0, pred)  # ìŒìˆ˜ ì œê±°
                    except:
                        # í”¼ì²˜ ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                        pred = 0.0
                    
                    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': pred
                    })
                    
                    # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ë°ì´í„° ì—…ë°ì´íŠ¸
                    next_date = prediction_data['ì˜ì—…ì¼ì'].max() + pd.Timedelta(days=1)
                    new_row = prediction_data.iloc[-1:].copy()
                    new_row['ì˜ì—…ì¼ì'] = next_date
                    new_row['ë§¤ì¶œìˆ˜ëŸ‰'] = pred
                    
                    # ë°ì´í„° ì¶”ê°€ ë° í¬ê¸° ì œí•œ (28ì¼ + ì˜ˆì¸¡ì¼ìˆ˜)
                    prediction_data = pd.concat([prediction_data, new_row], ignore_index=True)
                    if len(prediction_data) > 35:  # 28 + 7 ì—¬ìœ ë¶„
                        prediction_data = prediction_data.tail(35)
                    
                    # í”¼ì²˜ ë‹¤ì‹œ ìƒì„±
                    try:
                        prediction_data = create_features(prediction_data)
                    except:
                        # í”¼ì²˜ ìƒì„± ë¬¸ì œê°€ ìˆëŠ” ê²½ìš° ê¸°ì¡´ ë°ì´í„° ìœ ì§€
                        pass
                else:
                    # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì˜ˆì¸¡
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': 0.0
                    })
            
            processed_menus += 1
            
        print(f"  ì²˜ë¦¬ëœ ë©”ë‰´ ìˆ˜: {processed_menus}/{len(required_menus)}")
    
    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    pred_df = pd.DataFrame(all_predictions)
    
    # ì œì¶œ íŒŒì¼ ìƒì„± (ëª¨ë“  ë©”ë‰´ì— ëŒ€í•´ ì˜ˆì¸¡ê°’ ì±„ìš°ê¸°)
    print("ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    print(f"ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„° ê°œìˆ˜: {len(pred_df)}")
    print(f"ìƒ˜í”Œ ì œì¶œ íŒŒì¼ í–‰ ìˆ˜: {len(submission_df)}")
    
    filled_count = 0
    for idx, row in submission_df.iterrows():
        date = row['ì˜ì—…ì¼ì']
        for col in submission_df.columns[1:]:  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ ì˜ì—…ì¼ì
            matching_pred = pred_df[(pred_df['ì˜ì—…ì¼ì'] == date) & (pred_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == col)]
            if not matching_pred.empty:
                submission_df.at[idx, col] = float(matching_pred['ë§¤ì¶œìˆ˜ëŸ‰'].iloc[0])
                filled_count += 1
            else:
                # ë§¤ì¹­ë˜ëŠ” ì˜ˆì¸¡ì´ ì—†ëŠ” ê²½ìš°, í•´ë‹¹ ë©”ë‰´ì˜ í‰ê· ê°’ì´ë‚˜ 0 ì‚¬ìš©
                submission_df.at[idx, col] = 0.0
    
    print(f"ì´ ì±„ì›Œì§„ ì˜ˆì¸¡ê°’ ê°œìˆ˜: {filled_count}")
    
    # ê° ì—´(ë©”ë‰´)ë³„ë¡œ 0ì´ ì•„ë‹Œ ê°’ì˜ ê°œìˆ˜ í™•ì¸
    non_zero_counts = {}
    for col in submission_df.columns[1:]:
        non_zero_count = (submission_df[col] != 0).sum()
        if non_zero_count > 0:
            non_zero_counts[col] = non_zero_count
    
    print(f"0ì´ ì•„ë‹Œ ì˜ˆì¸¡ê°’ì„ ê°€ì§„ ë©”ë‰´ ìˆ˜: {len(non_zero_counts)}")
    if len(non_zero_counts) > 0:
        print("ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ë©”ë‰´ë“¤:")
        for menu, count in list(non_zero_counts.items())[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"  {menu}: {count}ê°œ ì˜ˆì¸¡ê°’")
        if len(non_zero_counts) > 10:
            print(f"  ... ë° {len(non_zero_counts) - 10}ê°œ ë©”ë‰´ ë”")


submission_df.to_csv('submission_xgboost_competition_compliant.csv', index=False)
print("submission_xgboost_competition_compliant.csv íŒŒì¼ ìƒì„± ì™„ë£Œ")
print("\n=== ğŸ† ëŒ€íšŒ ê·œì¹™ ì¤€ìˆ˜ + ê³ ê¸‰ í”¼ì²˜ XGBoost ëª¨ë¸ ===")
print("âœ… ëŒ€íšŒ ê·œì¹™ ì¤€ìˆ˜:")
print("  â€¢ 28ì¼ ë°ì´í„° ì œí•œ ê·œì¹™ ì ìš©")
print("  â€¢ ì‹œê³„ì—´ Data Leakage ë°©ì§€")
print("  â€¢ ë…ë¦½ì  ì¶”ë¡  ìˆ˜í–‰")
print("\nğŸ“Š ì¶”ê°€ëœ ê³ ê¸‰ í”¼ì²˜:")
print("  â€¢ ê³„ì ˆë³„ ë©”ë‰´ íŠ¹í™” ë¶„ë¥˜ (ë´„/ì—¬ë¦„/ê°€ì„/ê²¨ìš¸)")
print("  â€¢ ë©”ë‰´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ë¶„ì‹/ìŒë£Œ/ì£¼ë¥˜/í•œì‹/ì–‘ì‹/ë‹¨ì²´/ëŒ€ì—¬)")
print("  â€¢ ì˜ì—…ì¥ë³„ ì›í•« ì¸ì½”ë”©")
print("  â€¢ ì¸ê¸° ë©”ë‰´ TOP 10 íŠ¹ë³„ ì²˜ë¦¬")
print("  â€¢ ê³„ì ˆ-ë©”ë‰´ ìƒí˜¸ì‘ìš© í”¼ì²˜")
print("  â€¢ íŠ¹ì´ íŒ¨í„´ í”¼ì²˜ (3ì›” ê¸‰ê°, 1ì›” ìµœê³ , 12ì›” ì—°ë§)")
print("  â€¢ ğŸ¯ ê³ ê°€ì¤‘ì¹˜ ì˜ì—…ì¥ íŠ¹ë³„ ì²˜ë¦¬ (ë‹´í•˜, ë¯¸ë¼ì‹œì•„)")
print(f"  â€¢ ì´ í”¼ì²˜ ìˆ˜: {len(features)}ê°œ")
print("\nğŸ¯ ìˆ˜ë£Œ ê¸°ì¤€ ëª©í‘œ:")
print("  â€¢ Public Score â‰¤ 0.711046")
print("  â€¢ Private Score â‰¤ 0.693935")