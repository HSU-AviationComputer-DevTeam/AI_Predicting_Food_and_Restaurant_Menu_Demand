import os
import glob
import random
import shutil
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor
# make_scorerëŠ” TimeSeriesPredictorì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°
# from autogluon.core.metrics import make_scorer

# Prophet (ì˜µì…˜): ë¯¸ì„¤ì¹˜ ì‹œ ìë™ ë¹„í™œì„±í™”
try:
    from prophet import Prophet
except Exception:
    Prophet = None

# Prophet ê°€ì¤‘ì¹˜ (ìµœì¢… ì•™ìƒë¸”: final = (1-w)*AG + w*Prophet) - TimeSeriesPredictorì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# PROPHET_WEIGHT = 0.2
ANALYSIS_PATH = 'autogluon_analysis'
PREDICTION_LENGTH = 7  # ì˜ˆì¸¡ ê¸°ê°„


# TimeSeriesPredictorëŠ” ë‚´ì¥ sMAPEë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì‚¬ìš©ì ì •ì˜ í•¨ìˆ˜ ë¶ˆí•„ìš”
# # DACON ëŒ€íšŒìš© SMAPE í‰ê°€ ì§€í‘œ ì •ì˜
# def smape_metric(y_true, y_pred):
#     y_true = np.array(y_true)
#     y_pred = np.array(y_pred)
#     
#     # ëŒ€íšŒ ê·œì¹™: ì‹¤ì œ ë§¤ì¶œ ìˆ˜ëŸ‰ì´ 0ì¸ ê²½ìš°ëŠ” í‰ê°€ì—ì„œ ì œì™¸
#     mask = y_true != 0
#     
#     # ëª¨ë“  ì‹¤ì œ ê°’ì´ 0ì¸ ê²½ìš°, SMAPEëŠ” 0ìœ¼ë¡œ ì •ì˜
#     if not np.any(mask):
#         return 0.0
#
#     y_true = y_true[mask]
#     y_pred = y_pred[mask]
#     
#     # SMAPE ê³„ì‚°
#     numerator = np.abs(y_pred - y_true)
#     denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
#     
#     # ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€ (ì•ˆì „ì¥ì¹˜ë¡œ ë¶„ëª¨ê°€ 0ì´ë©´ ê²°ê³¼ëŠ” 0)
#     ratio = np.where(denominator == 0, 0, numerator / denominator)
#     
#     return np.mean(ratio) * 100
#
# # AutoGluonìš© Scorer ìƒì„±
# # ëŒ€íšŒì˜ ê°€ì¤‘ì¹˜ SMAPEëŠ” ë¹„ê³µê°œì´ë¯€ë¡œ, ì¼ë°˜ SMAPEë¡œ ê²€ì¦ ì ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
# smape_scorer = make_scorer(name='smape',
#                            score_func=smape_metric,
#                            optimum=0,
#                            greater_is_better=False)


# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)


# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)


def build_prophet_holidays_df():
    hd = pd.DataFrame({
        'holiday': 'kr_holiday',
        'ds': holiday_dates
    })
    return hd

# Prophetì„ í™œìš©í•œ í”¼ì²˜ ìƒì„± í•¨ìˆ˜
def create_prophet_features_and_models(df: pd.DataFrame) -> (pd.DataFrame, dict):
    if Prophet is None:
        return pd.DataFrame(), {}

    all_prophet_features = []
    prophet_models = {}
    unique_menus = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()

    for menu_name in tqdm(unique_menus, desc="Prophet í”¼ì²˜ ìƒì„± ë° ëª¨ë¸ í•™ìŠµ", leave=False):
        menu_df = df[df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()
        menu_df['ì˜ì—…ì¼ì'] = pd.to_datetime(menu_df['ì˜ì—…ì¼ì'])
        
        if len(menu_df) < 30:
            continue

        # Prophet ëª¨ë¸ í•™ìŠµ
        prophet_df = pd.DataFrame({
            'ds': menu_df['ì˜ì—…ì¼ì'],
            'y': np.log1p(menu_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))
        })
        
        try:
            m = Prophet(
                yearly_seasonality=True,
                weekly_seasonality=True,
                daily_seasonality=False,
                changepoint_prior_scale=0.1,
                seasonality_prior_scale=10.0,
                holidays=build_prophet_holidays_df()
            )
            m.fit(prophet_df)
            prophet_models[menu_name] = m  # í•™ìŠµëœ ëª¨ë¸ ì €ì¥

            # í•™ìŠµ ë°ì´í„° ê¸°ê°„ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ìƒì„±
            forecast = m.predict(prophet_df[['ds']])
            forecast = forecast[['ds', 'yhat', 'trend']].rename(columns={
                'ds': 'ì˜ì—…ì¼ì',
                'yhat': 'prophet_yhat',
                'trend': 'prophet_trend'
            })
            forecast['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] = menu_name
            all_prophet_features.append(forecast)

        except Exception as e:
            print(f"Prophet í”¼ì²˜ ìƒì„± ì¤‘ '{menu_name}' ë©”ë‰´ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if not all_prophet_features:
        return pd.DataFrame(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'prophet_yhat', 'prophet_trend']), {}

    result_df = pd.concat(all_prophet_features, ignore_index=True)
    result_df['prophet_yhat'] = np.expm1(result_df['prophet_yhat']).clip(lower=0)
    return result_df, prophet_models


# ë‹¬ë ¥ ê¸°ë°˜ í”¼ì²˜ ìƒì„± í•¨ìˆ˜
def create_calendar_features(df, menu_launch_dates=None):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    # ì¶œì‹œ ëŒ€ë¹„ ê²½ê³¼ì¼
    if menu_launch_dates is not None:
        # ì˜ˆì¸¡ ì‹œ: ë¯¸ë¦¬ ê³„ì‚°ëœ ì¶œì‹œì¼ ì •ë³´ë¥¼ ì‚¬ìš©
        df['min_date'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].map(menu_launch_dates)
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - df['min_date']).dt.days.fillna(0).astype(int)
        df = df.drop(columns=['min_date'])
    else:
        # í•™ìŠµ ì‹œ: ë°ì´í„°ì—ì„œ ì§ì ‘ ê³„ì‚°
        min_date_by_menu = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ì˜ì—…ì¼ì'].transform('min')
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - min_date_by_menu).dt.days

    # [ìˆ˜ì •] RecursiveTabular ëª¨ë¸ì˜ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ëª…ì‹œì  category ë³€í™˜ì„ ì œê±°í•©ë‹ˆë‹¤.
    # AutoGluonì´ ë‚´ë¶€ì ìœ¼ë¡œ íƒ€ì…ì„ ì¶”ë¡ í•˜ê³  ì²˜ë¦¬í•˜ë„ë¡ ë§¡ê¹ë‹ˆë‹¤.
    # for col in ['day_of_week', 'month', 'year', 'season']:
    #     df[col] = df[col].astype('category')

    return df

def create_advanced_calendar_features(df, menu_launch_dates=None):
    """ê³ ê¸‰ ë‹¬ë ¥ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    
    # ê¸°ë³¸ í”¼ì²˜
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year
    
    # ì‚¼ê°í•¨ìˆ˜ í”¼ì²˜ (ê³„ì ˆì„± ê°•í™”)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
    
    # ì›”ë³„ íŠ¹ì„±
    df['is_month_start'] = df['ì˜ì—…ì¼ì'].dt.is_month_start.astype(int)
    df['is_month_end'] = df['ì˜ì—…ì¼ì'].dt.is_month_end.astype(int)
    df['is_quarter_start'] = df['ì˜ì—…ì¼ì'].dt.is_quarter_start.astype(int)
    df['is_quarter_end'] = df['ì˜ì—…ì¼ì'].dt.is_quarter_end.astype(int)
    
    # ê¸‰ì—¬ì¼ ê·¼ì ‘ë„ (15ì¼, 25ì¼)
    df['days_to_payday'] = np.minimum(
        abs(df['ì˜ì—…ì¼ì'].dt.day - 15),
        abs(df['ì˜ì—…ì¼ì'].dt.day - 25)
    )
    df['is_near_payday'] = (df['days_to_payday'] <= 3).astype(int)
    
    # ê³µíœ´ì¼ ì „í›„
    df['days_to_holiday'] = df['ì˜ì—…ì¼ì'].apply(lambda x: 
        min([abs((x - h).days) for h in holiday_dates])
    )
    df['is_holiday_eve'] = (df['days_to_holiday'] == 1).astype(int)
    df['is_holiday_after'] = (df['days_to_holiday'] == 1).astype(int)
    
    # ì¶œì‹œ ëŒ€ë¹„ ê²½ê³¼ì¼
    if menu_launch_dates is not None:
        df['min_date'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].map(menu_launch_dates)
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - df['min_date']).dt.days.fillna(0).astype(int)
        df = df.drop(columns=['min_date'])
    else:
        min_date_by_menu = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ì˜ì—…ì¼ì'].transform('min')
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - min_date_by_menu).dt.days

    return df

def create_advanced_features(df):
    """ê³ ê¸‰ í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    
    # ì‚¼ê°í•¨ìˆ˜ í”¼ì²˜ (ê³„ì ˆì„± ê°•í™”)
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
    
    # ì›”ë³„ íŠ¹ì„±
    df['is_month_start'] = df['ì˜ì—…ì¼ì'].dt.is_month_start.astype(int)
    df['is_month_end'] = df['ì˜ì—…ì¼ì'].dt.is_month_end.astype(int)
    df['is_quarter_start'] = df['ì˜ì—…ì¼ì'].dt.is_quarter_start.astype(int)
    df['is_quarter_end'] = df['ì˜ì—…ì¼ì'].dt.is_quarter_end.astype(int)
    
    # ê¸‰ì—¬ì¼ ê·¼ì ‘ë„ (15ì¼, 25ì¼)
    df['days_to_payday'] = np.minimum(
        abs(df['ì˜ì—…ì¼ì'].dt.day - 15),
        abs(df['ì˜ì—…ì¼ì'].dt.day - 25)
    )
    df['is_near_payday'] = (df['days_to_payday'] <= 3).astype(int)
    
    # ê³µíœ´ì¼ ì „í›„
    df['days_to_holiday'] = df['ì˜ì—…ì¼ì'].apply(lambda x: 
        min([abs((x - h).days) for h in holiday_dates])
    )
    df['is_holiday_eve'] = (df['days_to_holiday'] == 1).astype(int)
    df['is_holiday_after'] = (df['days_to_holiday'] == 1).astype(int)
    
    return df

def create_lag_features(df):
    """ì‹œê³„ì—´ Lag í”¼ì²˜ ìƒì„±"""
    df = df.copy()
    df = df.sort_values(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'])
    
    # Lag í”¼ì²˜ (1, 7, 14, 21, 28ì¼)
    for lag in [1, 7, 14, 21, 28]:
        df[f'lag_{lag}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].shift(lag)
    
    # Rolling í†µê³„ (7, 14, 28ì¼)
    for window in [7, 14, 28]:
        df[f'rolling_mean_{window}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window, min_periods=1).mean().reset_index(0, drop=True)
        df[f'rolling_std_{window}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window, min_periods=1).std().reset_index(0, drop=True)
        df[f'rolling_min_{window}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window, min_periods=1).min().reset_index(0, drop=True)
        df[f'rolling_max_{window}'] = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰'].rolling(window, min_periods=1).max().reset_index(0, drop=True)
    
    return df


def make_regular_time_series(df: pd.DataFrame) -> pd.DataFrame:
    """ê° ë©”ë‰´ë³„ë¡œ ë¹ ì§„ ë‚ ì§œë¥¼ ì±„ì›Œë„£ì–´ ì‹œê³„ì—´ì„ ì •ê·œí™”í•©ë‹ˆë‹¤."""
    regularized_dfs = []
    
    # ì „ì²´ ë°ì´í„°ì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ ì°¾ê¸°
    overall_min_date = df['ì˜ì—…ì¼ì'].min()
    overall_max_date = df['ì˜ì—…ì¼ì'].max()

    for menu_name, menu_df in tqdm(df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'), desc="ë°ì´í„° ì •ê·œí™” (ì¼ë³„)", leave=False):
        # ë©”ë‰´ë³„ ì‹œì‘ì¼/ì¢…ë£Œì¼ì´ ì•„ë‹Œ, ê·¸ë£¹ ì „ì²´ì˜ ì‹œì‘/ì¢…ë£Œì¼ì„ ì‚¬ìš©í•´ì•¼
        # ë‚˜ì¤‘ì— concatí•  ë•Œ ë‚ ì§œ ì¸ë±ìŠ¤ê°€ ì¼ì •í•˜ê²Œ ìœ ì§€ë¨
        
        all_dates = pd.date_range(start=menu_df['ì˜ì—…ì¼ì'].min(), end=overall_max_date, freq='D')
        
        regular_df = pd.DataFrame({'ì˜ì—…ì¼ì': all_dates})
        regular_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] = menu_name
        
        merged_df = pd.merge(regular_df, menu_df, on=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'], how='left')
        merged_df['ë§¤ì¶œìˆ˜ëŸ‰'] = merged_df['ë§¤ì¶œìˆ˜ëŸ‰'].fillna(0)
        
        regularized_dfs.append(merged_df)
        
    return pd.concat(regularized_dfs, ignore_index=True)


# ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv('./data/train/train.csv')
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)
train_df['ì˜ì—…ì¼ì'] = pd.to_datetime(train_df['ì˜ì—…ì¼ì'])
submission_df = pd.read_csv('./data/sample_submission.csv')

# [ìˆ˜ì •] ë¶ˆê·œì¹™í•œ ì‹œê³„ì—´ì„ ê·œì¹™ì ì¸ ì¼ë³„ ì‹œê³„ì—´ë¡œ ë³€í™˜
train_df = make_regular_time_series(train_df)

# ë©”ë‰´ë³„ ìµœì´ˆ ì¶œì‹œì¼ ë¯¸ë¦¬ ê³„ì‚°
menu_launch_dates = train_df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ì˜ì—…ì¼ì'].min()

# íƒ€ê²Ÿ ë³€ìˆ˜ ë³€í™˜ (ë¡œê·¸ ë³€í™˜ìœ¼ë¡œ ë¶„í¬ ì•ˆì •í™”)
train_df['ë§¤ì¶œìˆ˜ëŸ‰_log'] = np.log1p(train_df['ë§¤ì¶œìˆ˜ëŸ‰'])

# ì´ìƒì¹˜ ì œê±° (ìƒìœ„ 1% ì œê±°)
q99 = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].quantile(0.99)
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(upper=q99)

# 0ê°’ ì²˜ë¦¬ ê°œì„  (ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ ëŒ€ì²´)
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].replace(0, 0.1)

# ë¡œê·¸ ë³€í™˜ëœ íƒ€ê²Ÿë„ ì—…ë°ì´íŠ¸
train_df['ë§¤ì¶œìˆ˜ëŸ‰_log'] = np.log1p(train_df['ë§¤ì¶œìˆ˜ëŸ‰'])

# í”¼ì²˜ ìƒì„± (ê³ ê¸‰ ë‹¬ë ¥ + Lag + Prophet)
print("ğŸ“… ê³ ê¸‰ ë‹¬ë ¥ ê¸°ë°˜ í”¼ì²˜ ìƒì„± ì¤‘...")
known_features_df = create_advanced_calendar_features(train_df[['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì']].drop_duplicates())
train_df = pd.merge(train_df, known_features_df, on=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'], how='left')

print("ğŸ“Š Lag í”¼ì²˜ ìƒì„± ì¤‘...")
train_df = create_lag_features(train_df)

prophet_models = {}
if Prophet is not None:
    print("ğŸ“ˆ Prophet í”¼ì²˜ ìƒì„± ì¤‘...")
    prophet_features, prophet_models = create_prophet_features_and_models(train_df)
    if not prophet_features.empty:
        train_df = pd.merge(train_df, prophet_features, on=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'], how='left')

# Prophet í”¼ì²˜ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” NaN ê°’ë§Œ 0ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤.
if 'prophet_yhat' in train_df.columns:
    train_df['prophet_yhat'] = train_df['prophet_yhat'].fillna(0)
    train_df['prophet_trend'] = train_df['prophet_trend'].fillna(0)

# ì¶”ê°€: ëª¨ë“  í”¼ì²˜ì˜ NaN ê°’ ì²˜ë¦¬
numeric_columns = train_df.select_dtypes(include=[np.number]).columns
for col in numeric_columns:
    if col != 'ë§¤ì¶œìˆ˜ëŸ‰':  # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ì œì™¸
        train_df[col] = train_df[col].fillna(0)

# ì¶”ê°€: ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
print(f"ì „ì²´ ë°ì´í„° í¬ê¸°: {len(train_df)}")
print(f"0ì´ ì•„ë‹Œ ë§¤ì¶œìˆ˜ëŸ‰ ê°œìˆ˜: {len(train_df[train_df['ë§¤ì¶œìˆ˜ëŸ‰'] > 0])}")
print(f"NaN ê°’ì´ ìˆëŠ” ì»¬ëŸ¼:")
for col in train_df.columns:
    nan_count = train_df[col].isna().sum()
    if nan_count > 0:
        print(f"  {col}: {nan_count}ê°œ")


# test í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬í•˜ì—¬ ì˜ˆì¸¡
test_paths = sorted(glob.glob('./data/test/*.csv'))
if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    all_predictions = []
    all_menu_scores = []  # ë©”ë‰´ë³„ ì„±ëŠ¥ ê¸°ë¡
    unique_menus = train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()

    for menu_name in tqdm(unique_menus, desc="ë©”ë‰´ë³„ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"):
        # 1. ë©”ë‰´ë³„ ë°ì´í„° ì¤€ë¹„
        menu_train_data = train_df[train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()

        # í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„° í™•ì¸ (0ì´ ì•„ë‹Œ ë°ì´í„°ê°€ 30ê°œ ë¯¸ë§Œì´ë©´ ê±´ë„ˆë›°ê¸°)
        if len(menu_train_data.query("ë§¤ì¶œìˆ˜ëŸ‰ > 0")) < 30:
            for path in test_paths:
                basename = os.path.basename(path).replace('.csv', '')
                for i in range(7):
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': 0
                    })
            continue

        # 2. ë©”ë‰´ë³„ TimeSeriesDataFrame ìƒì„±
        known_covariates_names = [
            'day_of_week', 'is_weekend', 'month', 'season', 'is_holiday', 'year',
            'days_since_launch'
        ]
        if 'prophet_yhat' in menu_train_data.columns:
            known_covariates_names.extend(['prophet_yhat', 'prophet_trend'])

        # ì¶”ê°€: ë©”ë‰´ë³„ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
        non_zero_count = len(menu_train_data[menu_train_data['ë§¤ì¶œìˆ˜ëŸ‰'] > 0])
        print(f"'{menu_name}': 0ì´ ì•„ë‹Œ ë°ì´í„° {non_zero_count}ê°œ")
        
        if non_zero_count < 50:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ì¦ê°€
            print(f"âš ï¸ '{menu_name}' ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ê±´ë„ˆëœë‹ˆë‹¤.")
            for path in test_paths:
                basename = os.path.basename(path).replace('.csv', '')
                for i in range(7):
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': 0
                    })
            continue

        # ì¶”ê°€: NaN ê°’ì´ ìˆëŠ” í–‰ ì œê±°
        menu_train_data = menu_train_data.dropna(subset=['ë§¤ì¶œìˆ˜ëŸ‰'])
        
        # ì¶”ê°€: í”¼ì²˜ì˜ NaN ê°’ ì²˜ë¦¬
        for col in known_covariates_names:
            if col in menu_train_data.columns:
                menu_train_data[col] = menu_train_data[col].fillna(0)

        train_ts_df = TimeSeriesDataFrame.from_data_frame(
            menu_train_data,
            id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
            timestamp_column="ì˜ì—…ì¼ì"
        )

        # 3. ë©”ë‰´ë³„ ëª¨ë¸ í•™ìŠµ
        predictor_path = f'autogluon_timeseries_menu/{menu_name.replace("/", "_").replace(" ", "")}'
        
        try:
            predictor = TimeSeriesPredictor.load(predictor_path)
            print(f"âœ… ì´ë¯¸ í•™ìŠµëœ '{menu_name}' ëª¨ë¸ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except Exception:
            predictor = TimeSeriesPredictor(
                label='ë§¤ì¶œìˆ˜ëŸ‰_log',  # ë¡œê·¸ ë³€í™˜ëœ íƒ€ê²Ÿ ì‚¬ìš©
                path=predictor_path,
                prediction_length=PREDICTION_LENGTH,
                eval_metric="sMAPE",
                known_covariates_names=known_covariates_names
                # num_val_windows íŒŒë¼ë¯¸í„° ì œê±°
            )
            print(f"ğŸš€ '{menu_name}' ë©”ë‰´ì˜ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            
            predictor.fit(
                train_ts_df,
                presets="best_quality",  # best_qualityë¡œ ë³€ê²½
                time_limit=300,  # ì‹œê°„ ì¦ê°€
                hyperparameters={
                    "Naive": {}, 
                    "SeasonalNaive": {}, 
                    "DirectTabular": {
                        "max_epochs": 200,  # ëŒ€í­ ì¦ê°€
                        "learning_rate": 0.005,  # ì¡°ì •
                        "dropout": 0.2,  # ì¦ê°€
                        "hidden_size": 128  # ì¦ê°€
                    },
                    "ETS": {
                        "trend": "add",
                        "seasonal": "add",
                        "seasonal_periods": 7
                    }, 
                    "Theta": {
                        "seasonal_periods": 7
                    }, 
                    "Chronos": {
                        "model_size": "medium",  # smallì—ì„œ mediumìœ¼ë¡œ
                        "num_samples": 50  # ì¦ê°€
                    }, 
                    "TemporalFusionTransformer": {
                        "lr": 0.0005,  # ê°ì†Œ
                        "max_epochs": 50,  # ì¦ê°€
                        "hidden_size": 128,  # ì¦ê°€
                        "attention_head_size": 8  # ì¦ê°€
                    },
                },
            )

        # 4. ì„±ëŠ¥ ê¸°ë¡ ë° ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì¡°ì •
        leaderboard = predictor.leaderboard()
        best_model_entry = leaderboard.iloc[0]
        
        # ëª¨ë¸ë³„ ì„±ëŠ¥ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ê³„ì‚°
        model_weights = {}
        total_score = 0
        for _, row in leaderboard.iterrows():
            score = -row['score_val']  # SMAPEëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            if score > 0:  # ìœ íš¨í•œ ì ìˆ˜ë§Œ
                model_weights[row['model']] = 1 / (score + 0.1)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                total_score += model_weights[row['model']]
        
        # ì •ê·œí™”
        if total_score > 0:
            for model in model_weights:
                model_weights[model] /= total_score
        
        all_menu_scores.append({
            "menu": menu_name,
            "best_model": best_model_entry["model"],
            "score_val": best_model_entry["score_val"],
            "model_weights": model_weights
        })
        
        print(f"âœ… '{menu_name}' Best Model: {best_model_entry['model']} | Validation SMAPE: {-best_model_entry['score_val']:.4f}")
        print(f"   ì•™ìƒë¸” ê°€ì¤‘ì¹˜: {model_weights}")

        # 5. ë©”ë‰´ë³„ ìˆœí™˜ ì˜ˆì¸¡
        menu_historical_data = menu_train_data.copy()
        for path in test_paths:
            test_day_df = pd.read_csv(path)
            test_day_df['ì˜ì—…ì¼ì'] = pd.to_datetime(test_day_df['ì˜ì—…ì¼ì'])

            menu_test_day_df = test_day_df[test_day_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name]

            menu_historical_data = pd.concat([menu_historical_data, menu_test_day_df], ignore_index=True)
            menu_historical_data = menu_historical_data.drop_duplicates(subset=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'], keep='last')

            historical_data_regular = make_regular_time_series(menu_historical_data)

            historical_ts_df = TimeSeriesDataFrame.from_data_frame(
                historical_data_regular,
                id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
                timestamp_column="ì˜ì—…ì¼ì"
            )

            last_date = historical_ts_df.index.get_level_values('timestamp').max()
            future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=PREDICTION_LENGTH)

            future_df = pd.DataFrame({'ì˜ì—…ì¼ì': future_dates, 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name})
            cal_feats = create_calendar_features(future_df, menu_launch_dates=menu_launch_dates)

            if Prophet is not None and menu_name in prophet_models:
                try:
                    m = prophet_models[menu_name]
                    future_prophet_df = pd.DataFrame({'ds': future_df['ì˜ì—…ì¼ì']})
                    forecast = m.predict(future_prophet_df)
                    cal_feats['prophet_yhat'] = np.expm1(forecast['yhat'].values).clip(lower=0)
                    cal_feats['prophet_trend'] = forecast['trend'].values
                except Exception:
                    cal_feats['prophet_yhat'] = 0
                    cal_feats['prophet_trend'] = 0
            elif 'prophet_yhat' in train_df.columns:
                cal_feats['prophet_yhat'] = 0
                cal_feats['prophet_trend'] = 0

            future_covariates = TimeSeriesDataFrame.from_data_frame(
                cal_feats,
                id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
                timestamp_column="ì˜ì—…ì¼ì",
            )

            predictions = predictor.predict(historical_ts_df, known_covariates=future_covariates)

            # ë¡œê·¸ ë³€í™˜ëœ ì˜ˆì¸¡ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            pred_df_reset = predictions.reset_index()
            pred_df_reset['mean'] = np.expm1(pred_df_reset['mean']).clip(lower=0)

            basename = os.path.basename(path).replace('.csv', '')
            unique_timestamps = sorted(pred_df_reset["timestamp"].unique())

            for i, ts in enumerate(unique_timestamps):
                day_preds = pred_df_reset[pred_df_reset["timestamp"] == ts]
                submission_date_str = f"{basename}+{i+1}ì¼"

                for _, row in day_preds.iterrows():
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': submission_date_str,
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': row['item_id'],
                        'ë§¤ì¶œìˆ˜ëŸ‰': max(0, row['mean'])
                    })

# ë©”ë‰´ë³„ ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
if all_menu_scores:
    print("\n=== ğŸ“Š ë©”ë‰´ë³„ ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½ ===")
    scores_df = pd.DataFrame(all_menu_scores)
    scores_df['smape'] = -scores_df['score_val']
    scores_df = scores_df.sort_values('smape', ascending=True)
    
    print(f"ì´ {len(scores_df)}ê°œ ë©”ë‰´ ì²˜ë¦¬ ì™„ë£Œ")
    print(f"í‰ê·  SMAPE: {scores_df['smape'].mean():.4f}")
    print(f"ìµœê³  ì„±ëŠ¥ ë©”ë‰´: {scores_df.iloc[0]['menu']} (SMAPE: {scores_df.iloc[0]['smape']:.4f})")
    print(f"ìµœì € ì„±ëŠ¥ ë©”ë‰´: {scores_df.iloc[-1]['menu']} (SMAPE: {scores_df.iloc[-1]['smape']:.4f})")
    
    # ì„±ëŠ¥ ìš”ì•½ì„ íŒŒì¼ë¡œ ì €ì¥
    scores_df.to_csv('menu_performance_summary.csv', index=False)
    print("âœ… ë©”ë‰´ë³„ ì„±ëŠ¥ ìš”ì•½ì´ 'menu_performance_summary.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
if all_predictions:
    pred_df = pd.DataFrame(all_predictions)
    
    print("\nì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
    
    final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
    final_submission = final_submission.fillna(0)
    
    # ì»¬ëŸ¼ ìˆœì„œë¥¼ ìƒ˜í”Œê³¼ ë™ì¼í•˜ê²Œ ë§ì¶¤
    final_submission = final_submission[submission_df.columns]
    
    output_filename = 'submission_timeseries_global_model.csv'
    final_submission.to_csv(output_filename, index=False)
    print(f"âœ… {output_filename} íŒŒì¼ ìƒì„± ì™„ë£Œ")

else:
    print("\nìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

print("\n=== ğŸ† AutoGluon TimeSeriesPredictor ì „ì—­ ëª¨ë¸ ===")
print("âœ… ëª¨ë“  ë©”ë‰´ë¥¼ í•˜ë‚˜ì˜ ì‹œê³„ì—´ ëª¨ë¸ë¡œ í•™ìŠµ ë° ì˜ˆì¸¡")
print("âœ… Prophet ì˜ˆì¸¡ì„ í”¼ì²˜ë¡œ í™œìš© (ì„¤ì¹˜ ì‹œ)")
print("âœ… ë‹¬ë ¥/ê³µíœ´ì¼ ë“± ë¯¸ë˜ì— ì•Œ ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ known_covariatesë¡œ í™œìš©")
