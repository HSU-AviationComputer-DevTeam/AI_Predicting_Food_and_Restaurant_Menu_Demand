import os
import glob
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
from autogluon.tabular import TabularPredictor
from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor
import warnings
warnings.filterwarnings('ignore')

# ==============================================================================
# ğŸ¯ ìµœì¢… ì „ëµ (v1.8): í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ê³ ë„í™” + ê³„ì¸µì  ëª¨ë¸ë§
# - í”¼ì²˜ ê°•í™”: ë‹¤ì–‘í•œ ê¸°ê°„(7, 14, 28ì¼)ì˜ í†µê³„ í”¼ì²˜ ë° ê³µíœ´ì¼ ê·¼ì ‘ë„ í”¼ì²˜ ì¶”ê°€
# - ê³„ì¸µì  ëª¨ë¸ë§: ë©”ë‰´ ì¹´í…Œê³ ë¦¬, ì˜ì—…ì¥ íŠ¹ì„±ì„ ì •ì  í”¼ì²˜(static_features)ë¡œ í™œìš©
# - ëª¨ë¸ ì•ˆì •ì„±: ë‹¨ìˆœ í‰ê·  ì•™ìƒë¸”ë¡œ ë³€ê²½í•˜ì—¬ íŠ¹ì • ë§¤ì¥ ì˜ì¡´ì„± ê°ì†Œ
# - í•™ìŠµ ìµœì í™”: í•™ìŠµ ì‹œê°„ ì¦ëŒ€ ë° ì˜ˆì¸¡ ì‹œ ë¶ˆí•„ìš”í•œ ê²½ê³  ë©”ì‹œì§€ ì œê±°
# ==============================================================================


# ê°€ì¤‘ ì•™ìƒë¸” ì„¤ì •
WEIGHT_CONFIG = {
    # ê¸°ë³¸ ê°€ì¤‘ì¹˜: [TabularPredictor ê°€ì¤‘ì¹˜, TimeSeriesPredictor ê°€ì¤‘ì¹˜]
    "default": [0.6, 0.4],
    # ì—…ì¥ë³„ íŠ¹í™” ê°€ì¤‘ì¹˜
    "special": {
        "ë‹´í™”": [0.5, 0.5],
        "ë¯¸ë¼ì‹œì•„": [0.4, 0.6]
    }
}

# AutoGluon í•™ìŠµ ì„¤ì • (ì‹œê°„ ì¦ëŒ€)
TABULAR_TIME_LIMIT = 1800  # 30ë¶„
TIMESERIES_TIME_LIMIT = 1800 # 30ë¶„

# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(42)

# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ (2025ë…„ í¬í•¨)
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03",
    "2023-10-09", "2023-12-25", "2024-01-01", "2024-02-09", "2024-02-10",
    "2024-02-11", "2024-02-12", "2024-03-01", "2024-04-10", "2024-05-05",
    "2024-05-06", "2024-05-15", "2024-06-06", "2024-08-15", "2024-09-16",
    "2024-09-17", "2024-09-18", "2024-10-03", "2024-10-09", "2024-12-25",
    "2025-01-01", "2025-01-28", "2025-01-29", "2025-01-30", "2025-03-01",
    "2025-05-05", "2025-05-06"
])

def find_nearest_holiday(date, holiday_dates):
    """ê°€ì¥ ê°€ê¹Œìš´ ê³µíœ´ì¼ê³¼ì˜ ì „í›„ ì°¨ì´ë¥¼ ê³„ì‚°"""
    future_holidays = holiday_dates[holiday_dates >= date]
    past_holidays = holiday_dates[holiday_dates < date]
    
    days_to_next = (future_holidays.min() - date).days if not future_holidays.empty else 365
    days_from_last = (date - past_holidays.max()).days if not past_holidays.empty else 365
    
    return days_to_next, days_from_last

def is_korean_holiday(date):
    return int(date in holiday_dates)

class AutoGluonEnsemblePredictor:
    def __init__(self, device):
        self.tabular_predictors = []
        self.timeseries_predictor = None
        self.feature_cols = None
        self.static_feature_cols = None
        self.device = device
        # TimeSeriesPredictorê°€ ì‚¬ìš©í•  covariate ëª©ë¡
        self.known_covariate_names = [
            'day_of_week', 'is_weekend', 'month', 'day',
            'week_of_year', 'season', 'is_holiday', 'year',
            'days_to_next_holiday', 'days_from_last_holiday' # ê³µíœ´ì¼ ê·¼ì ‘ë„ í”¼ì²˜ ì¶”ê°€
        ]

    def create_advanced_features(self, df):
        """
        ë‹¤ì–‘í•œ ë„ë©”ì¸ ì§€ì‹ ë° ì‹œê³„ì—´ íŠ¹ì„±ì„ ê²°í•©í•œ ê³ ê¸‰ í”¼ì²˜ ìƒì„± í•¨ìˆ˜
        (v1.8: ê³µíœ´ì¼ ê·¼ì ‘ë„ í”¼ì²˜ ì¶”ê°€, ì •ì /ë™ì  í”¼ì²˜ ë¶„ë¦¬ ì¤€ë¹„)
        """
        df = df.copy()
        # 1. ë‚ ì§œ ê¸°ë°˜ ê¸°ë³¸ í”¼ì²˜
        df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
        df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
        df['month'] = df['ì˜ì—…ì¼ì'].dt.month
        df['day'] = df['ì˜ì—…ì¼ì'].dt.day
        df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
        df['season'] = (df['month'] % 12 + 3) // 3
        df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
        df['year'] = df['ì˜ì—…ì¼ì'].dt.year

        # ê³µíœ´ì¼ ê·¼ì ‘ë„ í”¼ì²˜
        holiday_info = df['ì˜ì—…ì¼ì'].apply(lambda x: find_nearest_holiday(x, holiday_dates))
        df['days_to_next_holiday'] = [info[0] for info in holiday_info]
        df['days_from_last_holiday'] = [info[1] for info in holiday_info]
        
        # 2. í…ìŠ¤íŠ¸(ë©”ë‰´ëª…/ì˜ì—…ì¥ëª…) ê¸°ë°˜ ë„ë©”ì¸ í”¼ì²˜ -> ì •ì  í”¼ì²˜ë¡œ ë¶„ë¦¬
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].str.join('_')
        
        # ë©”ë‰´ ì¹´í…Œê³ ë¦¬ (ì •ì  í”¼ì²˜)
        df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
        df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False).astype(int)
        df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
        df['í•œì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False).astype(int)
        df['ì–‘ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False).astype(int)
        
        # ì˜ì—…ì¥ íŠ¹ì„± (One-hot encoding, ì •ì  í”¼ì²˜)
        store_dummies = pd.get_dummies(df['ì˜ì—…ì¥ëª…'], prefix='store')
        df = pd.concat([df, store_dummies], axis=1)

        if self.static_feature_cols is None:
            self.static_feature_cols = ['ë¶„ì‹ë¥˜', 'ìŒë£Œë¥˜', 'ì£¼ë¥˜', 'í•œì‹ë¥˜', 'ì–‘ì‹ë¥˜'] + list(store_dummies.columns)

        df = df.drop(columns=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])
        return df

    def prepare_tabular_training_data(self, full_train_df):
        """TabularPredictor í•™ìŠµì„ ìœ„í•œ í†µí•© ë°ì´í„°ì…‹ ìƒì„± (v1.8: ë‹¤ì–‘í•œ í†µê³„ í”¼ì²˜ ì¶”ê°€)"""
        X_list, y_list = [], []
        
        # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ê³ ê¸‰ í”¼ì²˜ ì¼ê´„ ìƒì„±
        featured_df = self.create_advanced_features(full_train_df.copy())
        
        for menu_name in tqdm(full_train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique(), desc="í”¼ì²˜ ë°ì´í„°ì…‹ ìƒì„±", leave=False):
            menu_df = featured_df[featured_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].sort_values(by='ì˜ì—…ì¼ì')
            sales = menu_df['ë§¤ì¶œìˆ˜ëŸ‰'].values
            
            if len(sales) < 35: continue

            for i in range(len(sales) - 34):
                features = {}
                # ë‹¤ì–‘í•œ ê¸°ê°„(7, 14, 28ì¼)ì˜ í†µê³„ í”¼ì²˜ ìƒì„±
                for window in [7, 14, 28]:
                    if i + 28 - window >= 0:
                        input_data = sales[i + 28 - window : i + 28]
                        features[f'mean_sales_{window}d'] = np.mean(input_data)
                        features[f'std_sales_{window}d'] = np.std(input_data)
                        features[f'median_sales_{window}d'] = np.median(input_data)
                        features[f'min_sales_{window}d'] = np.min(input_data)
                        features[f'max_sales_{window}d'] = np.max(input_data)
                
                # ì¶”ì„¸ í”¼ì²˜
                if i + 28 - 14 >= 0:
                    features['recent_trend_7_vs_14'] = np.mean(sales[i+21:i+28]) - np.mean(sales[i+14:i+21])

                # ê¸°ì¡´ í”¼ì²˜ì™€ ê²°í•©
                row_features = menu_df.iloc[i+27].to_dict()
                row_features.update(features)
                X_list.append(row_features)
                
                # íƒ€ê²Ÿ ë°ì´í„°
                y_list.append(sales[i+28:i+35])

        X_df = pd.DataFrame(X_list).drop(columns=['ì˜ì—…ì¼ì', 'ë§¤ì¶œìˆ˜ëŸ‰'])
        y_df = pd.DataFrame(y_list, columns=[f'target_{i+1}day' for i in range(7)])
        
        if self.feature_cols is None:
            self.feature_cols = X_df.columns
            
        return pd.concat([X_df, y_df], axis=1)

    def train_tabular_predictors(self, train_data):
        """7ì¼ ì˜ˆì¸¡ì„ ìœ„í•œ 7ê°œì˜ TabularPredictor ëª¨ë¸ í•™ìŠµ"""
        for day in range(7):
            print(f"\n--- TabularPredictor Day {day+1} ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
            label = f'target_{day+1}day'
            predictor = TabularPredictor(
                label=label,
                path=f'autogluon_models/tabular_day_{day+1}',
                problem_type='regression',
                eval_metric='rmse'
            ).fit(
                train_data.drop(columns=[f'target_{i+1}day' for i in range(7) if i != day]),
                time_limit=TABULAR_TIME_LIMIT,
                presets='best_quality'
            )
            self.tabular_predictors.append(predictor)
    
    def train_timeseries_predictor(self, full_train_df):
        """known_covariatesì™€ static_featuresë¥¼ ì‚¬ìš©í•˜ëŠ” TimeSeriesPredictor ëª¨ë¸ í•™ìŠµ"""
        print("\n--- TimeSeriesPredictor ëª¨ë¸ í•™ìŠµ ì‹œì‘ (ê³„ì¸µì  ëª¨ë¸ë§) ---")
        
        df_with_features = self.create_advanced_features(full_train_df.copy())

        # ì •ì  í”¼ì²˜ ì¶”ì¶œ: ê° ì•„ì´í…œë³„ë¡œ ë³€í•˜ì§€ ì•ŠëŠ” ê°’ë“¤
        static_features_df = df_with_features.groupby("ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…")[self.static_feature_cols].first()

        ts_df = TimeSeriesDataFrame.from_data_frame(
            df_with_features,
            id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
            timestamp_column="ì˜ì—…ì¼ì",
            static_features_df=static_features_df
        )

        self.timeseries_predictor = TimeSeriesPredictor(
            label='ë§¤ì¶œìˆ˜ëŸ‰',
            path='autogluon_models/timeseries_advanced_v1_8', # ê²½ë¡œ ë³€ê²½
            prediction_length=7,
            eval_metric='RMSE',
            known_covariates_names=self.known_covariate_names,
        ).fit(
            ts_df,
            time_limit=TIMESERIES_TIME_LIMIT,
            presets="best_quality",
            random_seed=42 # ì¬í˜„ì„±ì„ ìœ„í•´ ì¶”ê°€
        )

    def predict_7days_autogluon_ensemble(self, input_28days_data_df, last_date, menu_name):
        """
        ë‘ AutoGluon Predictorì˜ ì˜ˆì¸¡ì„ ì•™ìƒë¸” (v1.8: ê²½ê³  ì œê±°, ë‹¨ìˆœ í‰ê· )
        - input_28days_data_df: ë§¤ì¶œìˆ˜ëŸ‰ ë° ëª¨ë“  í”¼ì²˜ê°€ í¬í•¨ëœ 28ì¼ì¹˜ ë°ì´í„°í”„ë ˆì„
        """
        # 1. TabularPredictor ì˜ˆì¸¡
        base_features = input_28days_data_df.iloc[-1].to_dict()

        stat_features = {}
        sales_data = input_28days_data_df['ë§¤ì¶œìˆ˜ëŸ‰'].values
        for window in [7, 14, 28]:
            input_data = sales_data[-window:]
            stat_features[f'mean_sales_{window}d'] = np.mean(input_data)
            stat_features[f'std_sales_{window}d'] = np.std(input_data)
            stat_features[f'median_sales_{window}d'] = np.median(input_data)
            stat_features[f'min_sales_{window}d'] = np.min(input_data)
            stat_features[f'max_sales_{window}d'] = np.max(input_data)
        
        stat_features['recent_trend_7_vs_14'] = np.mean(sales_data[-7:]) - np.mean(sales_data[-14:-7])

        base_features.update(stat_features)
        
        X_pred_tabular = pd.DataFrame([base_features])[self.feature_cols]
        
        tabular_preds = []
        for p in self.tabular_predictors:
            # get_model_best()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì  ëª¨ë¸ì„ ëª…ì‹œ, ê²½ê³  ì œê±°
            best_model = p.get_model_best()
            pred = p.predict(X_pred_tabular, model=best_model).iloc[0]
            tabular_preds.append(max(0, pred))

        # 2. TimeSeriesPredictor ì˜ˆì¸¡ (static_features í¬í•¨)
        future_dates = pd.to_datetime([last_date + pd.Timedelta(days=i) for i in range(1, 8)])
        future_covariates_df = pd.DataFrame({
            'ì˜ì—…ì¼ì': future_dates,
            'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': [menu_name] * 7
        })
        future_covariates_featured = self.create_advanced_features(future_covariates_df)

        known_covariates = TimeSeriesDataFrame.from_data_frame(
            future_covariates_featured,
            id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
            timestamp_column="ì˜ì—…ì¼ì"
        )
        
        # ì˜ˆì¸¡ ì‹œì—ë„ static_featuresê°€ í¬í•¨ëœ context ë°ì´í„°ê°€ í•„ìš”
        ts_context_df = TimeSeriesDataFrame.from_data_frame(
            input_28days_data_df,
            id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
            timestamp_column="ì˜ì—…ì¼ì",
            static_features_df=input_28days_data_df.groupby("ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…")[self.static_feature_cols].first()
        )

        ts_preds_raw = self.timeseries_predictor.predict(
            ts_context_df,
            known_covariates=known_covariates
        )
        
        predictions_for_item = ts_preds_raw.loc[menu_name]
        ts_preds = predictions_for_item['mean'].clip(lower=0).values

        # 3. ë‹¨ìˆœ í‰ê·  ì•™ìƒë¸”
        ensemble_preds = (np.array(tabular_preds) + ts_preds) / 2
        
        return ensemble_preds

# ==============================================================================
# Main Execution
# ==============================================================================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    print("ë°ì´í„° ë¡œë“œ ì¤‘...")
    train_df = pd.read_csv('./data/train/train.csv')
    # Log1p ë³€í™˜
    train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = np.log1p(train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))
    train_df['ì˜ì—…ì¼ì'] = pd.to_datetime(train_df['ì˜ì—…ì¼ì'])
    submission_df = pd.read_csv('./data/sample_submission.csv')

    predictor = AutoGluonEnsemblePredictor(device)
    
    # --- ëª¨ë¸ í•™ìŠµ ---
    # 1. TabularPredictor í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° í•™ìŠµ
    tabular_train_data = predictor.prepare_tabular_training_data(train_df)
    predictor.train_tabular_predictors(tabular_train_data)
    
    # 2. TimeSeriesPredictor í•™ìŠµ
    predictor.train_timeseries_predictor(train_df)

    # --- Test íŒŒì¼ë³„ ì˜ˆì¸¡ ---
    print("\nìµœì¢… ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„± ì¤‘...")
    all_predictions = []
    test_paths = sorted(glob.glob('./data/test/*.csv'))
    
    for path in tqdm(test_paths, desc="Test íŒŒì¼ë³„ ì˜ˆì¸¡"):
        test_file_df = pd.read_csv(path)
        test_file_df['ì˜ì—…ì¼ì'] = pd.to_datetime(test_file_df['ì˜ì—…ì¼ì'])
        basename = os.path.basename(path).replace('.csv', '')
        
        # test ë°ì´í„°ì—ë„ log1p ë³€í™˜ ì ìš©
        test_file_df['ë§¤ì¶œìˆ˜ëŸ‰'] = np.log1p(test_file_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))
        # ì˜ˆì¸¡ì— í•„ìš”í•œ í”¼ì²˜ë¥¼ test_file_df ì „ì²´ì— ë¯¸ë¦¬ ìƒì„±
        test_file_df_featured = predictor.create_advanced_features(test_file_df.copy())
        
        for menu_name in test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique():
            # 28ì¼ ì…ë ¥ ë°ì´í„° êµ¬ì„± (í”¼ì²˜ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ì—ì„œ)
            context_df = test_file_df_featured[test_file_df_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].iloc[-28:]
            
            if context_df.empty:
                # submission íŒŒì¼ì— í•´ë‹¹ ë©”ë‰´ê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„
                continue
            
            last_date = context_df['ì˜ì—…ì¼ì'].max()
            
            # AutoGluon ì•™ìƒë¸” ì˜ˆì¸¡ (ì…ë ¥ ë°ì´í„° í˜•ì‹ ë³€ê²½)
            pred_7days_log = predictor.predict_7days_autogluon_ensemble(context_df, last_date, menu_name)
            
            # ì˜ˆì¸¡ê°’ ë³µì› (expm1)
            pred_7days = np.expm1(pred_7days_log)
            
            # ê²°ê³¼ ì €ì¥
            for i, pred_val in enumerate(pred_7days):
                all_predictions.append({
                    'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': max(0, pred_val) # í˜¹ì‹œ ëª¨ë¥¼ ìŒìˆ˜ê°’ ë°©ì§€
                })

    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---
    if all_predictions:
        pred_df = pd.DataFrame(all_predictions)
        submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
        final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
        final_submission = final_submission.fillna(0)
        final_submission = final_submission[submission_df.columns]
        
        output_filename = 'submission_autogluon_v1_8.csv' # ë²„ì „ëª… ë³€ê²½
        final_submission.to_csv(output_filename, index=False)
        print(f"\n{output_filename} íŒŒì¼ ìƒì„± ì™„ë£Œ")
    else:
        print("ìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    print("\n=== ğŸ† AutoGluon ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë¸ v1.8 ===")
    print(f"âœ… ê³ ê¸‰ í”¼ì²˜(ë‹¤ê¸°ê°„ í†µê³„, ê³µíœ´ì¼ ê·¼ì ‘ë„) + Logë³€í™˜ + ê³„ì¸µì  TS ëª¨ë¸ë§ ì ìš©")
    print(f"âœ… ë‹¨ìˆœ í‰ê·  ì•™ìƒë¸” ì ìš©")
    print("âœ… ëŒ€íšŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ìµœì¢… ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ")


#     submission_autogluon_advanced.csv íŒŒì¼ ìƒì„± ì™„ë£Œ

# === ğŸ† AutoGluon ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë¸ ===
# âœ… ê³ ê¸‰ í”¼ì²˜ + Logë³€í™˜ + TS ìµœì í™” ì ìš©
# âœ… 'ë‹´í™”', 'ë¯¸ë¼ì‹œì•„'ì— íŠ¹í™” ê°€ì¤‘ì¹˜ ì ìš©: {'ë‹´í™”': [0.5, 0.5], 'ë¯¸ë¼ì‹œì•„': [0.4, 0.6]}
# âœ… ëŒ€íšŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ìµœì¢… ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ
# (_ray_fit pid=25888) [3000]     valid_set's rmse: 0.640075 [repeated 10x across cluster]
# (.venv) 
