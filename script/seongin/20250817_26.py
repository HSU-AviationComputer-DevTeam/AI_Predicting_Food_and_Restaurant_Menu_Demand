import os
import glob
import random
import shutil
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.tabular import TabularPredictor
from autogluon.core.metrics import make_scorer
# sklearn imports ì œê±° (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

# âœ… ì¶”ê°€: GPU í™˜ê²½ ì„¤ì •
os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # ì²« ë²ˆì§¸ GPU ì‚¬ìš©
os.environ['CUDA_MEM_FRACTION'] = '0.8'   # GPU ë©”ëª¨ë¦¬ì˜ 80% ì‚¬ìš©

# GPU ìƒíƒœ í™•ì¸ í•¨ìˆ˜
def check_gpu_status():
    print("=== GPU ìƒíƒœ í™•ì¸ ===")
    
    # CUDA í™•ì¸
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… PyTorch CUDA: {torch.cuda.get_device_name(0)}")
            print(f"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ GPU ìˆ˜: {torch.cuda.device_count()}")
        else:
            print("âŒ PyTorch CUDA ì‚¬ìš© ë¶ˆê°€")
    except ImportError:
        print("âŒ PyTorch ë¯¸ì„¤ì¹˜")
    
    # XGBoost GPU í™•ì¸
    try:
        import xgboost as xgb
        print(f"âœ… XGBoost ì„¤ì¹˜ë¨")
    except ImportError:
        print("âŒ XGBoost ë¯¸ì„¤ì¹˜")
    
    # CatBoost GPU í™•ì¸
    try:
        import catboost
        print(f"âœ… CatBoost ì„¤ì¹˜ë¨")
    except ImportError:
        print("âŒ CatBoost ë¯¸ì„¤ì¹˜")
    
    print("===================")

# GPU ìƒíƒœ í™•ì¸ ì‹¤í–‰
check_gpu_status()

# Prophet (ì˜µì…˜): ë¯¸ì„¤ì¹˜ ì‹œ ìë™ ë¹„í™œì„±í™”
try:
    from prophet import Prophet
except Exception:
    Prophet = None

# âœ… ìˆ˜ì •: ì¤‘ë³µ ì œê±°í•˜ê³  í•˜ë‚˜ë¡œ í†µì¼
PROPHET_WEIGHT = 0.15  # AutoGluonì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
ANALYSIS_PATH = 'autogluon_analysis'
TOP_N_FEATURES = 10  # ë” ë§ì€ í”¼ì²˜ ì„ íƒ

# âœ… ìˆ˜ì •: ë‚´ì¥ ë©”íŠ¸ë¦­ ì‚¬ìš©ìœ¼ë¡œ PicklingError í•´ê²°
# DACON ëŒ€íšŒìš© SMAPE í‰ê°€ ì§€í‘œ ì •ì˜ (ë³„ë„ ê³„ì‚°ìš©)
def smape_metric(y_true, y_pred):
    """DACON ëŒ€íšŒìš© SMAPE í‰ê°€ ì§€í‘œ (ë³„ë„ ê³„ì‚°ìš©)"""
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    # ëŒ€íšŒ ê·œì¹™: ì‹¤ì œ ë§¤ì¶œ ìˆ˜ëŸ‰ì´ 0ì¸ ê²½ìš°ëŠ” í‰ê°€ì—ì„œ ì œì™¸
    mask = y_true != 0
    
    # ëª¨ë“  ì‹¤ì œ ê°’ì´ 0ì¸ ê²½ìš°, SMAPEëŠ” 0ìœ¼ë¡œ ì •ì˜
    if not np.any(mask):
        return 0.0

    y_true = y_true[mask]
    y_pred = y_pred[mask]
    
    # SMAPE ê³„ì‚°
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    
    # ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€ (ì•ˆì „ì¥ì¹˜ë¡œ ë¶„ëª¨ê°€ 0ì´ë©´ ê²°ê³¼ëŠ” 0)
    ratio = np.where(denominator == 0, 0, numerator / denominator)
    
    return np.mean(ratio) * 100

# AutoGluonìš© Scorer ìƒì„±
# ëŒ€íšŒì˜ ê°€ì¤‘ì¹˜ SMAPEëŠ” ë¹„ê³µê°œì´ë¯€ë¡œ, ì¼ë°˜ SMAPEë¡œ ê²€ì¦ ì ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
smape_scorer = make_scorer(name='smape',
                           score_func=smape_metric,
                           optimum=0,
                           greater_is_better=False)


# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)


# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)


def build_prophet_holidays_df():
    hd = pd.DataFrame({
        'holiday': 'kr_holiday',
        'ds': holiday_dates
    })
    return hd

# Prophet ë³´ì¡° ì˜ˆì¸¡ ìºì‹œ: ëª¨ë¸ ë° ë‚ ì§œë³„ ì˜ˆì¸¡ê°’
prophet_model_cache = {}
prophet_yhat_by_date_cache = {}


def get_or_fit_prophet_model(train_df_raw: pd.DataFrame, menu_name: str):
    if Prophet is None:
        return None, None
    if menu_name in prophet_model_cache:
        return prophet_model_cache[menu_name]

    # âœ… ìˆ˜ì •: í›ˆë ¨ ë°ì´í„°ë§Œ ì‚¬ìš©
    series = train_df_raw.loc[train_df_raw['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name, ['ì˜ì—…ì¼ì', 'ë§¤ì¶œìˆ˜ëŸ‰']].copy()
    if series.empty or series['ë§¤ì¶œìˆ˜ëŸ‰'].count() < 25:
        return None, None

    series = series.sort_values('ì˜ì—…ì¼ì')
    last_train_date = pd.to_datetime(series['ì˜ì—…ì¼ì']).max()
    df_p = pd.DataFrame({'ds': pd.to_datetime(series['ì˜ì—…ì¼ì']), 'y': np.log1p(series['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))})

    try:
        m = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False,
            changepoint_prior_scale=0.05,  # ë” ë¶€ë“œëŸ¬ìš´ ì¶”ì„¸
            seasonality_prior_scale=5.0,   # ê³„ì ˆì„± ê°•ë„ ì¡°ì ˆ
            holidays=build_prophet_holidays_df()
        )
        m.fit(df_p)
        prophet_model_cache[menu_name] = (m, last_train_date)
        return m, last_train_date
    except Exception:
        return None, None


def get_prophet_yhat_for_date(menu_name: str, target_date: pd.Timestamp) -> float | None:
    """
    ëª©í‘œ ë‚ ì§œì— ëŒ€í•œ Prophet yhatì„ ë°˜í™˜. í•„ìš” ì‹œ ë¯¸ë˜ í”„ë ˆì„ì„ í™•ì¥í•˜ì—¬ ìºì‹œí•©ë‹ˆë‹¤.
    """
    if Prophet is None:
        return None

    # ëª¨ë¸ ì¤€ë¹„
    m, last_train_date = prophet_model_cache.get(menu_name, (None, None))
    if m is None:
        # ëª¨ë¸ì´ ì—†ë‹¤ë©´ í•™ìŠµ ì‹œë„ (train_dfëŠ” ì „ì—­ ë²”ìœ„ì—ì„œ ì ‘ê·¼)
        return None

    if target_date <= last_train_date:
        return None

    # ìºì‹œ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    if menu_name not in prophet_yhat_by_date_cache:
        prophet_yhat_by_date_cache[menu_name] = {}

    yhat_map = prophet_yhat_by_date_cache[menu_name]
    if target_date in yhat_map:
        return yhat_map[target_date]

    # í•„ìš”í•œ ê¸°ê°„ê¹Œì§€ ë¯¸ë˜ ìƒì„± ë° ì˜ˆì¸¡
    periods = (target_date - last_train_date).days
    if periods <= 0:
        return None
    try:
        future = m.make_future_dataframe(periods=periods, freq='D', include_history=False)
        fcst = m.predict(future)[['ds', 'yhat']]
        # ìºì‹œì— ì €ì¥
        for _, row in fcst.iterrows():
            ds = pd.to_datetime(row['ds'])
            yhat = max(0.0, float(np.expm1(row['yhat'])))
            yhat_map[ds] = yhat
        return yhat_map.get(target_date)
    except Exception:
        return None


# í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± ì¶”ê°€)
def create_features(df):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    # ì˜ì—…ì¥ëª…ê³¼ ë©”ë‰´ëª… ë¶„ë¦¬
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].apply(lambda x: '_'.join(x) if x else '')

    # ì‹œê°„ í”¼ì²˜
    sort_keys = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'] if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else ['ì˜ì—…ì¼ì']
    df = df.sort_values(sort_keys)
    
    # ì¶œì‹œ ëŒ€ë¹„ ê²½ê³¼ì¼ ë° ì›” í™œì„± í”Œë˜ê·¸ ìƒì„±
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        min_date_by_menu = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ì˜ì—…ì¼ì'].transform('min')
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - min_date_by_menu).dt.days
    else:
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - df['ì˜ì—…ì¼ì'].min()).dt.days

    # is_active_month
    df['yyyymm'] = df['ì˜ì—…ì¼ì'].dt.to_period('M').astype(str)
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['is_active_month'] = (df.groupby(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'yyyymm']).cumcount() > 0).astype(int)
    else:
        df['is_active_month'] = (df.groupby(['yyyymm']).cumcount() > 0).astype(int)

    if 'ë§¤ì¶œìˆ˜ëŸ‰' in df.columns:
        gb_key = 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else 'ì˜ì—…ì¼ì'
        gb = df.groupby(gb_key)['ë§¤ì¶œìˆ˜ëŸ‰']
        
        # ê°œì„ ëœ Lag í”¼ì²˜
        for lag in [1, 2, 3, 7, 14, 21, 28]:
            df[f'lag_{lag}'] = gb.shift(lag)
        
        # ê°œì„ ëœ Rolling í”¼ì²˜
        for window in [7, 14, 28]:
            df[f'rolling_mean_{window}'] = gb.shift(1).rolling(window).mean()
            df[f'rolling_std_{window}'] = gb.shift(1).rolling(window).std()
            df[f'rolling_min_{window}'] = gb.shift(1).rolling(window).min()
            df[f'rolling_max_{window}'] = gb.shift(1).rolling(window).max()
    
    # AutoGluonì´ ë‚ ì§œ ê´€ë ¨ í”¼ì²˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ íƒ€ì… ë³€ê²½
    df['month'] = df['month'].astype(str)
    df['day_of_week'] = df['day_of_week'].astype(str)
    df['year'] = df['year'].astype(str)
    df['season'] = df['season'].astype(str)

    # ë¶ˆí•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼ ì œê±°
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df = df.drop(columns=['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])

    # ë‚´ë¶€ ê³„ì‚°ìš© ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    if 'yyyymm' in df.columns:
        df = df.drop(columns=['yyyymm'])

    df = df.fillna(0)
    
    return df

# ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv('./data/train/train.csv')
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)
submission_df = pd.read_csv('./data/sample_submission.csv')

# Prophet ëª¨ë¸ ë¯¸ë¦¬ ì í•©(ë©”ë‰´ë³„)
if Prophet is not None:
    unique_menus_for_prophet = train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
    for _menu in tqdm(unique_menus_for_prophet, desc='Prophet ëª¨ë¸ ì í•©', leave=False):
        m, last_d = get_or_fit_prophet_model(train_df, _menu)
        # ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ (ìºì‹œì—ëŠ” ì¶”ê°€ ì•ˆ ë¨)

# í”¼ì²˜ ìƒì„±
train_full_featured = create_features(train_df)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ (ë©”ë‰´ë³„ë¡œ ë¶„ë¦¬)
menu_predictions = {}

# ëˆ„ë½ ì›ì‹œ í”¼ì²˜ ë³´ì • ìœ í‹¸
def align_required_raw_features_for_predict(predictor: TabularPredictor, X: pd.DataFrame) -> pd.DataFrame:
    """
    í•™ìŠµ ë‹¹ì‹œ ì›ì‹œ ì…ë ¥ í”¼ì²˜(features_in) ì¤‘ í˜„ì¬ Xì— ëˆ„ë½ëœ ì»¬ëŸ¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.
    """
    try:
        required_cols = list(getattr(predictor._learner.feature_generator, 'features_in'))
    except Exception:
        required_cols = []
    # Known columns ë³´ê°•
    for col in ['days_since_launch', 'is_active_month']:
        if col not in required_cols:
            required_cols.append(col)
    # ëˆ„ë½ ë³´ì™„
    for col in required_cols:
        if col not in X.columns:
            X[col] = 0
    return X

# test í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
test_paths = sorted(glob.glob('./data/test/*.csv'))
if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    unique_menus = train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()

    for menu_name in tqdm(unique_menus, desc="ë©”ë‰´ë³„ ê°œë³„ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"):
        # âœ… ìˆ˜ì •: ë©”ë‰´ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
        menu_predictions[menu_name] = []
        
        # 1. ë©”ë‰´ë³„ ë°ì´í„° ì¤€ë¹„ (í›ˆë ¨ ë°ì´í„°ë§Œ ì‚¬ìš©)
        menu_train_data = train_full_featured[train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()
        
        if len(menu_train_data) < 30:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ë©”ë‰´ëŠ” 0ìœ¼ë¡œ ì˜ˆì¸¡
            for path in test_paths:
                basename = os.path.basename(path).replace('.csv', '')
                for i in range(7):
                    menu_predictions[menu_name].append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': 0
                    })
            continue
            
        # 2. ë©”ë‰´ë³„ ëª¨ë¸ í•™ìŠµ
        predictor_path = f'autogluon_models_menu/{menu_name.replace("/", "_").replace(" ", "")}'
        predictor = None
        
        try:
            predictor = TabularPredictor.load(predictor_path)
        except:
            pass
        
        if predictor is None:
            print(f"ğŸš€ [1ë‹¨ê³„-íƒìƒ‰] '{menu_name}' ë©”ë‰´ì˜ ëª¨ë¸ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            
            # âœ… ìˆ˜ì •: CPU ì „ìš© ì•ˆì • ì„¤ì •
            hyperparameters = {
                'GBM': [
                    {'num_boost_round': 800, 'learning_rate': 0.1, 'max_depth': 6},
                    {'num_boost_round': 1200, 'learning_rate': 0.05, 'max_depth': 8}
                ],
                'CAT': [
                    {'iterations': 800, 'learning_rate': 0.1, 'depth': 6},
                    {'iterations': 1200, 'learning_rate': 0.05, 'depth': 8}
                ],
                'XGB': [
                    {'n_estimators': 800, 'learning_rate': 0.1, 'max_depth': 6},
                    {'n_estimators': 1200, 'learning_rate': 0.05, 'max_depth': 8}
                ],
                'RF': [
                    {'n_estimators': 100, 'max_depth': 10},
                    {'n_estimators': 200, 'max_depth': 15}
                ],
                'XT': [
                    {'n_estimators': 100, 'max_depth': 10},
                    {'n_estimators': 200, 'max_depth': 15}
                ]
            }
            
            predictor = TabularPredictor(
                label='ë§¤ì¶œìˆ˜ëŸ‰',
                eval_metric='mean_absolute_error',
                path=predictor_path
            )
            
            predictor.fit(
                train_data=menu_train_data,
                hyperparameters=hyperparameters,
                time_limit=600,
                presets='medium_quality',
                num_cpus=6,
                num_gpus=0  # CPU ì „ìš©
            )
        
        # 3. ë©”ë‰´ë³„ ì˜ˆì¸¡ ìˆ˜í–‰
        for path in test_paths:
            basename = os.path.basename(path).replace('.csv', '')
            
            # âœ… ìˆ˜ì •: í‰ê°€ ë°ì´í„°ë§Œ ì‚¬ìš© (í›ˆë ¨ ë°ì´í„°ì™€ ë¶„ë¦¬)
            test_data = pd.read_csv(path)
            test_menu_data = test_data[test_data['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()
            
            if test_menu_data.empty:
                # í•´ë‹¹ ë©”ë‰´ê°€ í…ŒìŠ¤íŠ¸ì— ì—†ëŠ” ê²½ìš° 0ìœ¼ë¡œ ì˜ˆì¸¡
                for i in range(7):
                    menu_predictions[menu_name].append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                        'ë§¤ì¶œìˆ˜ëŸ‰': 0
                    })
                continue
            
            # 7ì¼ ì˜ˆì¸¡ (ê°ê° ë…ë¦½ì ìœ¼ë¡œ)
            for i in range(7):
                # ì˜ˆì¸¡í•  ë‚ ì§œ ê³„ì‚°
                last_date = pd.to_datetime(test_menu_data['ì˜ì—…ì¼ì'].max())
                target_date = last_date + pd.Timedelta(days=i+1)
                
                # âœ… ìˆ˜ì •: ì˜¬ë°”ë¥¸ í”¼ì²˜ ìƒì„± ë°©ì‹
                # ìƒˆë¡œìš´ ì˜ˆì¸¡ í–‰ì„ ì¶”ê°€í•˜ì—¬ í”¼ì²˜ ìƒì„±
                new_row = pd.DataFrame([{
                    'ì˜ì—…ì¼ì': target_date,
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': 0  # ì˜ˆì¸¡í•  ê°’ì´ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
                }])
                
                # 28ì¼ ë°ì´í„° + ìƒˆë¡œìš´ í–‰ìœ¼ë¡œ í”¼ì²˜ ìƒì„±
                combined_data = pd.concat([test_menu_data, new_row], ignore_index=True)
                featured_data = create_features(combined_data)
                
                # ë§ˆì§€ë§‰ í–‰ì˜ í”¼ì²˜ë§Œ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡
                last_features = featured_data.tail(1).copy()
                
                # ì‹œê°„ ê´€ë ¨ í”¼ì²˜ë§Œ ì—…ë°ì´íŠ¸
                last_features['ì¼'] = target_date.day
                last_features['ì›”'] = target_date.month
                last_features['ìš”ì¼'] = target_date.weekday()
                last_features['ì£¼'] = target_date.isocalendar()[1]
                last_features['ë¶„ê¸°'] = (target_date.month - 1) // 3 + 1
                last_features['ì—°'] = target_date.year
                
                # ì‚¼ê°í•¨ìˆ˜ ê¸°ë°˜ ê³„ì ˆì„± í”¼ì²˜ ì—…ë°ì´íŠ¸
                last_features['ì›”_sin'] = np.sin(2 * np.pi * target_date.month / 12)
                last_features['ì›”_cos'] = np.cos(2 * np.pi * target_date.month / 12)
                last_features['ìš”ì¼_sin'] = np.sin(2 * np.pi * target_date.weekday() / 7)
                last_features['ìš”ì¼_cos'] = np.cos(2 * np.pi * target_date.weekday() / 7)
                
                # AutoGluon ì˜ˆì¸¡
                X_test = last_features.drop(['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰'], axis=1, errors='ignore')
                prediction_ag = predictor.predict(X_test).iloc[0]
                
                # Prophet ì˜ˆì¸¡ (ì˜µì…˜)
                prediction_prophet = 0
                if Prophet is not None and len(menu_train_data) >= 50:
                    try:
                        # Prophet ëª¨ë¸ ì í•©
                        prophet_data = menu_train_data[['ì˜ì—…ì¼ì', 'ë§¤ì¶œìˆ˜ëŸ‰']].copy()
                        prophet_data.columns = ['ds', 'y']
                        prophet_data['ds'] = pd.to_datetime(prophet_data['ds'])
                        
                        model = Prophet(
                            changepoint_prior_scale=0.05,
                            seasonality_prior_scale=5.0,
                            yearly_seasonality=True,
                            weekly_seasonality=True,
                            daily_seasonality=False
                        )
                        model.fit(prophet_data)
                        
                        # Prophet ì˜ˆì¸¡
                        future = pd.DataFrame({'ds': [target_date]})
                        forecast = model.predict(future)
                        prediction_prophet = forecast['yhat'].iloc[0]
                    except:
                        prediction_prophet = 0
                
                # ê°€ì¤‘ ì•™ìƒë¸”
                if prediction_prophet > 0:
                    pred_final = PROPHET_WEIGHT * prediction_prophet + (1 - PROPHET_WEIGHT) * prediction_ag
                else:
                    pred_final = prediction_ag
                
                # ì˜ˆì¸¡ê°’ì´ ìŒìˆ˜ì¸ ê²½ìš° 0ìœ¼ë¡œ ì¡°ì •
                pred_final = max(0, pred_final)
                
                # âœ… ìˆ˜ì •: ë©”ë‰´ë³„ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
                menu_predictions[menu_name].append({
                    'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': pred_final
                })

# âœ… ìˆ˜ì •: ëª¨ë“  ë©”ë‰´ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
all_predictions = []
for menu_name in unique_menus:
    all_predictions.extend(menu_predictions[menu_name])

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
if all_predictions:
    pred_df = pd.DataFrame(all_predictions)
    
    print("\nì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    # âœ… ìˆ˜ì •: ì¤‘ë³µ ì œê±° í›„ pivot
    # ì¤‘ë³µëœ ì˜ˆì¸¡ì´ ìˆë‹¤ë©´ ë§ˆì§€ë§‰ ê°’ì„ ìœ ì§€
    pred_df = pred_df.drop_duplicates(subset=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'], keep='last')
    
    submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
    
    final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
    final_submission = final_submission.fillna(0)
    
    # âœ… ìˆ˜ì •: ì•ˆì „í•œ ì»¬ëŸ¼ ìˆœì„œ ë§¤ì¹­
    try:
        # ìƒ˜í”Œ íŒŒì¼ì˜ ì»¬ëŸ¼ ìˆœì„œë¡œ ë§ì¶”ê¸°
        available_columns = [col for col in submission_df.columns if col in final_submission.columns]
        final_submission = final_submission[available_columns]
        
        # ëˆ„ë½ëœ ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ì±„ìš°ê¸°
        missing_columns = [col for col in submission_df.columns if col not in final_submission.columns]
        for col in missing_columns:
            final_submission[col] = 0
        
        # ìµœì¢… ìˆœì„œ ë§ì¶”ê¸°
        final_submission = final_submission[submission_df.columns]
        
    except Exception as e:
        print(f"âš ï¸ ì»¬ëŸ¼ ìˆœì„œ ë§¤ì¹­ ì‹¤íŒ¨: {e}")
        print("ê¸°ë³¸ ìˆœì„œë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
        # ê¸°ë³¸ ìˆœì„œë¡œ ì €ì¥
        pass
    
    final_submission.to_csv('submission_autogluon_menu_pipeline.csv', index=False)
    print("âœ… submission_autogluon_menu_pipeline.csv íŒŒì¼ ìƒì„± ì™„ë£Œ")

    # ìµœì¢… í‰ê·  ê²€ì¦ ì ìˆ˜
    if all_menu_scores:
        avg_mae = np.mean(all_menu_scores)
        print(f"\nğŸ“Š ì „ì²´ ë©”ë‰´ì˜ í‰ê·  ê²€ì¦ MAE ì ìˆ˜: {avg_mae:.4f}")
else:
    print("\nìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

print("\n===  AutoGluon(+Prophet ë³´ì¡° ì•™ìƒë¸”) ëª¨ë¸ ===")
print("âœ… ê° ë©”ë‰´ë³„ AutoGluon ëª¨ë¸ + Prophet ë³´ì¡° ì˜ˆì¸¡ ê°€ì¤‘ ì•™ìƒë¸”")
print("âœ… Prophet ë¯¸ì„¤ì¹˜/ë°ì´í„° ë¶€ì¡± ì‹œ ìë™ìœ¼ë¡œ AutoGluon ë‹¨ë… ì˜ˆì¸¡")
print("âœ… ê³µíœ´ì¼/ì£¼ê°„/ì—°ê°„ ì‹œì¦Œì„±ê³¼ ì¶”ì„¸ë¥¼ ë³´ì¡°ë¡œ ë°˜ì˜")
print("âœ… Data Leakage ë°©ì§€ ë° PicklingError í•´ê²°")

