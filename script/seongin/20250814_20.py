import os
import glob
import random
import shutil
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.tabular import TabularPredictor
from pandas.api.types import is_object_dtype, CategoricalDtype

# --- 1. ì„¤ì • (Configuration) ---
class Config:
	"""
	í”„ë¡œì íŠ¸ ì„¤ì • ê°’ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
	"""
	# ë°ì´í„° ê²½ë¡œ
	data_path = './data/'
	train_path = os.path.join(data_path, 'train/train.csv')
	test_path_pattern = os.path.join(data_path, 'test/*.csv')
	submission_path = os.path.join(data_path, 'sample_submission.csv')
	# í–¥ìƒëœ í”¼ì²˜ê°€ í¬í•¨ëœ í•™ìŠµ ë°ì´í„° ê²½ë¡œ (ì‚¬ìš©ì ìƒì„±)
	enhanced_train_path = r'C:\GitHubRepo\AI_Forecasting_Food_and_Restaurant_Menu_Demand\script\seongin\enhanced_train.csv'
	
	# ëª¨ë¸ ë° ê²°ê³¼ ê²½ë¡œ
	model_dir = './AutogluonModels/global_model'
	submission_dir = './submissions'
	output_filename = 'submission_global_model.csv'
	
	# ì‹œë“œ
	seed = 42
	
	# AutoGluon ì„¤ì •
	time_limit = 3600  # 1ì‹œê°„ í•™ìŠµ
	presets = 'best_quality'  # ê³ í’ˆì§ˆ í”„ë¦¬ì…‹ ì‚¬ìš©
	eval_metric = 'root_mean_squared_error'  # ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•œ RMSE ì‚¬ìš©

# --- 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def set_seed(seed):
	"""
	ì‹œë“œ ê³ ì • í•¨ìˆ˜
	"""
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

def get_holiday_df():
	"""
	ê³µíœ´ì¼ ì •ë³´ë¥¼ ë‹´ì€ ë°ì´í„°í”„ë ˆì„ì„ ë°˜í™˜
	"""
holiday_dates = pd.to_datetime([
    "2023-01-01","2023-01-21","2023-01-22","2023-01-23","2023-01-24",
    "2023-03-01","2023-05-05","2023-05-27","2023-05-29","2023-06-06",
    "2023-08-15","2023-09-28","2023-09-29","2023-09-30","2023-10-03",
    "2023-10-09","2023-12-25",
    "2024-01-01","2024-02-09","2024-02-10","2024-02-11","2024-02-12",
    "2024-03-01","2024-04-10","2024-05-05","2024-05-06","2024-05-15",
    "2024-06-06","2024-08-15","2024-09-16","2024-09-17","2024-09-18",
    "2024-10-03","2024-10-09","2024-12-25",
    "2025-01-01","2025-01-27","2025-01-28","2025-01-29","2025-01-30",
    "2025-03-01","2025-03-03","2025-05-05","2025-05-06","2025-06-03",
    "2025-06-06","2025-08-15","2025-10-03","2025-10-05","2025-10-06",
    "2025-10-07","2025-10-08","2025-10-09","2025-12-25"
])
	holiday_df = pd.DataFrame(holiday_dates, columns=['ì˜ì—…ì¼ì'])
	holiday_df['is_holiday'] = 1
	return holiday_df

# --- 3. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ---
def create_features(df, holiday_df):
	"""
	ì›ì‹œ ì»¬ëŸ¼(ì˜ì—…ì¼ì, ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…, ë§¤ì¶œìˆ˜ëŸ‰)ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì†Œ/ê¸°ë³¸ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
	í–¥ìƒëœ í•™ìŠµ ë°ì´í„°(enhanced_train.csv)ì™€ì˜ ì™„ì „ ì¼ì¹˜ëŠ” ë³´ì¥í•˜ì§€ ì•Šìœ¼ë©°,
	ì˜ˆì¸¡ ì‹œ ë¶€ì¡±í•œ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ë³´ì™„í•˜ì—¬ ì •ë ¬í•©ë‹ˆë‹¤.
	"""
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    
	# 1. ë‚ ì§œ ê¸°ë°˜ í”¼ì²˜
	df['year'] = df['ì˜ì—…ì¼ì'].dt.year
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['day'] = df['ì˜ì—…ì¼ì'].dt.day
	df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
	df['quarter'] = df['ì˜ì—…ì¼ì'].dt.quarter
	df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
	
	# ì£¼ê¸°ì„± í”¼ì²˜
	df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
	df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
	df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
	df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
	
	# ê³µíœ´ì¼ í”¼ì²˜
	df = pd.merge(df, holiday_df, on='ì˜ì—…ì¼ì', how='left')
	df['is_holiday'] = df['is_holiday'].fillna(0).astype(int)
	
	# ë©”ë‰´/ì˜ì—…ì¥ ë¶„ë¦¬ ë° ê°„ë‹¨ ì¹´í…Œê³ ë¦¬
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].apply(lambda x: '_'.join(x) if x else '')
        df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
        df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ|ì‹í˜œ', na=False, case=False).astype(int)
        df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
        df['ì‹ì‚¬ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥|íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜', na=False).astype(int)
        df['ë‹¨ì²´/ëŒ€ì—¬'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ëŒ€ì—¬ë£Œ|conference|convention', na=False, case=False).astype(int)
    
	# ì‹œê³„ì—´ í”¼ì²˜ (ê°„ë‹¨ Lag/Rolling)
	df = df.sort_values(by=['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'])
    if 'ë§¤ì¶œìˆ˜ëŸ‰' in df.columns:
		grouped = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ë§¤ì¶œìˆ˜ëŸ‰']
		for lag in [7, 14, 21, 28]:
            df[f'lag_{lag}'] = grouped.shift(lag)
		shifted = grouped.shift(1)
		for window in [7, 14, 28]:
			df[f'rolling_mean_{window}'] = shifted.rolling(window, min_periods=1).mean()
			df[f'rolling_std_{window}'] = shifted.rolling(window, min_periods=1).std()
			df[f'rolling_min_{window}'] = shifted.rolling(window, min_periods=1).min()
			df[f'rolling_max_{window}'] = shifted.rolling(window, min_periods=1).max()
	
	# í›„ì²˜ë¦¬: ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±° ë° ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
        df = df.drop(columns=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])
    df = df.fillna(0)
    
	# ë²”ì£¼í˜• ì§€ì •(ëª¨ë¸ì´ ìë™ ì¸ì‹í•˜ë‚˜, ëª…ì‹œì ìœ¼ë¡œ ì§€ì •)
	for col in ['year', 'month', 'day', 'day_of_week', 'week_of_year', 'quarter']:
		if col in df.columns:
			df[col] = df[col].astype('category')
    
    return df

# ì˜ˆì¸¡ ì‹œ í•™ìŠµ í”¼ì²˜ì— ì •ë ¬/ë³´ì™„
def ensure_aligned_features(df_row: pd.DataFrame, feature_names: list, feature_dtypes: dict) -> pd.DataFrame:
	"""
	ë‹¨ì¼ í–‰ ë°ì´í„°í”„ë ˆì„(df_row)ì„ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í”¼ì²˜(feature_names)ì— ë§ì¶°
	ì»¬ëŸ¼ì„ ì •ë ¬í•˜ê³ , ëˆ„ë½ ì»¬ëŸ¼ì€ dtype ì— ë§ì¶° ì±„ì›Œ ì¶”ê°€í•©ë‹ˆë‹¤.
	 - ë²”ì£¼í˜•/ë¬¸ìì—´: 'unknown'
	 - ìˆ˜ì¹˜í˜•: 0
	"""
	for col in feature_names:
		if col not in df_row.columns:
			dt = feature_dtypes.get(col, None)
			if dt is not None and (isinstance(dt, CategoricalDtype) or is_object_dtype(dt)):
				df_row[col] = 'unknown'
			else:
				df_row[col] = 0
	return df_row.reindex(columns=feature_names)

# --- 4. ë°ì´ì½˜ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥ í•¨ìˆ˜ ---
def print_dacon_summary(config, predictor, output_path, dataset_info: str):
	"""
	ë°ì´ì½˜ ëŒ€íšŒ í˜•ì‹ì˜ ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
	"""
	leaderboard = predictor.leaderboard(silent=True)
	# AutoGluonì˜ leaderboardëŠ” scoreê°€ 'ë†’ì„ìˆ˜ë¡ ì¢‹ì€' ë°©í–¥ìœ¼ë¡œ í‘œê¸°ë©ë‹ˆë‹¤.
	try:
		best_row = leaderboard.sort_values('score_val', ascending=False).iloc[0]
		best_model = best_row['model']
	except Exception:
		best_model = str(leaderboard.iloc[0]['model'])
	
	print("\n\n" + "="*70)
	print("ğŸ† ì‹ìŒì—…ì¥ ë©”ë‰´ ìˆ˜ìš” ì˜ˆì¸¡ AI ì˜¨ë¼ì¸ í•´ì»¤í†¤ : ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ ğŸ†")
	print("="*70)
	
	print("\nâ–Œ ëŒ€íšŒ ê°œìš”")
	print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	print("  â€¢ ëŒ€íšŒëª…: LG Aimers | ì‹ìŒì—…ì¥ ë©”ë‰´ ìˆ˜ìš” ì˜ˆì¸¡ AI ì˜¨ë¼ì¸ í•´ì»¤í†¤")
	print("  â€¢ ì°¸ê°€ì: í™ì„±ì¸")
	print("  â€¢ ì œì¶œ ë°©ì‹: ë‹¨ì¼ ê¸€ë¡œë²Œ ëª¨ë¸ì„ í™œìš©í•œ ìë™í™”ëœ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸")
	print(f"  â€¢ ì‚¬ìš© ë°ì´í„°ì…‹: {dataset_info}")
	
	print("\nâ–Œ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
	print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	print(f"  â€¢ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {config.model_dir}")
	print(f"  â€¢ ìµœì¢… ì œì¶œ íŒŒì¼: {output_path}")
	print(f"  â€¢ ì‚¬ìš©ëœ ìµœìƒìœ„ ëª¨ë¸: {best_model}")
	print(f"  â€¢ í‰ê°€ ì§€í‘œ (Validation): {config.eval_metric}")
	
	print("\nâ–Œ AutoGluon ëª¨ë¸ í•™ìŠµ ë¦¬ë”ë³´ë“œ (Validation Set ê¸°ì¤€)")
	print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	print(leaderboard[['model', 'score_val', 'fit_time', 'predict_time']])
	
	print("\nâ–Œ ëŒ€íšŒ ìˆ˜ë£Œ ê¸°ì¤€ (ì°¸ê³ )")
	print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
	print("  â€¢ Public Score â‰¤ 0.711046")
	print("  â€¢ Private Score â‰¤ 0.693935")
	print("\n  [ì°¸ê³ ] ìœ„ ë¦¬ë”ë³´ë“œì˜ 'score_val'ì€ Validation ë°ì´í„°ì…‹ì— ëŒ€í•œ ì ìˆ˜ì´ë©°,")
	print("         DACONì˜ Public/Private Scoreì™€ëŠ” ë°ì´í„°ì…‹ì´ ë‹¬ë¼ ì§ì ‘ ë¹„êµëŠ” ì–´ë µìŠµë‹ˆë‹¤.")
	
	print("\n" + "="*70)
	print("ğŸ‰ ëª¨ë“  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ‰")
	print("="*70)

# --- 5. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
def main():
	config = Config()
	set_seed(config.seed)
	
	if os.path.exists(config.model_dir):
		print(f"ê¸°ì¡´ ëª¨ë¸ í´ë”({config.model_dir})ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
		shutil.rmtree(config.model_dir)
	os.makedirs(config.submission_dir, exist_ok=True)
	
	print("ë°ì´í„° ë¡œë”© ì¤‘...")
	# í–¥ìƒëœ í•™ìŠµ ë°ì´í„° ì‚¬ìš©
	train_df = pd.read_csv(config.enhanced_train_path)
	submission_df = pd.read_csv(config.submission_path)
	holiday_df = get_holiday_df()
	# ì•ˆì „ì¥ì¹˜
	if 'ë§¤ì¶œìˆ˜ëŸ‰' in train_df.columns:
		train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)
	
	print("í•™ìŠµ ë°ì´í„° ì¤€ë¹„(ì´ë¯¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ)...")
	# enhanced_train.csvëŠ” ì´ë¯¸ í”¼ì²˜ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆë‹¤ê³  ê°€ì •
	train_featured = train_df.copy()
	# í•™ìŠµì— ë¶ˆí•„ìš”í•œ ëª…ì‹œì  ë“œë¡­ (ë‚ ì§œë§Œ ì œê±°, ë¼ë²¨ì€ ìœ ì§€)
	if 'ì˜ì—…ì¼ì' in train_featured.columns:
		train_featured = train_featured.drop(columns=['ì˜ì—…ì¼ì'])
	
	# í•™ìŠµ í”¼ì²˜ ëª©ë¡ ë° dtype ì €ì¥
	if 'ë§¤ì¶œìˆ˜ëŸ‰' not in train_featured.columns:
		raise ValueError("í•™ìŠµ ë°ì´í„°ì— 'ë§¤ì¶œìˆ˜ëŸ‰' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
	used_feature_columns = [c for c in train_featured.columns if c != 'ë§¤ì¶œìˆ˜ëŸ‰']
	feature_dtypes = train_featured[used_feature_columns].dtypes.to_dict()
	
	print("AutoGluon ê¸€ë¡œë²Œ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
            predictor = TabularPredictor(
                label='ë§¤ì¶œìˆ˜ëŸ‰',
		path=config.model_dir,
		eval_metric=config.eval_metric,
		problem_type='regression'
            ).fit(
		train_featured,
		time_limit=config.time_limit,
		presets=config.presets,
		ag_args_fit={'num_gpus': 0},
		hyperparameters={'GBM': {}, 'CAT': {}, 'XGB': {}, 'RF': {}, 'XT': {}}
	)
	
	print("ëª¨ë¸ í•™ìŠµ ì™„ë£Œ. ë¦¬ë”ë³´ë“œ:")
	print(predictor.leaderboard(silent=True))
	
	print("ìˆœí™˜ ì˜ˆì¸¡ ì‹œì‘...")
	test_paths = sorted(glob.glob(config.test_path_pattern))
	all_predictions = []
	
	for path in tqdm(test_paths, desc="Test íŒŒì¼ë³„ ìˆœí™˜ ì˜ˆì¸¡"):
            test_file_df = pd.read_csv(path)
            basename = os.path.basename(path).replace('.csv', '')
		unique_menus_in_test = test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
		
		for menu_name in unique_menus_in_test:
			# ê³¼ê±° ë°ì´í„° êµ¬ì„±(í•„ìš” ìµœì†Œ ì»¬ëŸ¼ë§Œ ì‚¬ìš©)
            historical_data = pd.concat([
				train_df[train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name][['ì˜ì—…ì¼ì','ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…','ë§¤ì¶œìˆ˜ëŸ‰']],
				test_file_df[test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name][['ì˜ì—…ì¼ì','ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…','ë§¤ì¶œìˆ˜ëŸ‰']]
            ]).copy()
            
            for i in range(7):
				last_date = pd.to_datetime(historical_data['ì˜ì—…ì¼ì']).max()
                next_date = last_date + pd.Timedelta(days=1)
                new_row = pd.DataFrame([{'ì˜ì—…ì¼ì': next_date, 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name, 'ë§¤ì¶œìˆ˜ëŸ‰': np.nan}])
                
                combined_for_feature = pd.concat([historical_data, new_row], ignore_index=True)
				featured_data_min = create_features(combined_for_feature, holiday_df)
				X_test_row = featured_data_min.tail(1).drop(columns=['ì˜ì—…ì¼ì', 'ë§¤ì¶œìˆ˜ëŸ‰'])
                
				# í•™ìŠµ í”¼ì²˜ì— ë§ì¶° ì •ë ¬/ë³´ì™„ (dtype-aware)
				X_test_aligned = ensure_aligned_features(X_test_row, used_feature_columns, feature_dtypes)
                
				pred = predictor.predict(X_test_aligned, model='WeightedEnsemble_L2').iloc[0]
				pred = max(0, round(pred))
                
                all_predictions.append({
                    'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': pred
                })

                new_prediction_row = new_row.copy()
                new_prediction_row['ë§¤ì¶œìˆ˜ëŸ‰'] = pred
                historical_data = pd.concat([historical_data, new_prediction_row], ignore_index=True)

	print("ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    if all_predictions:
        pred_df = pd.DataFrame(all_predictions)
		submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰')
		final_submission = submission_df.set_index('ì˜ì—…ì¼ì')
        final_submission.update(submission_pivot)
        final_submission.reset_index(inplace=True)
		final_submission = final_submission.fillna(0)
    else:
        final_submission = submission_df.copy()

	output_path = os.path.join(config.submission_dir, config.output_filename)
	final_submission.to_csv(output_path, index=False, encoding='utf-8-sig')
	
	# ë°ì´ì½˜ í˜•ì‹ì˜ ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
	dataset_info = f"enhanced_train.csv (columns={len(train_df.columns)})"
	print_dacon_summary(config, predictor, output_path, dataset_info)

if __name__ == "__main__":
	main()
