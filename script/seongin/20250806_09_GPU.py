# ==============================================================================
# Google Colab í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì•ˆë‚´
# ==============================================================================
# 1. ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½: ë©”ë‰´ì—ì„œ [ëŸ°íƒ€ì„] > [ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½]ì„ ì„ íƒí•˜ê³ , í•˜ë“œì›¨ì–´ ê°€ì†ê¸°ë¥¼ 'GPU'ë¡œ ì„¤ì •í•˜ì„¸ìš”.
#
# 2. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: ì•„ë˜ ì½”ë“œë¥¼ Colab ì…€ì—ì„œ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
# !pip install autogluon.tabular~=1.0.0
#
# 3. ë°ì´í„° ì¤€ë¹„:
#    - ì˜µì…˜ A: Google Drive ì—°ë™
#      from google.colab import drive
#      drive.mount('/content/drive')
#      # ì•„ë˜ DATA_PATHë¥¼ ìì‹ ì˜ Google Drive ë‚´ í”„ë¡œì íŠ¸ í´ë” ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”.
#      # ì˜ˆ: DATA_PATH = '/content/drive/MyDrive/AI_Forecasting_Food_and_Restaurant_Menu_Demand/'
#      DATA_PATH = './'
#
#    - ì˜µì…˜ B: ì§ì ‘ íŒŒì¼ ì—…ë¡œë“œ
#      Colabì˜ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ 'íŒŒì¼' íƒ­ì„ ì—´ê³ , 'ì„¸ì…˜ ì €ì¥ì†Œì— ì—…ë¡œë“œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬
#      data í´ë”(train, test í¬í•¨)ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
#      DATA_PATH = './' # ì´ ê²½ìš° ê²½ë¡œëŠ” ê¸°ë³¸ê°’ì¸ í˜„ì¬ ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤.
# ==============================================================================

import os
import glob
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.tabular import TabularPredictor

# --- Colab í™˜ê²½ì— ë§ê²Œ ê²½ë¡œ ì„¤ì • ---
# Google Driveë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ì•„ë˜ ê²½ë¡œë¥¼ ìì‹ ì˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
# ì˜ˆ: PROJECT_PATH = '/content/drive/MyDrive/AI_Forecasting_Food_and_Restaurant_Menu_Demand/'
PROJECT_PATH = './' 
DATA_PATH = os.path.join(PROJECT_PATH, 'data/')
MODEL_PATH = os.path.join(PROJECT_PATH, 'autogluon_models_gpu/')

# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    # GPU ê´€ë ¨ ì‹œë“œ ê³ ì •ì„ ì›í•œë‹¤ë©´ PyTorch ì„¤ì¹˜ í›„ ì•„ë˜ ì½”ë“œ ì¶”ê°€
    # import torch
    # torch.manual_seed(seed)
    # if torch.cuda.is_available():
    #     torch.cuda.manual_seed_all(seed)

set_seed(42)

# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)

# í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
def create_features(df):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    df['day'] = df['ì˜ì—…ì¼ì'].dt.day
    df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].apply(lambda x: '_'.join(x) if x else '')

    if 'ë©”ë‰´ëª…' in df.columns:
        spring_keywords = ['ë¸ŒëŸ°ì¹˜', 'ìƒëŸ¬ë“œ', 'ë¦¬ì¡°ë˜', 'ê·¸ë¦´ë“œ', 'ì‹œì €']
        df['ë´„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(spring_keywords), na=False).astype(int)
        
        summer_keywords = ['ice', 'ì•„ì´ìŠ¤', 'ì—ì´ë“œ', 'ì‹í˜œ', 'ìƒìˆ˜', 'ëƒ‰ë©´', 'í•´ë¬¼', 'ëìŠ¤íƒ€', 'ì‰¬ë¦¼í”„', 'í•´ì‚°ë¬¼']
        df['ì—¬ë¦„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(summer_keywords), na=False, case=False).astype(int)
        
        fall_keywords = ['ë§‰ê±¸ë¦¬', 'ì†Œì£¼', 'ë§¥ì£¼', 'ì°¸ì´ìŠ¬', 'ì¹´ìŠ¤', 'beer']
        df['ê°€ì„_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(fall_keywords), na=False, case=False).astype(int)
        
        winter_keywords = ['êµ­', 'íƒ•', 'ì°Œê°œ', 'í•´ì¥', 'hot', 'í•«ë„ê·¸', 'ë–¡ë³¶ì´', 'ê¼¬ì¹˜ì–´ë¬µ', 'íŒŒì „', 'ë¶ˆê³ ê¸°', 'ê°ˆë¹„', 'ëˆê¹ŒìŠ¤', 'bbq', 'í•œìš°', 'ì‚¼ê²¹']
        df['ê²¨ìš¸_íŠ¹í™”ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('|'.join(winter_keywords), na=False, case=False).astype(int)
        
        df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
        df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False).astype(int)
        df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
        df['í•œì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False).astype(int)
        df['ì–‘ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False).astype(int)
        df['ë‹¨ì²´ë©”ë‰´'] = df['ë©”ë‰´ëª…'].str.contains('ë‹¨ì²´|íŒ¨í‚¤ì§€|ì„¸íŠ¸|ë¸ŒëŸ°ì¹˜', na=False).astype(int)
        df['ëŒ€ì—¬ë£Œ'] = df['ë©”ë‰´ëª…'].str.contains('ëŒ€ì—¬ë£Œ|ì´ìš©ë£Œ|conference|convention', na=False, case=False).astype(int)
        df['í¬ë ˆìŠ¤íŠ¸ë¦¿'] = (df['ì˜ì—…ì¥ëª…'] == 'í¬ë ˆìŠ¤íŠ¸ë¦¿').astype(int)
        df['ì¹´í˜í…Œë¦¬ì•„'] = (df['ì˜ì—…ì¥ëª…'] == 'ì¹´í˜í…Œë¦¬ì•„').astype(int)
        df['í™”ë‹´ìˆ²ì£¼ë§‰'] = (df['ì˜ì—…ì¥ëª…'] == 'í™”ë‹´ìˆ²ì£¼ë§‰').astype(int)
        df['ë‹´í•˜'] = (df['ì˜ì—…ì¥ëª…'] == 'ë‹´í•˜').astype(int)
        df['ë¯¸ë¼ì‹œì•„'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¯¸ë¼ì‹œì•„').astype(int)
        df['ëŠí‹°ë‚˜ë¬´'] = (df['ì˜ì—…ì¥ëª…'] == 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ').astype(int)
        df['ë¼ê·¸ë¡œíƒ€'] = (df['ì˜ì—…ì¥ëª…'] == 'ë¼ê·¸ë¡œíƒ€').astype(int)
        df['ì—°íšŒì¥'] = (df['ì˜ì—…ì¥ëª…'] == 'ì—°íšŒì¥').astype(int)
        df['í™”ë‹´ìˆ²ì¹´í˜'] = (df['ì˜ì—…ì¥ëª…'] == 'í™”ë‹´ìˆ²ì¹´í˜').astype(int)

    sort_keys = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'] if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else ['ì˜ì—…ì¼ì']
    df = df.sort_values(sort_keys)
    
    if 'ë§¤ì¶œìˆ˜ëŸ‰' in df.columns:
        gb_key = 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else 'ì˜ì—…ì¼ì'
        gb = df.groupby(gb_key)['ë§¤ì¶œìˆ˜ëŸ‰']
        for lag in [1, 2, 3, 7, 14]:
            df[f'lag_{lag}'] = gb.shift(lag)
        for window in [7, 14, 28]:
            df[f'rolling_mean_{window}'] = gb.shift(1).rolling(window).mean()
            df[f'rolling_std_{window}'] = gb.shift(1).rolling(window).std()
    
    df['month'] = df['month'].astype(str)
    df['day'] = df['day'].astype(str)
    df['week_of_year'] = df['week_of_year'].astype(str)
    df['day_of_week'] = df['day_of_week'].astype(str)
    df['year'] = df['year'].astype(str)
    df['season'] = df['season'].astype(str)

    if 'ë©”ë‰´ëª…' in df.columns:
        df = df.drop(columns=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])

    df = df.fillna(0)
    
    return df

# ë°ì´í„° ë¡œë“œ
try:
    train_df = pd.read_csv(os.path.join(DATA_PATH, 'train/train.csv'))
    submission_df = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))
    test_paths = sorted(glob.glob(os.path.join(DATA_PATH, 'test/*.csv')))
except FileNotFoundError:
    print("="*50)
    print("ğŸš¨ ë°ì´í„° íŒŒì¼(train.csv, sample_submission.csv)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ğŸš¨")
    print("Colab í™˜ê²½ì˜ ê²½ìš°, ìƒë‹¨ì˜ 'ë°ì´í„° ì¤€ë¹„' ì„¹ì…˜ ì•ˆë‚´ì— ë”°ë¼ íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ê±°ë‚˜ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    print("="*50)
    # Colab í™˜ê²½ì—ì„œ ì—ëŸ¬ ë°œìƒ ì‹œ ì‹¤í–‰ì„ ì¤‘ì§€í•˜ë„ë¡ ì²˜ë¦¬
    import sys
    sys.exit()

train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)

# í”¼ì²˜ ìƒì„±
train_full_featured = create_features(train_df)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
all_predictions = []

if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    unique_menus = train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
    
    for menu_name in tqdm(unique_menus, desc="ë©”ë‰´ë³„ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"):
        
        menu_train_data = train_full_featured[train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].copy()
        
        if len(menu_train_data) < 30:
            continue
            
        train_data_ag = menu_train_data.drop(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'])

        # Colabì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì • ë³€ê²½
        predictor_path = os.path.join(MODEL_PATH, f'{menu_name.replace("/", "_").replace(" ", "")}')

        # "ìŠ¤ë§ˆíŠ¸í•œ ì´ì–´í•˜ê¸°" ê¸°ëŠ¥: ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œ í•™ìŠµ
        if os.path.exists(predictor_path):
            print(f"âœ… ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ ë°œê²¬: {menu_name}. ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
            predictor = TabularPredictor.load(predictor_path)
        else:
            print(f"ğŸš€ ìƒˆë¡œìš´ ëª¨ë¸ í•™ìŠµ ì‹œì‘: {menu_name}")
            predictor = TabularPredictor(
                label='ë§¤ì¶œìˆ˜ëŸ‰',
                path=predictor_path,
                problem_type='regression',
                eval_metric='root_mean_squared_error'
            ).fit(
                train_data_ag,
                presets='best_quality',
                time_limit=180, 
                # GPU ì‚¬ìš© ì„¤ì •!
                ag_args_fit={'num_gpus': 1} 
            )

        for path in test_paths:
            test_file_df = pd.read_csv(path)
            
            if menu_name not in test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique():
                continue

            basename = os.path.basename(path).replace('.csv', '')
            
            historical_data = pd.concat([
                train_full_featured[train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name],
                test_file_df[test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name]
            ]).copy()
            historical_data['ì˜ì—…ì¼ì'] = pd.to_datetime(historical_data['ì˜ì—…ì¼ì'])
            historical_data = historical_data.sort_values(by='ì˜ì—…ì¼ì').tail(28)

            for i in range(7):
                last_date = historical_data['ì˜ì—…ì¼ì'].max()
                next_date = last_date + pd.Timedelta(days=1)
                
                new_row = pd.DataFrame([{'ì˜ì—…ì¼ì': next_date, 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name, 'ë§¤ì¶œìˆ˜ëŸ‰': np.nan}])
                
                combined_for_feature = pd.concat([historical_data, new_row], ignore_index=True)
                featured_data = create_features(combined_for_feature)
                
                X_test = featured_data.tail(1).drop(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰'])
                
                pred = predictor.predict(X_test).iloc[0]
                pred = max(0, pred)
                
                all_predictions.append({
                    'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': pred
                })

                update_row = featured_data.tail(1).copy()
                update_row['ë§¤ì¶œìˆ˜ëŸ‰'] = pred
                historical_data = pd.concat([historical_data, update_row], ignore_index=True)

if all_predictions:
    pred_df = pd.DataFrame(all_predictions)
    
    print("ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
    
    final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
    final_submission = final_submission.fillna(0)
    
    final_submission = final_submission[submission_df.columns]
    
    submission_filename = os.path.join(PROJECT_PATH, 'submission_autogluon_gpu.csv')
    final_submission.to_csv(submission_filename, index=False)
    print(f"{submission_filename} íŒŒì¼ ìƒì„± ì™„ë£Œ")
else:
    print("ìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

print("\n=== ğŸ† AutoGluon (GPU ìµœì í™”)ì„ ì´ìš©í•œ ìë™í™” ëª¨ë¸ ===")
print("âœ… Colab GPU í™˜ê²½ì— ë§ê²Œ ì„¤ì • ë³€ê²½")
print("âœ… ê° ë©”ë‰´ë³„ë¡œ ë…ë¦½ì ì¸ ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ ì •í™•ë„ í–¥ìƒ ì‹œë„")
print("âœ… AutoGluonì´ ìë™ìœ¼ë¡œ ìµœì ì˜ ëª¨ë¸ íƒìƒ‰ ë° ì•™ìƒë¸” ìˆ˜í–‰")
print("\nğŸ¯ ìˆ˜ë£Œ ê¸°ì¤€ ëª©í‘œ:")
print("  â€¢ Public Score â‰¤ 0.711046")
print("  â€¢ Private Score â‰¤ 0.693935")

