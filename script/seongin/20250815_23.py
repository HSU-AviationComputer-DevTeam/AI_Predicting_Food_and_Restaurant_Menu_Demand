import os
import glob
import random
import shutil
import numpy as np
import pandas as pd
from tqdm import tqdm
from autogluon.tabular import TabularPredictor
from autogluon.core.metrics import make_scorer
# sklearn imports ì œê±° (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)

# Prophet (ì˜µì…˜): ë¯¸ì„¤ì¹˜ ì‹œ ìë™ ë¹„í™œì„±í™”
try:
    from prophet import Prophet
except Exception:
    Prophet = None

# Prophet ê°€ì¤‘ì¹˜ (ìµœì¢… ì•™ìƒë¸”: final = (1-w)*AG + w*Prophet)
PROPHET_WEIGHT = 0.2  # ê°€ì¤‘ì¹˜ ê°ì†Œë¡œ AutoGluon ì„±ëŠ¥ í™œìš©
ANALYSIS_PATH = 'autogluon_analysis'
TOP_N_FEATURES = 7 # í”¼ì²˜ ì„ íƒ ì‹œ ì‚¬ìš©í•  ìƒìœ„ í”¼ì²˜ ê°œìˆ˜


# DACON ëŒ€íšŒìš© SMAPE í‰ê°€ ì§€í‘œ ì •ì˜
def smape_metric(y_true, y_pred):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    # ëŒ€íšŒ ê·œì¹™: ì‹¤ì œ ë§¤ì¶œ ìˆ˜ëŸ‰ì´ 0ì¸ ê²½ìš°ëŠ” í‰ê°€ì—ì„œ ì œì™¸
    mask = y_true != 0
    
    # ëª¨ë“  ì‹¤ì œ ê°’ì´ 0ì¸ ê²½ìš°, SMAPEëŠ” 0ìœ¼ë¡œ ì •ì˜
    if not np.any(mask):
        return 0.0

    y_true = y_true[mask]
    y_pred = y_pred[mask]
    
    # SMAPE ê³„ì‚°
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    
    # ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²½ìš°ë¥¼ ë°©ì§€ (ì•ˆì „ì¥ì¹˜ë¡œ ë¶„ëª¨ê°€ 0ì´ë©´ ê²°ê³¼ëŠ” 0)
    ratio = np.where(denominator == 0, 0, numerator / denominator)
    
    return np.mean(ratio) * 100

# AutoGluonìš© Scorer ìƒì„±
# ëŒ€íšŒì˜ ê°€ì¤‘ì¹˜ SMAPEëŠ” ë¹„ê³µê°œì´ë¯€ë¡œ, ì¼ë°˜ SMAPEë¡œ ê²€ì¦ ì ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
smape_scorer = make_scorer(name='smape',
                           score_func=smape_metric,
                           optimum=0,
                           greater_is_better=False)


# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

set_seed(42)


# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ ë° í•¨ìˆ˜
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03", 
    "2023-10-09", "2023-12-25",
    "2024-01-01", "2024-02-09", "2024-02-10", "2024-02-11", "2024-02-12", 
    "2024-03-01", "2024-04-10", "2024-05-05", "2024-05-06", "2024-05-15", 
    "2024-06-06", "2024-08-15", "2024-09-16", "2024-09-17", "2024-09-18", 
    "2024-10-03", "2024-10-09", "2024-12-25"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)


def build_prophet_holidays_df():
    hd = pd.DataFrame({
        'holiday': 'kr_holiday',
        'ds': holiday_dates
    })
    return hd

# Prophet ë³´ì¡° ì˜ˆì¸¡ ìºì‹œ: ëª¨ë¸ ë° ë‚ ì§œë³„ ì˜ˆì¸¡ê°’
prophet_model_cache = {}
prophet_yhat_by_date_cache = {}


def get_or_fit_prophet_model(train_df_raw: pd.DataFrame, menu_name: str):
    if Prophet is None:
        return None, None
    if menu_name in prophet_model_cache:
        return prophet_model_cache[menu_name]

    series = train_df_raw.loc[train_df_raw['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name, ['ì˜ì—…ì¼ì', 'ë§¤ì¶œìˆ˜ëŸ‰']].copy()
    if series.empty or series['ë§¤ì¶œìˆ˜ëŸ‰'].count() < 30:
        return None, None

    series = series.sort_values('ì˜ì—…ì¼ì')
    last_train_date = pd.to_datetime(series['ì˜ì—…ì¼ì']).max()
    df_p = pd.DataFrame({'ds': pd.to_datetime(series['ì˜ì—…ì¼ì']), 'y': np.log1p(series['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))})

    try:
        m = Prophet(
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=False,
            changepoint_prior_scale=0.1,
            seasonality_prior_scale=10.0,
            holidays=build_prophet_holidays_df()
        )
        m.fit(df_p)
        prophet_model_cache[menu_name] = (m, last_train_date)
        return m, last_train_date
    except Exception:
        return None, None


def get_prophet_yhat_for_date(menu_name: str, target_date: pd.Timestamp) -> float | None:
    """
    ëª©í‘œ ë‚ ì§œì— ëŒ€í•œ Prophet yhatì„ ë°˜í™˜. í•„ìš” ì‹œ ë¯¸ë˜ í”„ë ˆì„ì„ í™•ì¥í•˜ì—¬ ìºì‹œí•©ë‹ˆë‹¤.
    """
    if Prophet is None:
        return None

    # ëª¨ë¸ ì¤€ë¹„
    m, last_train_date = prophet_model_cache.get(menu_name, (None, None))
    if m is None:
        # ëª¨ë¸ì´ ì—†ë‹¤ë©´ í•™ìŠµ ì‹œë„ (train_dfëŠ” ì „ì—­ ë²”ìœ„ì—ì„œ ì ‘ê·¼)
        return None

    if target_date <= last_train_date:
        return None

    # ìºì‹œ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    if menu_name not in prophet_yhat_by_date_cache:
        prophet_yhat_by_date_cache[menu_name] = {}

    yhat_map = prophet_yhat_by_date_cache[menu_name]
    if target_date in yhat_map:
        return yhat_map[target_date]

    # í•„ìš”í•œ ê¸°ê°„ê¹Œì§€ ë¯¸ë˜ ìƒì„± ë° ì˜ˆì¸¡
    periods = (target_date - last_train_date).days
    if periods <= 0:
        return None
    try:
        future = m.make_future_dataframe(periods=periods, freq='D', include_history=False)
        fcst = m.predict(future)[['ds', 'yhat']]
        # ìºì‹œì— ì €ì¥
        for _, row in fcst.iterrows():
            ds = pd.to_datetime(row['ds'])
            yhat = max(0.0, float(np.expm1(row['yhat'])))
            yhat_map[ds] = yhat
        return yhat_map.get(target_date)
    except Exception:
        return None


# í”¼ì²˜ ìƒì„± í•¨ìˆ˜ (ê³„ì ˆë³„ ë©”ë‰´ íŠ¹ì„± ì¶”ê°€)
def create_features(df):
    df = df.copy()
    df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
    df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
    df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)
    df['month'] = df['ì˜ì—…ì¼ì'].dt.month
    # day, week_of_year ì œê±° (ì›”ë³„/ê³„ì ˆ íŒ¨í„´ìœ¼ë¡œ ì¶©ë¶„)
    df['season'] = df['month'] % 12 // 3 + 1
    df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
    df['year'] = df['ì˜ì—…ì¼ì'].dt.year

    # ì˜ì—…ì¥ëª…ê³¼ ë©”ë‰´ëª… ë¶„ë¦¬
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].apply(lambda x: '_'.join(x) if x else '')

    # ë©”ë‰´ë³„ ëª¨ë¸ë§ì—ì„œëŠ” ë©”ë‰´ íŠ¹ì„± í”¼ì²˜ê°€ ëª¨ë‘ ë™ì¼í•œ ê°’ì„ ê°€ì§€ë¯€ë¡œ ì œì™¸
    # (ì „ì²´ ë©”ë‰´ í†µí•© ëª¨ë¸ì—ì„œë§Œ ìœ ìš©í•¨)

    # ì‹œê°„ í”¼ì²˜
    sort_keys = ['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¼ì'] if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else ['ì˜ì—…ì¼ì']
    df = df.sort_values(sort_keys)
    
    # ì¶œì‹œ ëŒ€ë¹„ ê²½ê³¼ì¼ ë° ì›” í™œì„± í”Œë˜ê·¸ ìƒì„±
    # days_since_launch: ê° ë©”ë‰´ê°€ ë“±ì¥í•œ ìµœì´ˆ ë‚ ì§œë¡œë¶€í„°ì˜ ê²½ê³¼ ì¼ìˆ˜
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        min_date_by_menu = df.groupby('ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…')['ì˜ì—…ì¼ì'].transform('min')
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - min_date_by_menu).dt.days
    else:
        df['days_since_launch'] = (df['ì˜ì—…ì¼ì'] - df['ì˜ì—…ì¼ì'].min()).dt.days

    # is_active_month: í•´ë‹¹ ì›”ì— ì´ë¯¸ ê°™ì€ ë©”ë‰´ê°€ í•œ ë²ˆì´ë¼ë„ ë“±ì¥í–ˆëŠ”ì§€ ì—¬ë¶€(ë™ì›” 2ë²ˆì§¸ ê´€ì¸¡ë¶€í„° 1)
    df['yyyymm'] = df['ì˜ì—…ì¼ì'].dt.to_period('M').astype(str)
    if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns:
        df['is_active_month'] = (df.groupby(['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'yyyymm']).cumcount() > 0).astype(int)
    else:
        df['is_active_month'] = (df.groupby(['yyyymm']).cumcount() > 0).astype(int)

    if 'ë§¤ì¶œìˆ˜ëŸ‰' in df.columns:
        gb_key = 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' if 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…' in df.columns else 'ì˜ì—…ì¼ì'
        gb = df.groupby(gb_key)['ë§¤ì¶œìˆ˜ëŸ‰']
        for lag in [1, 2, 3, 7, 14]:
            df[f'lag_{lag}'] = gb.shift(lag)
        # 7ì¼ rollingë§Œ ì‚¬ìš© (14ì¼, 28ì¼ì€ ê³¼ì í•© ìœ„í—˜)
        for window in [7]:
            df[f'rolling_mean_{window}'] = gb.shift(1).rolling(window).mean()
            df[f'rolling_std_{window}'] = gb.shift(1).rolling(window).std()
    
    # AutoGluonì´ ë‚ ì§œ ê´€ë ¨ í”¼ì²˜ë¥¼ ë²”ì£¼í˜•ìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ íƒ€ì… ë³€ê²½
    df['month'] = df['month'].astype(str)
    df['day_of_week'] = df['day_of_week'].astype(str)
    df['year'] = df['year'].astype(str)
    df['season'] = df['season'].astype(str)

    # ë¶ˆí•„ìš”í•œ ì›ë³¸ ì»¬ëŸ¼ ì œê±°
    # 'ë©”ë‰´ëª…'ì€ ì´ì œ ëª¨ë¸ì´ ë©”ë‰´ë¥¼ êµ¬ë¶„í•˜ëŠ” í•µì‹¬ í”¼ì²˜ë¡œ ì‚¬ìš©ë˜ë¯€ë¡œ ì‚­ì œí•˜ì§€ ì•ŠìŒ
    if 'ì˜ì—…ì¥ëª…' in df.columns:
        df = df.drop(columns=['ì˜ì—…ì¥ëª…'])

    # ë‚´ë¶€ ê³„ì‚°ìš© ì„ì‹œ ì»¬ëŸ¼ ì œê±°
    if 'yyyymm' in df.columns:
        df = df.drop(columns=['yyyymm'])

    df = df.fillna(0)
    
    return df

# ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv('./data/train/train.csv')
train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0)
submission_df = pd.read_csv('./data/sample_submission.csv')

# Prophet ëª¨ë¸ ë¯¸ë¦¬ ì í•©(ë©”ë‰´ë³„)
if Prophet is not None:
    unique_menus_for_prophet = train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
    for _menu in tqdm(unique_menus_for_prophet, desc='Prophet ëª¨ë¸ ì í•©', leave=False):
        m, last_d = get_or_fit_prophet_model(train_df, _menu)
        # ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ (ìºì‹œì—ëŠ” ì¶”ê°€ ì•ˆ ë¨)

# í”¼ì²˜ ìƒì„±
train_full_featured = create_features(train_df)

# ë¶„ì„ ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±
os.makedirs(ANALYSIS_PATH, exist_ok=True)

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
all_predictions = []
all_menu_scores = [] # ë©”ë‰´ë³„ ê²€ì¦ ì ìˆ˜ ì €ì¥ ë¦¬ìŠ¤íŠ¸

# ëˆ„ë½ ì›ì‹œ í”¼ì²˜ ë³´ì • ìœ í‹¸
def align_required_raw_features_for_predict(predictor: TabularPredictor, X: pd.DataFrame) -> pd.DataFrame:
    """
    í•™ìŠµ ë‹¹ì‹œ ì›ì‹œ ì…ë ¥ í”¼ì²˜(features_in) ì¤‘ í˜„ì¬ Xì— ëˆ„ë½ëœ ì»¬ëŸ¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ì™„í•©ë‹ˆë‹¤.
    - ê¸°ë³¸ê°’: 0 (ìˆ˜ì¹˜í˜• ê°€ì •). ë¬¸ìì—´/ë²”ì£¼í˜•ì¼ ê°€ëŠ¥ì„± ìˆëŠ” ê²½ìš°ì—ë„ 0ìœ¼ë¡œ ì±„ìš°ë˜, AutoGluonì´ ë‚´ë¶€ ì¸ì½”ë”© ì²˜ë¦¬.
    - ë‚´ë¶€ í”„ë¼ì´ë¹— ì†ì„± ì ‘ê·¼ì„ ì‹œë„í•˜ê³  ì‹¤íŒ¨í•˜ë©´ ìµœì†Œí•œ known ì»¬ëŸ¼('days_since_launch','is_active_month')ë§Œ ë³´ì™„.
    """
    try:
        required_cols = list(getattr(predictor._learner.feature_generator, 'features_in'))  # type: ignore[attr-defined]
    except Exception:
        required_cols = []
    # Known columns ë³´ê°•
    for col in ['days_since_launch', 'is_active_month']:
        if col not in required_cols:
            required_cols.append(col)
    # ëˆ„ë½ ë³´ì™„
    for col in required_cols:
        if col not in X.columns:
            X[col] = 0
    return X

# test í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
test_paths = sorted(glob.glob('./data/test/*.csv'))
if not test_paths:
    print("test í´ë”ì— ì˜ˆì¸¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ë§¤ì¥ë³„ ëª¨ë¸ë§ì„ ìœ„í•´ 'ì˜ì—…ì¥ëª…' í”¼ì²˜ ìƒì„±
    train_full_featured['ì˜ì—…ì¥ëª…'] = train_full_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
    unique_restaurants = train_full_featured['ì˜ì—…ì¥ëª…'].unique()

    for restaurant_name in tqdm(unique_restaurants, desc="ë§¤ì¥ë³„ í†µí•© ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡"):
        # 1. ë§¤ì¥ë³„ ë°ì´í„° ì¤€ë¹„
        restaurant_train_data = train_full_featured[train_full_featured['ì˜ì—…ì¥ëª…'] == restaurant_name].copy()
        
        if len(restaurant_train_data) < 50: # í•™ìŠµì— í•„ìš”í•œ ìµœì†Œ ë°ì´í„° ìˆ˜
            continue
            
        # AutoGluon í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
        train_data_ag = restaurant_train_data.drop(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ì˜ì—…ì¥ëª…'])

        # ê²½ë¡œ ì„¤ì •
        predictor_path = f'autogluon_models_restaurant/{restaurant_name.replace("/", "_").replace(" ", "")}'
        
        predictor = None
        if os.path.exists(predictor_path):
            try:
                print(f"âœ… ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ ë°œê²¬: {restaurant_name}. ë¶ˆëŸ¬ì˜¤ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
                predictor = TabularPredictor.load(predictor_path)
            except Exception as e:
                print(f"ğŸš¨ ëª¨ë¸ '{restaurant_name}' ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨ (ì˜¤ë¥˜: {e}). ì†ìƒëœ ëª¨ë¸ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
                shutil.rmtree(predictor_path)
                predictor = None
        
        if predictor is None:
            print(f"ğŸš€ ìƒˆë¡œìš´ í†µí•© ëª¨ë¸ í•™ìŠµ ì‹œì‘: {restaurant_name}")
            hyperparameters = {
                'GBM': {}, 'CAT': {}, 'XGB': {}, 'RF': {}, 'XT': {}
            }
            
            predictor = TabularPredictor(
                label='ë§¤ì¶œìˆ˜ëŸ‰', path=predictor_path, problem_type='regression', eval_metric=smape_scorer
            ).fit(
                train_data_ag, hyperparameters=hyperparameters,
                time_limit=600, # ë§¤ì¥ë³„ ëª¨ë¸ì€ ë” ë§ì€ ë°ì´í„°ë¥¼ ë‹¤ë£¨ë¯€ë¡œ ì‹œê°„ ì¦ê°€
                presets='medium_quality',
                num_bag_folds=5, num_bag_sets=1, ag_args_fit={'num_gpus': 0}
            )

        leaderboard = predictor.leaderboard(silent=True)
        best_score = leaderboard.iloc[0]['score_val']
        all_menu_scores.append(best_score)
        print(f"ğŸ“ˆ ë§¤ì¥ '{restaurant_name}' í†µí•© ëª¨ë¸ ê²€ì¦ SMAPE ì ìˆ˜: {best_score:.4f}")

        try:
            feature_importance = predictor.feature_importance(train_data_ag)
            print("âœ¨ ìƒìœ„ 10ê°œ ì¤‘ìš” í”¼ì²˜:")
            print(feature_importance.head(10))
        except Exception as e:
            print(f"âš ï¸ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # ë§¤ì¥ë³„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ (ìˆœí™˜ ì˜ˆì¸¡)
        for path in test_paths:
            test_file_df = pd.read_csv(path)
            test_file_df['ì˜ì—…ì¥ëª…'] = test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
            
            # í˜„ì¬ ë§¤ì¥ì˜ ë©”ë‰´ê°€ í…ŒìŠ¤íŠ¸ íŒŒì¼ì— ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if restaurant_name not in test_file_df['ì˜ì—…ì¥ëª…'].unique():
                continue

            basename = os.path.basename(path).replace('.csv', '')
            
            # ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° (train + test íŒŒì¼ì˜ ê³¼ê±° ë°ì´í„°)
            historical_data = pd.concat([
                train_full_featured[train_full_featured['ì˜ì—…ì¥ëª…'] == restaurant_name],
                test_file_df[test_file_df['ì˜ì—…ì¥ëª…'] == restaurant_name]
            ]).copy()
            historical_data['ì˜ì—…ì¼ì'] = pd.to_datetime(historical_data['ì˜ì—…ì¼ì'])
            historical_data = historical_data.sort_values(by='ì˜ì—…ì¼ì').tail(28 * len(unique_restaurants)) # ì¶©ë¶„í•œ ê³¼ê±° ë°ì´í„° í™•ë³´

            # 7ì¼ ì˜ˆì¸¡
            menus_to_predict = test_file_df[test_file_df['ì˜ì—…ì¥ëª…'] == restaurant_name]['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique()
            
            for i in range(7):
                last_date = historical_data['ì˜ì—…ì¼ì'].max()
                next_date = last_date + pd.Timedelta(days=1)
                
                # ì˜ˆì¸¡ì„ ìœ„í•œ ìƒˆë¡œìš´ í–‰ ìƒì„± (í•´ë‹¹ ë§¤ì¥ì˜ ëª¨ë“  ë©”ë‰´ì— ëŒ€í•´)
                new_rows = pd.DataFrame([
                    {'ì˜ì—…ì¼ì': next_date, 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu, 'ë§¤ì¶œìˆ˜ëŸ‰': np.nan}
                    for menu in menus_to_predict
                ])
                
                # í”¼ì²˜ ìƒì„±ì„ ìœ„í•´ ê³¼ê±° ë°ì´í„°ì™€ í•©ì¹¨
                combined_for_feature = pd.concat([historical_data, new_rows], ignore_index=True)
                featured_data = create_features(combined_for_feature)
                
                # ì˜ˆì¸¡í•  ë§ˆì§€ë§‰ í–‰ë“¤ ì„ íƒ (AG ì…ë ¥)
                X_test = featured_data.tail(len(menus_to_predict)).drop(columns=['ì˜ì—…ì¼ì', 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', 'ë§¤ì¶œìˆ˜ëŸ‰', 'ì˜ì—…ì¥ëª…'])
                
                # AutoGluon ì˜ˆì¸¡
                X_test_aligned = align_required_raw_features_for_predict(predictor, X_test.copy())
                predictions = predictor.predict(X_test_aligned)
                predictions = predictions.clip(lower=0)
                
                # Prophetì€ í˜„ì¬ êµ¬ì¡°ì—ì„œ ì‚¬ìš©í•˜ê¸° ë³µì¡í•˜ë¯€ë¡œ ì•™ìƒë¸”ì—ì„œ ì œì™¸
                pred_final = predictions.values
                
                # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                for idx, menu in enumerate(menus_to_predict):
                    all_predictions.append({
                        'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                        'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu,
                        'ë§¤ì¶œìˆ˜ëŸ‰': pred_final[idx]
                    })

                # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ì˜ˆì¸¡ê°’ì„ í¬í•¨í•˜ì—¬ historical_data ì—…ë°ì´íŠ¸
                update_rows = featured_data.tail(len(menus_to_predict)).copy()
                update_rows['ë§¤ì¶œìˆ˜ëŸ‰'] = pred_final
                historical_data = pd.concat([historical_data, update_rows], ignore_index=True)
        # ë£¨í”„ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ë™ì¼í•˜ê²Œ ìœ ì§€

# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì œì¶œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
if all_predictions:
    pred_df = pd.DataFrame(all_predictions)
    
    print("ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    
    submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
    
    final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
    final_submission = final_submission.fillna(0)
    
    # ì»¬ëŸ¼ ìˆœì„œë¥¼ ìƒ˜í”Œê³¼ ë™ì¼í•˜ê²Œ ë§ì¶¤
    final_submission = final_submission[submission_df.columns]
    
    final_submission.to_csv('submission_autogluon_per_item.csv', index=False)
    print("submission_autogluon_per_item.csv íŒŒì¼ ìƒì„± ì™„ë£Œ")

    # ìµœì¢… í‰ê·  ê²€ì¦ ì ìˆ˜ ì¶œë ¥
    if all_menu_scores:
        average_smape = np.mean(all_menu_scores)
        print("\n" + "="*50)
        print(f"ğŸ“Š ì „ì²´ ë©”ë‰´ì˜ í‰ê·  ê²€ì¦ SMAPE ì ìˆ˜: {average_smape:.4f}")
        print("="*50)
else:
    print("ìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

print("\n=== ğŸ† AutoGluon(+Prophet ë³´ì¡° ì•™ìƒë¸”) ëª¨ë¸ ===")
print("âœ… ê° ë©”ë‰´ë³„ AutoGluon ëª¨ë¸ + Prophet ë³´ì¡° ì˜ˆì¸¡ ê°€ì¤‘ ì•™ìƒë¸”")
print("âœ… Prophet ë¯¸ì„¤ì¹˜/ë°ì´í„° ë¶€ì¡± ì‹œ ìë™ìœ¼ë¡œ AutoGluon ë‹¨ë… ì˜ˆì¸¡")
print("âœ… ê³µíœ´ì¼/ì£¼ê°„/ì—°ê°„ ì‹œì¦Œì„±ê³¼ ì¶”ì„¸ë¥¼ ë³´ì¡°ë¡œ ë°˜ì˜")
