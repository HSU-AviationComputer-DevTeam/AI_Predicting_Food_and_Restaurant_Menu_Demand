import os
import glob
import random
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
from autogluon.tabular import TabularPredictor
from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor
import warnings
warnings.filterwarnings('ignore')

# ==============================================================================
# ğŸ¯ ìµœì¢… ì „ëµ (v1.7): ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ + AutoGluon ìµœì í™”
# - í”¼ì²˜ ê°•í™”: ë©”ë‰´ ì¹´í…Œê³ ë¦¬, ì˜ì—…ì¥ íŠ¹ì„±, ìƒí˜¸ì‘ìš© í”¼ì²˜ ë“± ëŒ€í­ ì¶”ê°€
# - Log ë³€í™˜: np.log1pë¥¼ ì ìš©í•˜ì—¬ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ì•ˆì •í™”
# - TS ìµœì í™”: known_covariatesë¥¼ TimeSeriesPredictorì— ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
# - ë‘ Predictorì˜ ê²°ê³¼ë¥¼ 'ë‹´í™”', 'ë¯¸ë¼ì‹œì•„'ì— íŠ¹í™”ëœ ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸”
# ==============================================================================


# ê°€ì¤‘ ì•™ìƒë¸” ì„¤ì •
WEIGHT_CONFIG = {
    # ê¸°ë³¸ ê°€ì¤‘ì¹˜: [TabularPredictor ê°€ì¤‘ì¹˜, TimeSeriesPredictor ê°€ì¤‘ì¹˜]
    "default": [0.6, 0.4],
    # ì—…ì¥ë³„ íŠ¹í™” ê°€ì¤‘ì¹˜
    "special": {
        "ë‹´í™”": [0.5, 0.5],
        "ë¯¸ë¼ì‹œì•„": [0.4, 0.6]
    }
}

# AutoGluon í•™ìŠµ ì„¤ì • (ì‹œê°„ ì¦ëŒ€)
TABULAR_TIME_LIMIT = 600
TIMESERIES_TIME_LIMIT = 600

# ì‹œë“œ ê³ ì •
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(42)

# ê³µíœ´ì¼ ë¦¬ìŠ¤íŠ¸ (2025ë…„ í¬í•¨)
holiday_dates = pd.to_datetime([
    "2023-01-01", "2023-01-21", "2023-01-22", "2023-01-23", "2023-01-24",
    "2023-03-01", "2023-05-05", "2023-05-27", "2023-05-29", "2023-06-06",
    "2023-08-15", "2023-09-28", "2023-09-29", "2023-09-30", "2023-10-03",
    "2023-10-09", "2023-12-25", "2024-01-01", "2024-02-09", "2024-02-10",
    "2024-02-11", "2024-02-12", "2024-03-01", "2024-04-10", "2024-05-05",
    "2024-05-06", "2024-05-15", "2024-06-06", "2024-08-15", "2024-09-16",
    "2024-09-17", "2024-09-18", "2024-10-03", "2024-10-09", "2024-12-25",
    "2025-01-01", "2025-01-28", "2025-01-29", "2025-01-30", "2025-03-01",
    "2025-05-05", "2025-05-06"
])

def is_korean_holiday(date):
    return int(date in holiday_dates)

class AutoGluonEnsemblePredictor:
    def __init__(self, device):
        self.tabular_predictors = []
        self.timeseries_predictor = None
        self.feature_cols = None
        self.device = device
        # TimeSeriesPredictorê°€ ì‚¬ìš©í•  covariate ëª©ë¡
        self.known_covariate_names = [
            'day_of_week', 'is_weekend', 'month', 'day',
            'week_of_year', 'season', 'is_holiday', 'year'
        ]

    def create_advanced_features(self, df):
        """
        ë‹¤ì–‘í•œ ë„ë©”ì¸ ì§€ì‹ ë° ì‹œê³„ì—´ íŠ¹ì„±ì„ ê²°í•©í•œ ê³ ê¸‰ í”¼ì²˜ ìƒì„± í•¨ìˆ˜
        (ê¸°ì¡´ create_28day_featuresì™€ create_features í•¨ìˆ˜ë¥¼ í†µí•© ë° ê°•í™”)
        """
        # 1. ë‚ ì§œ ê¸°ë°˜ ê¸°ë³¸ í”¼ì²˜
        df['ì˜ì—…ì¼ì'] = pd.to_datetime(df['ì˜ì—…ì¼ì'])
        df['day_of_week'] = df['ì˜ì—…ì¼ì'].dt.weekday
        df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)
        df['month'] = df['ì˜ì—…ì¼ì'].dt.month
        df['day'] = df['ì˜ì—…ì¼ì'].dt.day
        df['week_of_year'] = df['ì˜ì—…ì¼ì'].dt.isocalendar().week.astype(int)
        df['season'] = (df['month'] % 12 + 3) // 3
        df['is_holiday'] = df['ì˜ì—…ì¼ì'].apply(is_korean_holiday)
        df['year'] = df['ì˜ì—…ì¼ì'].dt.year
        
        # 2. í…ìŠ¤íŠ¸(ë©”ë‰´ëª…/ì˜ì—…ì¥ëª…) ê¸°ë°˜ ë„ë©”ì¸ í”¼ì²˜
        df['ì˜ì—…ì¥ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[0]
        df['ë©”ë‰´ëª…'] = df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].str.split('_').str[1:].str.join('_')
        
        # ë©”ë‰´ ì¹´í…Œê³ ë¦¬
        df['ë¶„ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ê¼¬ì¹˜ì–´ë¬µ|ë–¡ë³¶ì´|í•«ë„ê·¸|íŠ€ê¹€|ìˆœëŒ€|ì–´ë¬µ|íŒŒì „', na=False).astype(int)
        df['ìŒë£Œë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼|ì½œë¼|ìŠ¤í”„ë¼ì´íŠ¸|ìƒìˆ˜|ì—ì´ë“œ|í•˜ì´ë³¼|ìŒë£Œ', na=False).astype(int)
        df['ì£¼ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('ë§‰ê±¸ë¦¬|ì†Œì£¼|ë§¥ì£¼|ì¹µí…Œì¼|ì™€ì¸|beer|ìƒë§¥ì£¼', na=False, case=False).astype(int)
        df['í•œì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('êµ­ë°¥|í•´ì¥êµ­|ë¶ˆê³ ê¸°|ê¹€ì¹˜|ëœì¥|ë¹„ë¹”ë°¥|ê°ˆë¹„|ê³µê¹ƒë°¥', na=False).astype(int)
        df['ì–‘ì‹ë¥˜'] = df['ë©”ë‰´ëª…'].str.contains('íŒŒìŠ¤íƒ€|í”¼ì|ìŠ¤í…Œì´í¬|ìƒëŸ¬ë“œ|ë¦¬ì¡°ë˜|ìŠ¤íŒŒê²Œí‹°', na=False).astype(int)
        
        # ì˜ì—…ì¥ íŠ¹ì„± (One-hot encoding)
        for store in ['í¬ë ˆìŠ¤íŠ¸ë¦¿', 'ì¹´í˜í…Œë¦¬ì•„', 'í™”ë‹´ìˆ²ì£¼ë§‰', 'ë‹´í•˜', 'ë¯¸ë¼ì‹œì•„', 'ëŠí‹°ë‚˜ë¬´ ì…€í”„BBQ', 'ë¼ê·¸ë¡œíƒ€', 'ì—°íšŒì¥', 'í™”ë‹´ìˆ²ì¹´í˜']:
            df[store] = (df['ì˜ì—…ì¥ëª…'] == store).astype(int)

        # 3. 28ì¼ ìœˆë„ìš° ê¸°ë°˜ í†µê³„ í”¼ì²˜ (TabularPredictorìš©)
        # ì´ ë¶€ë¶„ì€ prepare_tabular_training_dataì—ì„œ ë°ì´í„°í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        
        df = df.drop(columns=['ì˜ì—…ì¥ëª…', 'ë©”ë‰´ëª…'])
        return df

    def prepare_tabular_training_data(self, full_train_df):
        """TabularPredictor í•™ìŠµì„ ìœ„í•œ í†µí•© ë°ì´í„°ì…‹ ìƒì„±"""
        X_list, y_list = [], []
        
        # ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ê³ ê¸‰ í”¼ì²˜ ì¼ê´„ ìƒì„±
        featured_df = self.create_advanced_features(full_train_df.copy())
        
        for menu_name in tqdm(full_train_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique(), desc="í”¼ì²˜ ë°ì´í„°ì…‹ ìƒì„±", leave=False):
            menu_df = featured_df[featured_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].sort_values(by='ì˜ì—…ì¼ì')
            sales = menu_df['ë§¤ì¶œìˆ˜ëŸ‰'].values
            
            if len(sales) < 35: continue

            for i in range(len(sales) - 34):
                # 28ì¼ í†µê³„ í”¼ì²˜
                input_data = sales[i:i+28]
                features = {
                    'mean_sales_28d': np.mean(input_data),
                    'std_sales_28d': np.std(input_data),
                    'median_sales_28d': np.median(input_data),
                    'last_7day_mean': np.mean(input_data[-7:]),
                    'recent_trend': np.mean(input_data[-7:]) - np.mean(input_data[-14:-7]),
                }
                
                # ê¸°ì¡´ í”¼ì²˜ì™€ ê²°í•©
                row_features = menu_df.iloc[i+27].to_dict()
                row_features.update(features)
                X_list.append(row_features)
                
                # íƒ€ê²Ÿ ë°ì´í„°
                y_list.append(sales[i+28:i+35])

        X_df = pd.DataFrame(X_list).drop(columns=['ì˜ì—…ì¼ì', 'ë§¤ì¶œìˆ˜ëŸ‰'])
        y_df = pd.DataFrame(y_list, columns=[f'target_{i+1}day' for i in range(7)])
        
        if self.feature_cols is None:
            self.feature_cols = X_df.columns
            
        return pd.concat([X_df, y_df], axis=1)

    def train_tabular_predictors(self, train_data):
        """7ì¼ ì˜ˆì¸¡ì„ ìœ„í•œ 7ê°œì˜ TabularPredictor ëª¨ë¸ í•™ìŠµ"""
        for day in range(7):
            print(f"\n--- TabularPredictor Day {day+1} ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
            label = f'target_{day+1}day'
            predictor = TabularPredictor(
                label=label,
                path=f'autogluon_models/tabular_day_{day+1}',
                problem_type='regression',
                eval_metric='rmse'
            ).fit(
                train_data.drop(columns=[f'target_{i+1}day' for i in range(7) if i != day]),
                time_limit=TABULAR_TIME_LIMIT,
                presets='best_quality'
            )
            self.tabular_predictors.append(predictor)
    
    def train_timeseries_predictor(self, full_train_df):
        """known_covariatesë¥¼ ì‚¬ìš©í•˜ëŠ” TimeSeriesPredictor ëª¨ë¸ í•™ìŠµ"""
        print("\n--- TimeSeriesPredictor ëª¨ë¸ í•™ìŠµ ì‹œì‘ (known_covariates ì‚¬ìš©) ---")
        
        # full_train_dfì— ì§ì ‘ í”¼ì²˜ë¥¼ ìƒì„±í•˜ì—¬ ì—´ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        df_with_features = self.create_advanced_features(full_train_df.copy())

        ts_df = TimeSeriesDataFrame.from_data_frame(
            df_with_features,
            id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
            timestamp_column="ì˜ì—…ì¼ì"
        )

        self.timeseries_predictor = TimeSeriesPredictor(
            label='ë§¤ì¶œìˆ˜ëŸ‰',
            path='autogluon_models/timeseries_advanced',
            prediction_length=7,
            eval_metric='RMSE',
            known_covariates_names=self.known_covariate_names
        ).fit(
            ts_df,
            time_limit=TIMESERIES_TIME_LIMIT,
            presets="best_quality",
        )

    def predict_7days_autogluon_ensemble(self, input_28days_data, last_date, menu_name, context_df):
        """ë‘ AutoGluon Predictorì˜ ì˜ˆì¸¡ì„ ê°€ì¤‘ ì•™ìƒë¸” (known_covariates í¬í•¨)"""
        # 1. TabularPredictor ì˜ˆì¸¡
        # ì˜ˆì¸¡ì— í•„ìš”í•œ í”¼ì²˜ ìƒì„± (ì£¼ì˜: 28ì¼ í†µê³„ í”¼ì²˜ëŠ” ë³„ë„ ê³„ì‚°)
        temp_df = pd.DataFrame({'ì˜ì—…ì¼ì': [last_date], 'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': [menu_name]})
        base_features = self.create_advanced_features(temp_df).iloc[0].to_dict()

        stat_features = {
            'mean_sales_28d': np.mean(input_28days_data),
            'std_sales_28d': np.std(input_28days_data),
            'median_sales_28d': np.median(input_28days_data),
            'last_7day_mean': np.mean(input_28days_data[-7:]),
            'recent_trend': np.mean(input_28days_data[-7:]) - np.mean(input_28days_data[-14:-7]),
        }
        base_features.update(stat_features)
        
        X_pred_tabular = pd.DataFrame([base_features])[self.feature_cols]
        tabular_preds = [
            max(0, p.predict(X_pred_tabular).iloc[0]) for p in self.tabular_predictors
        ]

        # 2. TimeSeriesPredictor ì˜ˆì¸¡ (known_covariates í¬í•¨)
        future_dates = pd.to_datetime([last_date + pd.Timedelta(days=i) for i in range(1, 8)])
        future_covariates_df = pd.DataFrame({
            'ì˜ì—…ì¼ì': future_dates,
            'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': [menu_name] * 7
        })
        future_covariates_featured = self.create_advanced_features(future_covariates_df)

        # known_covariatesë¥¼ TimeSeriesDataFrameìœ¼ë¡œ ëª…ì‹œì  ë³€í™˜
        known_covariates = TimeSeriesDataFrame.from_data_frame(
            future_covariates_featured,
            id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…",
            timestamp_column="ì˜ì—…ì¼ì"
        )

        ts_context_df = TimeSeriesDataFrame.from_data_frame(
            context_df, id_column="ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…", timestamp_column="ì˜ì—…ì¼ì"
        )
        ts_preds_raw = self.timeseries_predictor.predict(
            ts_context_df,
            known_covariates=known_covariates
        )
        
        predictions_for_item = ts_preds_raw.loc[menu_name]
        ts_preds = predictions_for_item['mean'].clip(lower=0).values

        # 3. ê°€ì¤‘ ì•™ìƒë¸”
        store_name = menu_name.split('_')[0]
        weights = WEIGHT_CONFIG['special'].get(store_name, WEIGHT_CONFIG['default'])
        
        ensemble_preds = (np.array(tabular_preds) * weights[0] + ts_preds * weights[1])
        
        return ensemble_preds

# ==============================================================================
# Main Execution
# ==============================================================================
if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

    print("ë°ì´í„° ë¡œë“œ ì¤‘...")
    train_df = pd.read_csv('./data/train/train.csv')
    # Log1p ë³€í™˜
    train_df['ë§¤ì¶œìˆ˜ëŸ‰'] = np.log1p(train_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))
    train_df['ì˜ì—…ì¼ì'] = pd.to_datetime(train_df['ì˜ì—…ì¼ì'])
    submission_df = pd.read_csv('./data/sample_submission.csv')

    predictor = AutoGluonEnsemblePredictor(device)
    
    # --- ëª¨ë¸ í•™ìŠµ ---
    # 1. TabularPredictor í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° í•™ìŠµ
    tabular_train_data = predictor.prepare_tabular_training_data(train_df)
    predictor.train_tabular_predictors(tabular_train_data)
    
    # 2. TimeSeriesPredictor í•™ìŠµ
    predictor.train_timeseries_predictor(train_df)

    # --- Test íŒŒì¼ë³„ ì˜ˆì¸¡ ---
    print("\nìµœì¢… ì•™ìƒë¸” ì˜ˆì¸¡ ìƒì„± ì¤‘...")
    all_predictions = []
    test_paths = sorted(glob.glob('./data/test/*.csv'))
    
    for path in tqdm(test_paths, desc="Test íŒŒì¼ë³„ ì˜ˆì¸¡"):
        test_file_df = pd.read_csv(path)
        test_file_df['ì˜ì—…ì¼ì'] = pd.to_datetime(test_file_df['ì˜ì—…ì¼ì'])
        basename = os.path.basename(path).replace('.csv', '')
        
        # test ë°ì´í„°ì—ë„ log1p ë³€í™˜ ì ìš©
        test_file_df['ë§¤ì¶œìˆ˜ëŸ‰'] = np.log1p(test_file_df['ë§¤ì¶œìˆ˜ëŸ‰'].clip(lower=0))
        # ì˜ˆì¸¡ì— í•„ìš”í•œ í”¼ì²˜ë¥¼ test_file_df ì „ì²´ì— ë¯¸ë¦¬ ìƒì„±
        test_file_df_featured = predictor.create_advanced_features(test_file_df.copy())
        
        for menu_name in test_file_df['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'].unique():
            # 28ì¼ ì…ë ¥ ë°ì´í„° êµ¬ì„± (í”¼ì²˜ê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ì—ì„œ)
            context_df = test_file_df_featured[test_file_df_featured['ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…'] == menu_name].iloc[-28:]
            
            if context_df.empty:
                # submission íŒŒì¼ì— í•´ë‹¹ ë©”ë‰´ê°€ ì—†ì„ ê²½ìš° ëŒ€ë¹„
                continue
            
            input_28days_data = context_df['ë§¤ì¶œìˆ˜ëŸ‰'].values
            last_date = context_df['ì˜ì—…ì¼ì'].max()
            
            # AutoGluon ì•™ìƒë¸” ì˜ˆì¸¡
            pred_7days_log = predictor.predict_7days_autogluon_ensemble(input_28days_data, last_date, menu_name, context_df)
            
            # ì˜ˆì¸¡ê°’ ë³µì› (expm1)
            pred_7days = np.expm1(pred_7days_log)
            
            # ê²°ê³¼ ì €ì¥
            for i, pred_val in enumerate(pred_7days):
                all_predictions.append({
                    'ì˜ì—…ì¼ì': f"{basename}+{i+1}ì¼",
                    'ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…': menu_name,
                    'ë§¤ì¶œìˆ˜ëŸ‰': max(0, pred_val) # í˜¹ì‹œ ëª¨ë¥¼ ìŒìˆ˜ê°’ ë°©ì§€
                })

    # --- ì œì¶œ íŒŒì¼ ìƒì„± ---
    if all_predictions:
        pred_df = pd.DataFrame(all_predictions)
        submission_pivot = pred_df.pivot(index='ì˜ì—…ì¼ì', columns='ì˜ì—…ì¥ëª…_ë©”ë‰´ëª…', values='ë§¤ì¶œìˆ˜ëŸ‰').reset_index()
        final_submission = pd.merge(submission_df[['ì˜ì—…ì¼ì']], submission_pivot, on='ì˜ì—…ì¼ì', how='left')
        final_submission = final_submission.fillna(0)
        final_submission = final_submission[submission_df.columns]
        
        output_filename = 'submission_autogluon_advanced.csv'
        final_submission.to_csv(output_filename, index=False)
        print(f"\n{output_filename} íŒŒì¼ ìƒì„± ì™„ë£Œ")
    else:
        print("ìƒì„±ëœ ì˜ˆì¸¡ì´ ì—†ìŠµë‹ˆë‹¤.")

    print("\n=== ğŸ† AutoGluon ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë¸ ===")
    print(f"âœ… ê³ ê¸‰ í”¼ì²˜ + Logë³€í™˜ + TS ìµœì í™” ì ìš©")
    print(f"âœ… 'ë‹´í™”', 'ë¯¸ë¼ì‹œì•„'ì— íŠ¹í™” ê°€ì¤‘ì¹˜ ì ìš©: {WEIGHT_CONFIG['special']}")
    print("âœ… ëŒ€íšŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ìµœì¢… ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ")


#     submission_autogluon_advanced.csv íŒŒì¼ ìƒì„± ì™„ë£Œ

# === ğŸ† AutoGluon ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë¸ ===
# âœ… ê³ ê¸‰ í”¼ì²˜ + Logë³€í™˜ + TS ìµœì í™” ì ìš©
# âœ… 'ë‹´í™”', 'ë¯¸ë¼ì‹œì•„'ì— íŠ¹í™” ê°€ì¤‘ì¹˜ ì ìš©: {'ë‹´í™”': [0.5, 0.5], 'ë¯¸ë¼ì‹œì•„': [0.4, 0.6]}
# âœ… ëŒ€íšŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ëŠ” ìµœì¢… ëª¨ë¸ êµ¬í˜„ ì™„ë£Œ
# (_ray_fit pid=25888) [3000]     valid_set's rmse: 0.640075 [repeated 10x across cluster]
# (.venv) 
